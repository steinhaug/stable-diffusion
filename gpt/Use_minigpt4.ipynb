{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "premium",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/steinhaug/stable-diffusion/blob/main/gpt/Use_minigpt4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Now you can use MiniGPT-4 13B/7B in Google Colab\n",
        "\n",
        "## <font color=\"#dd0000\">Notice</font>\n",
        "\n",
        "1. You should be a **Google Colab Pro** user.\n",
        "2. You must use **high level GPU**.\n",
        "\n",
        "Otherwise you will not be able to run MiniGPT-4 in colab!!!"
      ],
      "metadata": {
        "id": "wJNQu3Tj9mla"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Clone repo"
      ],
      "metadata": {
        "id": "W87F1-Di8M9R"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3WFuEa_H_R14",
        "outputId": "360aad93-c202-47a5-d0b4-c410064af436"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'MiniGPT-4'...\n",
            "remote: Enumerating objects: 266, done.\u001b[K\n",
            "remote: Counting objects: 100% (93/93), done.\u001b[K\n",
            "remote: Compressing objects: 100% (50/50), done.\u001b[K\n",
            "remote: Total 266 (delta 63), reused 43 (delta 43), pack-reused 173\u001b[K\n",
            "Receiving objects: 100% (266/266), 57.53 MiB | 16.54 MiB/s, done.\n",
            "Resolving deltas: 100% (105/105), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/Vision-CAIR/MiniGPT-4.git"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Check gpu"
      ],
      "metadata": {
        "id": "QQzLoKL38P0R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IQiobft0yXpg",
        "outputId": "dbc03def-30a6-4bab-bfe0-3a9b386a738b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sun Apr 23 01:12:41 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   56C    P8     9W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Install package"
      ],
      "metadata": {
        "id": "gSy1wyO38TTp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ls"
      ],
      "metadata": {
        "id": "7p3vtgW1_f5o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "715722bf-3ace-41d9-ec2b-b77e0636d570"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0m\u001b[01;34mMiniGPT-4\u001b[0m/  \u001b[01;34msample_data\u001b[0m/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd MiniGPT-4/"
      ],
      "metadata": {
        "id": "XPWawh6y_jZ-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4bc1c62d-6f09-40cd-ea0c-8e3d45da92ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/MiniGPT-4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Get requirements.txt in `https://github.com/WangRongsheng/Use-LLMs-in-Colab/blob/main/MiniGPT-4/requirements.txt`"
      ],
      "metadata": {
        "id": "r0sksdnw-jIG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -qr requirements.txt"
      ],
      "metadata": {
        "id": "BzZIcNue_pYn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q salesforce-lavis\n",
        "!pip install -q bitsandbytes\n",
        "!pip install -q accelerate\n",
        "!pip install -q gradio==3.27.0"
      ],
      "metadata": {
        "id": "VyRZwh6X1gYt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "10e3e3dd-fb79-4b81-ba72-b9117aab973d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m71.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m377.0/377.0 kB\u001b[0m \u001b[31m43.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.1/53.1 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.7/9.7 MB\u001b[0m \u001b[31m93.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.8/47.8 MB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m235.4/235.4 kB\u001b[0m \u001b[31m33.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m202.7/202.7 kB\u001b[0m \u001b[31m29.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m102.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m115.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.8/98.8 kB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.1/82.1 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m164.8/164.8 kB\u001b[0m \u001b[31m25.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m111.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m468.5/468.5 kB\u001b[0m \u001b[31m54.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for fairscale (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for contexttimer (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for validators (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.3/17.3 MB\u001b[0m \u001b[31m82.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m286.2/286.2 kB\u001b[0m \u001b[31m36.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q h5py\n",
        "!pip install -q typing-extensions\n",
        "!pip install -q wheel\n",
        "!pip install -q git+https://github.com/huggingface/transformers.git -U"
      ],
      "metadata": {
        "id": "3QaQcHjT2l6z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce51bbf2-b287-4a29-f31d-e227113f1472"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Download pretrained_minigpt4"
      ],
      "metadata": {
        "id": "iftS7jdt8XDB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# if you run 13B , Plaease Download Checkpoint Aligned with Vicuna 13B\n",
        "#!wget https://huggingface.co/wangrongsheng/MiniGPT4/blob/main/pretrained_minigpt4.pth\n",
        "\n",
        "# if you run 7B , Plaease Download Checkpoint Aligned with Vicuna 7B\n",
        "!wget https://huggingface.co/wangrongsheng/MiniGPT4-7B/resolve/main/prerained_minigpt4_7b.pth"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "69XCMTuCAVfO",
        "outputId": "ebc155ee-bb79-44b0-d43f-21dacb308f08"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-04-23 01:19:12--  https://huggingface.co/wangrongsheng/MiniGPT4-7B/resolve/main/prerained_minigpt4_7b.pth\n",
            "Resolving huggingface.co (huggingface.co)... 18.155.68.44, 18.155.68.116, 18.155.68.38, ...\n",
            "Connecting to huggingface.co (huggingface.co)|18.155.68.44|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://cdn-lfs.huggingface.co/repos/25/fa/25fa880e116eda3d82c5c87b32eb0a7fa8f76b139d70ce756851215ce7a76179/017a9ed588a11ed383711003cf50cf675191420a04689f682fb56fa9bbb8dcbb?response-content-disposition=attachment%3B+filename*%3DUTF-8%27%27prerained_minigpt4_7b.pth%3B+filename%3D%22prerained_minigpt4_7b.pth%22%3B&Expires=1682471952&Policy=eyJTdGF0ZW1lbnQiOlt7IlJlc291cmNlIjoiaHR0cHM6Ly9jZG4tbGZzLmh1Z2dpbmdmYWNlLmNvL3JlcG9zLzI1L2ZhLzI1ZmE4ODBlMTE2ZWRhM2Q4MmM1Yzg3YjMyZWIwYTdmYThmNzZiMTM5ZDcwY2U3NTY4NTEyMTVjZTdhNzYxNzkvMDE3YTllZDU4OGExMWVkMzgzNzExMDAzY2Y1MGNmNjc1MTkxNDIwYTA0Njg5ZjY4MmZiNTZmYTliYmI4ZGNiYj9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSoiLCJDb25kaXRpb24iOnsiRGF0ZUxlc3NUaGFuIjp7IkFXUzpFcG9jaFRpbWUiOjE2ODI0NzE5NTJ9fX1dfQ__&Signature=DsRDra5GigHPHD0B7R3oxr2ciPbwmw4y-3-n3vxekAeoqSzjsbCpWoQnvCjzaLCkngwVN7wnQe0c9KBJ%7ERPjvSDsWwdIuO4VC5Q4TRCpentePf3FEcKG3EwyuZI1qCUFGkEwR8%7EnejKfhR9FMjIxbB49ybzxJ-2qrxlTb3BmnyQn2wfQ9ONtO5yqpQNXA2R5R4b8C0JuKKWSCN5A5EqLkfayDOC6FNrN-BbNp0lOs%7ExZE1T418C5HWAyfYgevdsIRUhx-PZaFBdZCn7i6MM9D4MTilYdsJku%7EBPdhLTP5gun1LHvuEf9bk7NZzANUCciTpU4UHXmohzuILzsmSiv-g__&Key-Pair-Id=KVTP0A1DKRTAX [following]\n",
            "--2023-04-23 01:19:12--  https://cdn-lfs.huggingface.co/repos/25/fa/25fa880e116eda3d82c5c87b32eb0a7fa8f76b139d70ce756851215ce7a76179/017a9ed588a11ed383711003cf50cf675191420a04689f682fb56fa9bbb8dcbb?response-content-disposition=attachment%3B+filename*%3DUTF-8%27%27prerained_minigpt4_7b.pth%3B+filename%3D%22prerained_minigpt4_7b.pth%22%3B&Expires=1682471952&Policy=eyJTdGF0ZW1lbnQiOlt7IlJlc291cmNlIjoiaHR0cHM6Ly9jZG4tbGZzLmh1Z2dpbmdmYWNlLmNvL3JlcG9zLzI1L2ZhLzI1ZmE4ODBlMTE2ZWRhM2Q4MmM1Yzg3YjMyZWIwYTdmYThmNzZiMTM5ZDcwY2U3NTY4NTEyMTVjZTdhNzYxNzkvMDE3YTllZDU4OGExMWVkMzgzNzExMDAzY2Y1MGNmNjc1MTkxNDIwYTA0Njg5ZjY4MmZiNTZmYTliYmI4ZGNiYj9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSoiLCJDb25kaXRpb24iOnsiRGF0ZUxlc3NUaGFuIjp7IkFXUzpFcG9jaFRpbWUiOjE2ODI0NzE5NTJ9fX1dfQ__&Signature=DsRDra5GigHPHD0B7R3oxr2ciPbwmw4y-3-n3vxekAeoqSzjsbCpWoQnvCjzaLCkngwVN7wnQe0c9KBJ%7ERPjvSDsWwdIuO4VC5Q4TRCpentePf3FEcKG3EwyuZI1qCUFGkEwR8%7EnejKfhR9FMjIxbB49ybzxJ-2qrxlTb3BmnyQn2wfQ9ONtO5yqpQNXA2R5R4b8C0JuKKWSCN5A5EqLkfayDOC6FNrN-BbNp0lOs%7ExZE1T418C5HWAyfYgevdsIRUhx-PZaFBdZCn7i6MM9D4MTilYdsJku%7EBPdhLTP5gun1LHvuEf9bk7NZzANUCciTpU4UHXmohzuILzsmSiv-g__&Key-Pair-Id=KVTP0A1DKRTAX\n",
            "Resolving cdn-lfs.huggingface.co (cdn-lfs.huggingface.co)... 54.192.150.84, 54.192.150.19, 54.192.150.69, ...\n",
            "Connecting to cdn-lfs.huggingface.co (cdn-lfs.huggingface.co)|54.192.150.84|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 37907201 (36M) [binary/octet-stream]\n",
            "Saving to: ‘prerained_minigpt4_7b.pth’\n",
            "\n",
            "prerained_minigpt4_ 100%[===================>]  36.15M  10.6MB/s    in 3.4s    \n",
            "\n",
            "2023-04-23 01:19:16 (10.6 MB/s) - ‘prerained_minigpt4_7b.pth’ saved [37907201/37907201]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <font color=\"#660000\">Notice</font>\n",
        "\n",
        "## IF you run 13B:\n",
        "\n",
        "- Set `llama_model: \"wangrongsheng/MiniGPT-4-LLaMA\"` in `minigpt4/configs/models/minigpt4.yaml`\n",
        "- Set `ckpt: 'pretrained_minigpt4.pth'` in `eval_configs/minigpt4_eval.yaml`\n",
        "\n",
        "> `wangrongsheng/MiniGPT-4-LLaMA` was created from `vicuna-13b-delta-v0` and `llama-13b-hf`\n",
        "\n",
        "## IF you run 7B:\n",
        "\n",
        "- Set `llama_model: \"wangrongsheng/MiniGPT-4-LLaMA-7B\"` in `minigpt4/configs/models/minigpt4.yaml`\n",
        "- Set `ckpt: 'prerained_minigpt4_7b.pth'` in `eval_configs/minigpt4_eval.yaml`\n",
        "\n",
        "> `wangrongsheng/MiniGPT-4-LLaMA-7B` was created from `vicuna-7b-delta-v0` and `llama-7b-hf`"
      ],
      "metadata": {
        "id": "RqLKLejaDEUf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Run MiniGPT-4"
      ],
      "metadata": {
        "id": "lndJLTq89crE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python demo.py --cfg-path eval_configs/minigpt4_eval.yaml --gpu-id 0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IoPqDP4WC_km",
        "outputId": "da2ad319-33bc-494f-c6c9-c16c1bd483b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/requests/__init__.py:102: RequestsDependencyWarning: urllib3 (1.26.15) or chardet (5.1.0)/charset_normalizer (2.0.12) doesn't match a supported version!\n",
            "  warnings.warn(\"urllib3 ({}) or chardet ({})/charset_normalizer ({}) doesn't match a supported \"\n",
            "2023-04-23 01:44:25.093945: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Initializing Chat\n",
            "Loading VIT\n",
            "Loading VIT Done\n",
            "Loading Q-Former\n",
            "Loading Q-Former Done\n",
            "Loading LLAMA\n",
            "\n",
            "===================================BUG REPORT===================================\n",
            "Welcome to bitsandbytes. For bug reports, please submit your error trace to: https://github.com/TimDettmers/bitsandbytes/issues\n",
            "================================================================================\n",
            "Loading checkpoint shards:   0% 0/2 [00:00<?, ?it/s]^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3YZwzYXFPEmu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}