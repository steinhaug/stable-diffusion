{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/steinhaug/stable-diffusion/blob/main/Dreambooth_Colab_edition_for_people_in_a_hurry_fp16.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BzM7j0ZSc_9c"
      },
      "source": [
        "# Dreambooth - Colab edition for people in a hurry v1.5\n",
        "\n",
        "Let's skip the jargon and all the AI tech talk. I will make sure you are up and running with your own pretrained model within the hour without any skills needed. I have also prepared a AI-Art pack for you so that you don't have to learn prompting either, however you will be able to try prompts if you want.\n",
        "<br>\n",
        "<br>\n",
        "<b>* * Will not run on T4 - needs GPU * *</b>\n",
        "<br><br>\n",
        "<b>Time required to complete this demo:</b><br>\n",
        "60 minutes, this includes rendering of some 100+ AI art images.<br>\n",
        "_(change the runtime GPU to A100 and get a huge speed boost, from 60 to 20 minutes...)_\n",
        "\n",
        "---\n",
        "<small>**Credits:**</small><br>\n",
        "![Visitors](https://api.visitorbadge.io/api/combined?path=https%3A%2F%2Fcolab.research.google.com%2Fgithub%2Fsteinhaug%2Fstable-diffusion%2Fblob%2Fmain%2FDreambooth_Colab_edition_for_people_in_a_hurry_fp16.ipynb&label=hitcount&countColor=%23263759&style=flat)\n",
        "<a href=\"https://colab.research.google.com/github/steinhaug/stable-diffusion/blob/main/Dreambooth_Colab_edition_for_people_in_a_hurry_fp16.ipynb?1\" target=\"_blank\"><img alt=\"Open Notebook in Colab\" src=\"https://img.shields.io/badge/Dreambooth%20--%20for%20people%20in%20a%20hurry-Notebook-blue?logo=googlecolab\"></a> maintained by <a href=\"https://github.com/steinhaug/\" target=\"_blank\"><img alt=\"Open Github profile\" src=\"https://img.shields.io/badge/Steinhaug-Profile-black?logo=github\"></a> derived work from <a href=\"https://colab.research.google.com/github/ShivamShrirao/diffusers/blob/main/examples/dreambooth/DreamBooth_Stable_Diffusion.ipynb\" target=\"_blank\"><img alt=\"Open in Github\" src=\"https://img.shields.io/badge/ShivamShrirao%20--%20dreambooth-Notebook-blue?logo=googlecolab\"></a> by <a href=\"https://github.com/ShivamShrirao\" target=\"_blank\"><img alt=\"Open in Github\" src=\"https://img.shields.io/badge/ShivamShrirao-Profile-black?logo=github\"></a> and <a href=\"https://colab.research.google.com/github/TheLastBen/fast-stable-diffusion/blob/main/fast-DreamBooth.ipynb\" target=\"_blank\"><img alt=\"Open in Colab\" src=\"https://img.shields.io/badge/TheLastBen%20--%20Dreambooth-PRO%20Notebook-blue?logo=googlecolab\"></a> by <a href=\"https://github.com/TheLastBen\" target=\"_blank\"><img alt=\"Open in Github\" src=\"https://img.shields.io/badge/TheLastBen-Profile-black?logo=github\"></a>.\n",
        "<br>\n",
        "[![Buy me a beer](https://raw.githubusercontent.com/steinhaug/stable-diffusion/main/assets/buy-me-a-beer.png ) ](https://steinhaug.com/donate/)\n",
        "\n",
        "**Lastly two quicktips,** <br>\n",
        "Chose \"Save a copy in drive\" from File menu or you will not be able to save progress of this notebook, however dont worry this notebook is setup with no need for save in mind.<br>\n",
        "Finally if you have two sharp and detailed face images tilt them left and right and create extra variants. It's easier to get good results this way. You should tilt them before cropping the 512px ones<br><h2>Example of 6 images typically for this demonstration - made from 2</h2>\n",
        "![Init](https://raw.githubusercontent.com/steinhaug/stable-diffusion/main/assets/training-in-a-hurry-6-mugshots.png)\n",
        "<br>Hope you have fun!<br>_Regards, Kim Steinhaug_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5slbFJ_iFxsS"
      },
      "source": [
        "# PART 1.0: Configuration\n",
        "![Init](https://raw.githubusercontent.com/steinhaug/stable-diffusion/main/assets/notebook-setup.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mMr93d_vsOJ9"
      },
      "source": [
        "Checklist:\n",
        "1. You have created an account on huggingface.co and retrieved your write access token (needed for uploading your model to huggingsface in part 4)\n",
        "2. You already have a google account, or you have registered a new Google Account, so you can access Drive, Colab and Gmail services.\n",
        "3. You have prepared 6 images for what you want to train the AI model, they have been cropped for 512x512.\n",
        "\n",
        "if thats all good... lets go!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "XU7NuMAA2drw"
      },
      "outputs": [],
      "source": [
        "#@title Setup 1/4 - System check... Verify that we are running with a GPU\n",
        "!nvidia-smi --query-gpu=name,memory.total,memory.free --format=csv,noheader\n",
        "\n",
        "import tensorflow as tf\n",
        "gpus = tf.config.list_physical_devices('GPU')\n",
        "for gpu in gpus:\n",
        "    print(\"Name:\", gpu.name, \"  Type:\", gpu.device_type)\n",
        "\n",
        "import requests\n",
        "from IPython.display import Markdown\n",
        "\n",
        "def print_markdown(text):\n",
        "    display(Markdown(text))\n",
        "\n",
        "def load_url_as_int(url):\n",
        "    response = requests.get(url)\n",
        "    content = response.text.strip()\n",
        "    try:\n",
        "        number = int(content)\n",
        "        return number\n",
        "    except ValueError:\n",
        "        print(\"The content of the URL is not a valid integer.\")\n",
        "        return None\n",
        "\n",
        "VERSION_CURR_NOTEB = 15\n",
        "VERSION_LATEST_NOTEBurl = \"https://raw.githubusercontent.com/steinhaug/stable-diffusion/main/assets/versions/Dreambooth_Colab_edition_for_people_in_a_hurry_fp16.txt\"\n",
        "VERSION_LATEST_NOTEB = load_url_as_int(VERSION_LATEST_NOTEBurl)\n",
        "UPDATE_TXT = '''\n",
        "# WeeeHOOO! NoteBook Update available!\n",
        "This notebook have been updated, click the link here to load the updated notebook!\n",
        "\n",
        "[![Open in Colab](https://img.shields.io/badge/steinhaug-Open%20in%20Colab-blue?logo=google-colab)](https://colab.research.google.com/github/steinhaug/stable-diffusion/blob/main/Dreambooth_Colab_edition_for_people_in_a_hurry_fp16.ipynb)\n",
        "'''\n",
        "if VERSION_LATEST_NOTEB is not None:\n",
        "    if VERSION_LATEST_NOTEB > VERSION_CURR_NOTEB:\n",
        "        print_markdown(UPDATE_TXT)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "NwjiODwM9jQ1"
      },
      "outputs": [],
      "source": [
        "#@title Setup 2/4: Connect and mount drive\n",
        "#@markdown You will need 8 GB free space on your Google Drive to complete this AI Demo<br>\n",
        "#@markdown Tip: If you dont have that much available, register an extra Google Account. Its free :)\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "QpN7E3zuV8SY"
      },
      "outputs": [],
      "source": [
        "#@title Setup 3/4: Add your identifiers **(RELOADER)**\n",
        "#@markdown $\\color{orange}{\\text{--- If the notebook crashes you need to replay this cell, you will be notified in case you need to play it again.}}$\n",
        "#@markdown <br> $\\color{orange}{\\text{--- Think of this cell as the RELOADER cell.}}$\n",
        "\n",
        "from IPython.display import clear_output\n",
        "from google.colab import drive\n",
        "from pathlib import Path\n",
        "from zipfile import ZipFile\n",
        "import time\n",
        "import requests\n",
        "import json\n",
        "import os\n",
        "\n",
        "%cd /content\n",
        "\n",
        "HUGGINGFACE_TOKEN = \"\" #@param {type:\"string\"}\n",
        "YOUR_TOKEN = \"piax1\" #@param {type:\"string\"}\n",
        "TOKEN_GENDER = \"woman\" #@param [\"person\", \"man\", \"woman\"]\n",
        "\n",
        "#@markdown $\\color{grey}{\\text{--- If you want to select another model chose or change the text. Only Diffusers from Huggingface.}}$\n",
        "\n",
        "MODEL_NAME = \"dreamlike-art/dreamlike-photoreal-2.0\" #@param [\"SG161222/Realistic_Vision_V2.0\",\"runwayml/stable-diffusion-v1-5\",\"prompthero/openjourney\",\"XpucT/Deliberate\",\"Lykon/DreamShaper\",\"Linaqruf/anything-v3.0\",\"hakurei/waifu-diffusion\",\"dreamlike-art/dreamlike-photoreal-2.0\"] {allow-input: true}\n",
        "\n",
        "YOUR_TOKEN = \"x_\" + YOUR_TOKEN\n",
        "\n",
        "!mkdir -p ~/.cache\n",
        "!mkdir -p ~/.cache/huggingface\n",
        "!echo -n \"{HUGGINGFACE_TOKEN}\" > ~/.cache/huggingface/token\n",
        "\n",
        "if TOKEN_GENDER == 'man':\n",
        "    concepts_list = [\n",
        "        {\n",
        "            \"instance_prompt\":      \"photo of \" + YOUR_TOKEN + \" man\",\n",
        "            \"class_prompt\":         \"photo of a man\",\n",
        "            \"instance_data_dir\":    \"/content/data/\" + YOUR_TOKEN,\n",
        "            \"class_data_dir\":       \"/content/data/man_mixed-100\"\n",
        "        },\n",
        "    ]\n",
        "    regularizationFile = \"man_mixed-100.zip\"\n",
        "    SAMPLE_PROMPT = '\"' + YOUR_TOKEN + \" man as viking king, highly saturated colors, concept art, Dan Mumford, Greg rutkowski\" + '\"'\n",
        "elif TOKEN_GENDER == 'woman':\n",
        "    concepts_list = [\n",
        "        {\n",
        "            \"instance_prompt\":      \"photo of \" + YOUR_TOKEN + \" woman\",\n",
        "            \"class_prompt\":         \"photo of a woman\",\n",
        "            \"instance_data_dir\":    \"/content/data/\" + YOUR_TOKEN,\n",
        "            \"class_data_dir\":       \"/content/data/woman_art-100\"\n",
        "        },\n",
        "    ]\n",
        "    regularizationFile = \"woman_art-100.zip\"\n",
        "    SAMPLE_PROMPT = '\"' + YOUR_TOKEN + \" woman as amazon queen, highly saturated colors, concept art, Dan Mumford, Greg rutkowski\" + '\"'\n",
        "else:\n",
        "    concepts_list = [\n",
        "        {\n",
        "            \"instance_prompt\":      \"photo of \" + YOUR_TOKEN + \" person\",\n",
        "            \"class_prompt\":         \"photo of a person\",\n",
        "            \"instance_data_dir\":    \"/content/data/\" + YOUR_TOKEN,\n",
        "            \"class_data_dir\":       \"/content/data/person_art-100\"\n",
        "        },\n",
        "    ]\n",
        "    regularizationFile = \"person_art-100.zip\"\n",
        "    SAMPLE_PROMPT = '\"' + YOUR_TOKEN + \" person as amazon queen, highly saturated colors, concept art, Dan Mumford, Greg rutkowski\" + '\"'\n",
        "\n",
        "for c in concepts_list:\n",
        "    os.makedirs(c[\"instance_data_dir\"], exist_ok=True)\n",
        "\n",
        "with open(\"concepts_list.json\", \"w\") as f:\n",
        "    json.dump(concepts_list, f, indent=4)\n",
        "\n",
        "save_to_gdrive = True\n",
        "\n",
        "OUTPUT_DIR = \"stable_diffusion_weights/\" + YOUR_TOKEN\n",
        "\n",
        "if save_to_gdrive:\n",
        "    OUTPUT_DIR = \"/content/drive/MyDrive/\" + OUTPUT_DIR\n",
        "else:\n",
        "    OUTPUT_DIR = \"/content/\" + OUTPUT_DIR\n",
        "\n",
        "!mkdir -p $OUTPUT_DIR\n",
        "\n",
        "\n",
        "def bar(prg):\n",
        "    br=\"\u001b[1;33mUploading to HuggingFace : \" '\u001b[0m|'+'█' * prg + ' ' * (25-prg)+'| ' +str(prg*4)+ \"%\"\n",
        "    return br\n",
        "def ret_directoryFileCount(dir_path):\n",
        "    file_count = 0\n",
        "    for path in os.listdir(dir_path):\n",
        "        if os.path.isfile(os.path.join(dir_path, path)):\n",
        "            file_count += 1\n",
        "    return file_count\n",
        "\n",
        "clear_output();\n",
        "\n",
        "# Let's verify Huggingface model\n",
        "httpResponse = requests.get('https://huggingface.co/' + MODEL_NAME)\n",
        "theHTTPCode = httpResponse.status_code\n",
        "if theHTTPCode == 200:\n",
        "    print('\u001b[1;32mDone! ✓')\n",
        "elif theHTTPCode == 404:\n",
        "    print('Oh no, seems that the URL is broken! Something is wrong with the URL being downloaded from Huggingface')\n",
        "else:\n",
        "    print(f\"Unknown error, HTTP status: {theHTTPCode}. Link: 'https://huggingface.co/'{MODEL_NAME}\")\n",
        "\n",
        "\n",
        "path = Path(\"/content/data\")\n",
        "if not path.exists():\n",
        "    path.mkdir(parents = False, exist_ok = False)\n",
        "%cd /content/data\n",
        "!wget -O {regularizationFile} https://huggingface.co/datasets/steinhaug/regularization/resolve/main/{regularizationFile}\n",
        "with ZipFile(\"/content/data/\" + regularizationFile, 'r') as zObject:\n",
        "    zObject.extractall(path=\"/content/data\")\n",
        "\n",
        "print('\u001b[1;32mRegularization in place... Done');\n",
        "\n",
        "clear_output()\n",
        "print('\u001b[1;32mDone! ✓')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "32gYIDDR1aCp"
      },
      "outputs": [],
      "source": [
        "#@title Setup 4/4: Upload your training images, 6 in total, all 512x512 cropped\n",
        "#@markdown ![Init](https://raw.githubusercontent.com/steinhaug/stable-diffusion/main/assets/training-images.png)\n",
        "#@markdown <br>Use [bulkimagecrop.com](https://bulkimagecrop.com/) and [birme.net](https://www.birme.net/?target_width=512&target_height=512&image_format=jpeg&quality_jpeg=99) to prepare your images.\n",
        "#@markdown <br>**Important!** This demo is assuming 6 (max 8) images so do not upload more as this only degrades everything. Unless doing the 2 image trick go against your gut feeling and use images from different settings and lightning, having different clothing is also better. But again, dont worry as I purposly removed any settings or controls so you cannot do anything anyway.. KISS - Keep it stupidly simple, use birme link above and continue.\n",
        "import os\n",
        "from google.colab import files\n",
        "import shutil\n",
        "\n",
        "for c in concepts_list:\n",
        "    print(f\"Uploading instance images for `{c['instance_prompt']}`\")\n",
        "    uploaded = files.upload()\n",
        "    for filename in uploaded.keys():\n",
        "        dst_path = os.path.join(c['instance_data_dir'], filename)\n",
        "        shutil.move(filename, dst_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e0xAX_SnbP1H"
      },
      "source": [
        "# PART 2.0: Install environment and start training\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZXboMUTN8eXB"
      },
      "source": [
        "What to do: Play the cells\n",
        "_Estimated time to complete: 30 minutes_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "aLWXPZqjsZVV"
      },
      "outputs": [],
      "source": [
        "#@markdown Install libraries and configure settings for training\n",
        "from IPython.display import clear_output\n",
        "from IPython.utils import capture\n",
        "from pathlib import Path\n",
        "from zipfile import ZipFile\n",
        "import time\n",
        "import os\n",
        "\n",
        "%cd /content\n",
        "!wget -q https://github.com/ShivamShrirao/diffusers/raw/main/examples/dreambooth/train_dreambooth.py\n",
        "!wget -q https://github.com/ShivamShrirao/diffusers/raw/main/scripts/convert_diffusers_to_original_stable_diffusion.py\n",
        "%pip install -qq git+https://github.com/ShivamShrirao/diffusers\n",
        "#%pip install -q -U triton\n",
        "#%pip install -q accelerate transformers ftfy bitsandbytes gradio natsort safetensors xformers\n",
        "\n",
        "#!yes | pip uninstall accelerate\n",
        "#!pip install accelerate==0.20.3\n",
        "#%pip install -U tensorflow==2.12.1\n",
        "\n",
        "%pip install -q -U triton\n",
        "%pip install -q accelerate\n",
        "%pip install -q transformers\n",
        "%pip install -q ftfy bitsandbytes\n",
        "%pip install -q gradio\n",
        "%pip install -q natsort safetensors\n",
        "%pip install -q xformers\n",
        "\n",
        "clear_output()\n",
        "print('\u001b[1;32mAll dependencies installed! ✓')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ooo_YjYV3fcQ"
      },
      "source": [
        "# PART 3.0: Train\n",
        "![Training](https://raw.githubusercontent.com/steinhaug/stable-diffusion/main/assets/notebook-training.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "jjcSXTp-u-Eg"
      },
      "outputs": [],
      "source": [
        "#@markdown Start training - eta: max 45 minutes...\n",
        "%cd /content\n",
        "clear_output()\n",
        "!python3 train_dreambooth.py \\\n",
        "  --pretrained_model_name_or_path=$MODEL_NAME \\\n",
        "  --pretrained_vae_name_or_path=\"stabilityai/sd-vae-ft-mse\" \\\n",
        "  --output_dir=$OUTPUT_DIR \\\n",
        "  --revision=\"main\" \\\n",
        "  --with_prior_preservation --prior_loss_weight=1.0 \\\n",
        "  --seed=1337 \\\n",
        "  --resolution=512 \\\n",
        "  --train_batch_size=1 \\\n",
        "  --train_text_encoder \\\n",
        "  --mixed_precision=\"fp16\" \\\n",
        "  --use_8bit_adam \\\n",
        "  --gradient_accumulation_steps=1 \\\n",
        "  --learning_rate=1e-6 \\\n",
        "  --lr_scheduler=\"constant\" \\\n",
        "  --lr_warmup_steps=0 \\\n",
        "  --num_class_images=75 \\\n",
        "  --sample_batch_size=4 \\\n",
        "  --max_train_steps=1000 \\\n",
        "  --save_interval=2000 \\\n",
        "  --save_sample_prompt=$SAMPLE_PROMPT \\\n",
        "  --concepts_list=\"concepts_list.json\"\n",
        "\n",
        "from IPython.display import Markdown\n",
        "training_complete_str = \"\"\"\n",
        "![Training complete!](https://raw.githubusercontent.com/steinhaug/stable-diffusion/main/assets/training-complete.jpg)\n",
        "\"\"\"\n",
        "display(Markdown(training_complete_str))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BCyzeaKdv58y"
      },
      "source": [
        "# PART 4.0: Configure and load your model, ready to create AI images\n",
        "![Systemstart](https://raw.githubusercontent.com/steinhaug/stable-diffusion/main/assets/notebook-startup.png)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bkDEu5OEGgYR"
      },
      "source": [
        "This part creates a checkpoint file and loads up the environment with the diffusers model ready for inference.\n",
        "\n",
        "_Estimated time to complete: 3 minute_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "gW15FjffdTID"
      },
      "outputs": [],
      "source": [
        "#@markdown Prepare inference and the Generative AI engine...\n",
        "reload_image = \"\"\"\n",
        "![Reload Setup 3/4 cell](https://raw.githubusercontent.com/steinhaug/stable-diffusion/main/assets/reload-cell-image-s.png)\n",
        "\"\"\"\n",
        "from IPython.display import Markdown\n",
        "def notify_reloader_cell():\n",
        "    try:\n",
        "        variable_value = OUTPUT_DIR\n",
        "    except KeyError:\n",
        "        display(Markdown(reload_image))\n",
        "        raise SystemExit()\n",
        "notify_reloader_cell()\n",
        "\n",
        "# - - - - - - -\n",
        "\n",
        "from slugify import slugify\n",
        "from IPython.display import clear_output\n",
        "import os\n",
        "\n",
        "WEIGHTS_DIR = OUTPUT_DIR + \"/1000\"\n",
        "\n",
        "#WEIGHTS_DIR = \"/content/drive/MyDrive/stable_diffusion_weights/x_espenne/1000\"\n",
        "\n",
        "CKPT_FILENAME = \"fp16-\" + slugify(YOUR_TOKEN + \" \" + TOKEN_GENDER) + \".ckpt\"\n",
        "CKPT_FILEPATH = WEIGHTS_DIR + \"/\" + CKPT_FILENAME\n",
        "\n",
        "if not os.path.exists(CKPT_FILEPATH):\n",
        "    print(f\"[*] Creating ckpt model....\")\n",
        "    !python convert_diffusers_to_original_stable_diffusion.py --model_path $WEIGHTS_DIR --checkpoint_path $CKPT_FILEPATH --half\n",
        "    print(f\"[*] ... .ckpt complete. Saved at {CKPT_FILEPATH}\")\n",
        "else:\n",
        "    print(f\"[*] .ckpt already exist. Saved at {CKPT_FILEPATH}\")\n",
        "\n",
        "import torch\n",
        "from torch import autocast\n",
        "from IPython.display import display\n",
        "\n",
        "model_path = WEIGHTS_DIR\n",
        "\n",
        "from diffusers import StableDiffusionPipeline\n",
        "pipe = StableDiffusionPipeline.from_pretrained(model_path, safety_checker=None, torch_dtype=torch.float16).to(\"cuda\")\n",
        "\n",
        "from diffusers import DDIMScheduler\n",
        "pipe.scheduler = DDIMScheduler.from_config(pipe.scheduler.config)\n",
        "\n",
        "pipe.enable_xformers_memory_efficient_attention()\n",
        "g_cuda = None\n",
        "\n",
        "g_cuda = torch.Generator(device='cuda')\n",
        "seed = 1\n",
        "g_cuda.manual_seed(seed)\n",
        "saved_file_count = 1;\n",
        "\n",
        "clear_output();\n",
        "print('\u001b[1;32mDone! ✓')\n",
        "print(f'.ckpt file location: {CKPT_FILEPATH}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "on9i_ums35pT"
      },
      "source": [
        "# PART 4.1: Auto-mode, time to create some AI Images... Press play\n",
        "![Bonus](https://raw.githubusercontent.com/steinhaug/stable-diffusion/main/assets/notebook-bonus.png)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "flFar9i6cstB"
      },
      "source": [
        "Before you try crafting your own prompt you can play the first cell below and I will create alot of AI Images for you so you can have some fun without needing to do pretty much anything :) Can't make it simpler than this to be honest!\n",
        "\n",
        "When this is done go to the next cell and you are ready to try out yourself, I have added a quick tutorial for you so you get the hang of it. What you need to know is that great images require some effort and skill in prompting so this is actually quite reqarding work when you start playing around with it. I will make more videoes with more tips here if people are interested, but for now! Lets see some AI Magic!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "RS-KIgLM8SaA"
      },
      "outputs": [],
      "source": [
        "#@markdown **AI-Automatic - Create some 100+  AI-Images from your brand new trained model**<br>\n",
        "#@markdown I have put together a little \"Avatar\"-bonus pack for you, press play and let it complete and check your Google Drive folder for the completed AI Images.<br><br>\n",
        "#@markdown Time to complete: around 30 minutes\n",
        "\n",
        "import os.path\n",
        "from os import path\n",
        "from IPython.display import display\n",
        "import ast\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "from slugify import slugify\n",
        "\n",
        "model_trained_steps_for_filename = 'auto'\n",
        "num_samples = 2\n",
        "images_savepath = '/content/drive/MyDrive/AutoAI-Images2'\n",
        "models = \"('\" + YOUR_TOKEN + \"','\" + YOUR_TOKEN + \" \" + TOKEN_GENDER + \"')\"\n",
        "\n",
        "n_override_width = None\n",
        "n_override_height = None\n",
        "n_override_seed = None\n",
        "n_override_guidance_scale = None\n",
        "n_override_inference_steps = None\n",
        "\n",
        "width = 512\n",
        "height = 512\n",
        "\n",
        "kista_trainednames = ast.literal_eval('[' + models + ']')\n",
        "\n",
        "if path.exists(images_savepath) == False:\n",
        "    os.mkdir(images_savepath)\n",
        "\n",
        "if TOKEN_GENDER == 'man':\n",
        "    auto_prompts = [\n",
        "        (\"warrior_poster\",696969,8.0,50,\n",
        "        \"poster of __token__ , (__token__:2.5) big chest, warrior god| standing alone on hill| centered| detailed gorgeous face| anime style| key visual| intricate detail| highly detailed| breathtaking| vibrant| panoramic| cinematic| Carne Griffiths| Conrad Roset| Makoto Shinkai\",\n",
        "        \"boobs| blurry| fuzzy| extra fingers| disfigured| cropped| bad fingers| deformed fingers| mutated fingers| out of frame\", 0\n",
        "        ),\n",
        "        (\"halloween_man_1\",2971107907,7.5,50,\n",
        "        \"The personification of the Halloween holiday played by (__ttoken__:1.95), portraited as a (__token__:1.5) with short hair and a villain's smile and a cute hat, cute cheeks, unreal engine, highly detailed, artgerm digital illustration, by Alexei Vinogradov bakery, sweets\",\n",
        "        \"bad anatomy, extra legs, extra arms, poorly drawn face, poorly drawn hands, poorly drawn feet, fat, disfigured, out of frame, long neck, poo art, bad hands, bad art, deformed, gun, double head, flowers,asian,hyperrealistic,child\", 33\n",
        "        ),\n",
        "        (\"warrior\",16,8.0,75,\n",
        "        \"__token__ as strong warrior prince| (__token__:2.5) |centered| key visual| intricate| highly detailed| breathtaking beauty| precise lineart| vibrant| comprehensive cinematic| Carne Griffiths| Conrad Roset\",\n",
        "        \"bad anatomy, extra legs, extra arms, poorly drawn face, poorly drawn hands, poorly drawn feet, fat, disfigured, out of frame, long neck, poo art, bad hands, bad art, deformed, gun, double head, flowers,asian,hyperrealistic,child\", 100\n",
        "        ),\n",
        "        (\"warrior_sketch\",16,8.0,75,\n",
        "        \"__token__ as strong warrior king| centered| key visual| intricate| highly detailed| breathtaking beauty| precise lineart| vibrant| comprehensive cinematic| Carne Griffiths| Conrad Roset\",\n",
        "        \"\", 100\n",
        "        ),\n",
        "        (\"warrior_sketch\",16,8.0,25,\n",
        "        \"__token__ as strong warrior prince| (__token__:2.5) |centered| key visual| intricate| highly detailed| breathtaking beauty| precise lineart| vibrant| comprehensive cinematic| Carne Griffiths| Conrad Roset\",\n",
        "        \"\", 0\n",
        "        ),\n",
        "        (\"punk_face\",422313768,7.5,50,\n",
        "        \"(__ttoken__:1.25), detailed (bladerunner:1.5) portrait of Punk (__token__:1.2), (__token__:2.5) |(standing hair line:2), Sheen Holographic Futuristic sci-fi fashion cyberpunk, neotokyo, synthwave, (aesthetics), futuristic, art by greg rutkowski Alexandros Pyromallis Nekro Rene Margitte\",\n",
        "        \"\", 0\n",
        "        ),\n",
        "        (\"Cyberpunked_1\",1654522787,7.5,50,\n",
        "        \"cyberpunk (__token__:1.5) in heavy raining futuristic tokyo rooftop cyberpunk night, sci-fi, __ttoken__ fantasy, (__token__:2.5) | intricate, very very beautiful, elegant, neon light, highly detailed, digital painting, artstation, concept art, soft light, hdri, smooth, sharp focus, illustration| art by tian zi| craig mullins| wlop| alphonse much\",\n",
        "        \"no words| watermark| bad anatomy| blurry| fuzzy| extra legs| extra arms| extra fingers| poorly drawn hands| poorly drawn feet| disfigured| out of frame| tiling| bad art| deformed| mutated| double face\", 0\n",
        "        ),\n",
        "        (\"Cyberpunked_2\",1654522787,8.0,50,\n",
        "        \"(__token__:2.0), cyberpunk, in heavy raining futuristic tokyo rooftop cyberpunk night, sci-fi, fantasy, intricate, (__token__:2.5) | very very beautiful, elegant, neon light, highly detailed, digital painting, artstation, concept art, soft light, hdri, smooth, sharp focus, illustration, art by tian zi and craig mullins and wlop and alphonse much\",\n",
        "        \"((missing arms)), ((missing legs)), (((extra arms))), (((extra legs))), (fused fingers), (too many fingers), (((long neck)))\", 0\n",
        "        ),\n",
        "        (\"Tarrot_card\",2001405895,7.0,50,\n",
        "        \"(__token__ squared head:2.0) on tarot card with intricate detailed frame around the outside | (__token__:2.5) side profile of cyberpunk body with cyborg skull | cyberpunk | styled in Art Nouveau | insanely detailed | embellishments | high definition | concept art | digital art | vibrant\",\n",
        "        \"((missing arms)), ((missing legs)), (((extra arms))), (((extra legs))), (fused fingers), (too many fingers), (((long neck)))\", 150\n",
        "        ),\n",
        "        (\"Tarrot_card\",2001405895,7.0,50,\n",
        "        \"(__token__:2.0) squared head on tarot card with intricate detailed frame around the outside | (__token__:2.5) side profile of cyberpunk body with cyborg skull | cyberpunk | styled in Art Nouveau | insanely detailed | embellishments | high definition | concept art | digital art | vibrant\",\n",
        "        \"\", 0\n",
        "        ),\n",
        "        (\"Cyborg\",558991465,8.0,50,\n",
        "        \"__token__ pixar portrait 8 k photo, beautiful shiny white rich galactic prima clowncore russian cyborg soldier boy, golden ratio details, (__token__:2.0) sci - fi, fantasy, cyberpunk, intricate, decadent, highly detailed, digital painting, ever after high, octane render, artstation, concept art, smooth, sharp focus, illustration, art by artgerm, loish, wlop\",\n",
        "        \"lowres| worst quality| low quality| normal quality| signature| blurry| bad anatomy| bad hands| missing fingers| extra digit| fewer digits| cropped\", 25\n",
        "        ),\n",
        "        (\"The_hippie\",2001405895,7.0,50,\n",
        "        \"full body render of an alluring god, (__token__:2.1)  as festival hippy with tribal tattoos surrounded by a underwater ink pour and flowing liquid gallium and sacred geometry, perfect body and face, sexy (__ttoken__:0.3), cinematic, beautifully lit, by miho hirano, by karol bak, by donato giancola, 3 d, trending on artstation, octane render, 8 k\",\n",
        "        \"lowres| worst quality| low quality| normal quality| signature| blurry| bad anatomy| bad hands| missing fingers| extra digit| fewer digits| cropped\", 0\n",
        "        ),\n",
        "        (\"Sango_dream_1\",428858956,7.0,60,\n",
        "        \"__token__, (__token__:2.0) sango fantasy, fantasy magic, intricate, sharp focus, illustration, highly detailed, digital painting, concept art, matte, Artgerm and Paul lewin and kehinde wiley, masterpiece\",\n",
        "        \"no words| watermark| bad anatomy| blurry| fuzzy| extra legs| extra arms| extra fingers| poorly drawn hands| poorly drawn feet| disfigured| out of frame| tiling| bad art| deformed| mutated| double face\", 100\n",
        "        ),\n",
        "        (\"Sango_dream_2\",4289232563,7.0,30,\n",
        "        \"__token__, (__token__:2.0) sango fantasy, fantasy magic, , intricate, sharp focus, illustration, highly detailed, digital painting, concept art, matte, Artgerm and Paul lewin and kehinde wiley, masterpiece\",\n",
        "        \"circles, bad anatomy| blurry| fuzzy| extra legs| extra arms| extra fingers| poorly drawn hands| poorly drawn feet| disfigured| out of frame| tiling| bad art| deformed| mutated| double face\", 25\n",
        "        )\n",
        "    ]\n",
        "else:\n",
        "    auto_prompts = [\n",
        "        (\"warrior_poster\",696969,8.0,50,\n",
        "        \"poster of __token__ , (__token__:2.5) big boobs, warrior goddess| standing alone on hill| centered| detailed gorgeous face| anime style| key visual| intricate detail| highly detailed| breathtaking| vibrant| panoramic| cinematic| Carne Griffiths| Conrad Roset| Makoto Shinkai\",\n",
        "        \"boobs| blurry| fuzzy| extra fingers| disfigured| cropped| bad fingers| deformed fingers| mutated fingers| out of frame\", 0\n",
        "        ),\n",
        "        (\"halloween_man_1\",2971107907,7.5,50,\n",
        "        \"The personification of the Halloween holiday played by (__ttoken__:0.95), portraited as a (__token__:0.5) with short hair and a villain's smile and a cute hat, cute cheeks, unreal engine, highly detailed, artgerm digital illustration, by Alexei Vinogradov bakery, sweets, emerald eyes\",\n",
        "        \"bad anatomy, extra legs, extra arms, poorly drawn face, poorly drawn hands, poorly drawn feet, fat, disfigured, out of frame, long neck, poo art, bad hands, bad art, deformed, gun, double head, flowers,asian,hyperrealistic,child\", 33\n",
        "        ),\n",
        "        (\"warrior\",16,8.0,75,\n",
        "        \"__token__ as strong warrior princess| (__token__:2.5) |centered| key visual| intricate| highly detailed| breathtaking beauty| precise lineart| vibrant| comprehensive cinematic| Carne Griffiths| Conrad Roset\",\n",
        "        \"bad anatomy, extra legs, extra arms, poorly drawn face, poorly drawn hands, poorly drawn feet, fat, disfigured, out of frame, long neck, poo art, bad hands, bad art, deformed, gun, double head, flowers,asian,hyperrealistic,child\", 100\n",
        "        ),\n",
        "        (\"warrior_sketch\",16,8.0,75,\n",
        "        \"__token__ as strong warrior queen| centered| key visual| intricate| highly detailed| breathtaking beauty| precise lineart| vibrant| comprehensive cinematic| Carne Griffiths| Conrad Roset\",\n",
        "        \"\", 100\n",
        "        ),\n",
        "        (\"warrior_sketch\",16,8.0,25,\n",
        "        \"__token__ as strong warrior princess| (__token__:2.5) |centered| key visual| intricate| highly detailed| breathtaking beauty| precise lineart| vibrant| comprehensive cinematic| Carne Griffiths| Conrad Roset\",\n",
        "        \"\", 0\n",
        "        ),\n",
        "        (\"punk_face\",422313768,7.5,50,\n",
        "        \"(__ttoken__:1.25), detailed (bladerunner:1.5) portrait of Punk (__token__:1.2), (__token__:2.5) |(standing hair line:2), Sheen Holographic Futuristic sci-fi fashion cyberpunk, neotokyo, synthwave, (aesthetics), futuristic, art by greg rutkowski Alexandros Pyromallis Nekro Rene Margitte\",\n",
        "        \"\", 0\n",
        "        ),\n",
        "        (\"Cyberpunked_1\",1654522787,7.5,50,\n",
        "        \"cyberpunk (__token__:1.5) in heavy raining futuristic tokyo rooftop cyberpunk night, sci-fi, __ttoken__ fantasy, (__token__:2.5) | intricate, very very beautiful, elegant, neon light, highly detailed, digital painting, artstation, concept art, soft light, hdri, smooth, sharp focus, illustration| art by tian zi| craig mullins| wlop| alphonse much\",\n",
        "        \"no words| watermark| bad anatomy| blurry| fuzzy| extra legs| extra arms| extra fingers| poorly drawn hands| poorly drawn feet| disfigured| out of frame| tiling| bad art| deformed| mutated| double face\", 0\n",
        "        ),\n",
        "        (\"Cyberpunked_2\",1654522787,8.0,50,\n",
        "        \"(__token__:2.0), cyberpunk, in heavy raining futuristic tokyo rooftop cyberpunk night, sci-fi, fantasy, intricate, (__token__:2.5) | very very beautiful, elegant, neon light, highly detailed, digital painting, artstation, concept art, soft light, hdri, smooth, sharp focus, illustration, art by tian zi and craig mullins and wlop and alphonse much\",\n",
        "        \"((missing arms)), ((missing legs)), (((extra arms))), (((extra legs))), (fused fingers), (too many fingers), (((long neck)))\", 0\n",
        "        ),\n",
        "        (\"Tarrot_card\",2001405895,7.0,50,\n",
        "        \"(__token__ squared head:2.0) on tarot card with intricate detailed frame around the outside | (__token__:2.5) side profile of cyberpunk body with cyborg skull | cyberpunk | styled in Art Nouveau | insanely detailed | embellishments | high definition | concept art | digital art | vibrant\",\n",
        "        \"((missing arms)), ((missing legs)), (((extra arms))), (((extra legs))), (fused fingers), (too many fingers), (((long neck)))\", 150\n",
        "        ),\n",
        "        (\"Tarrot_card\",2001405895,7.0,50,\n",
        "        \"(__token__:2.0) squared head on tarot card with intricate detailed frame around the outside | (__token__:2.5) side profile of cyberpunk body with cyborg skull | cyberpunk | styled in Art Nouveau | insanely detailed | embellishments | high definition | concept art | digital art | vibrant\",\n",
        "        \"\", 0\n",
        "        ),\n",
        "        (\"Cyborg\",558991465,8.0,50,\n",
        "        \"__token__ pixar portrait 8 k photo, beautiful shiny white rich galactic prima clowncore russian cyborg college girl, golden ratio details, (__token__:2.0) sci - fi, fantasy, cyberpunk, intricate, decadent, highly detailed, digital painting, ever after high, octane render, artstation, concept art, smooth, sharp focus, illustration, art by artgerm, loish, wlop\",\n",
        "        \"lowres| worst quality| low quality| normal quality| signature| blurry| bad anatomy| bad hands| missing fingers| extra digit| fewer digits| cropped\", 25\n",
        "        ),\n",
        "        (\"The_hippie\",2001405895,7.0,50,\n",
        "        \"full body render of an alluring goddess, (__token__:2.1)  as festival hippy with tribal tattoos surrounded by a underwater ink pour and flowing liquid gallium and sacred geometry, perfect body and face, sexy (__ttoken__:0.3), cinematic, beautifully lit, by miho hirano, by karol bak, by donato giancola, 3 d, trending on artstation, octane render, 8 k\",\n",
        "        \"lowres| worst quality| low quality| normal quality| signature| blurry| bad anatomy| bad hands| missing fingers| extra digit| fewer digits| cropped\", 0\n",
        "        ),\n",
        "        (\"Sango_dream_1\",428858956,7.0,60,\n",
        "        \"__token__, (__token__:2.0) sango fantasy, fantasy magic, intricate, sharp focus, illustration, highly detailed, digital painting, concept art, matte, Artgerm and Paul lewin and kehinde wiley, masterpiece\",\n",
        "        \"no words| watermark| bad anatomy| blurry| fuzzy| extra legs| extra arms| extra fingers| poorly drawn hands| poorly drawn feet| disfigured| out of frame| tiling| bad art| deformed| mutated| double face\", 100\n",
        "        ),\n",
        "        (\"Sango_dream_2\",4289232563,7.0,30,\n",
        "        \"__token__, (__token__:2.0) sango fantasy, fantasy magic, intricate, sharp focus, illustration, highly detailed, digital painting, concept art, matte, Artgerm and Paul lewin and kehinde wiley, masterpiece\",\n",
        "        \"circles, bad anatomy| blurry| fuzzy| extra legs| extra arms| extra fingers| poorly drawn hands| poorly drawn feet| disfigured| out of frame| tiling| bad art| deformed| mutated| double face\", 25\n",
        "        )\n",
        "    ]\n",
        "\n",
        "autoresolutions = [\n",
        "    (512,512,256,256,2), (512,1080,128,270,2), (512,768,128,192,2), (512,768,128,192,2), (768,512,192,128,2), (1536,512,384,128,1)\n",
        "]\n",
        "\n",
        "print(f\"[*] All AI-Images are saved to your Google Drive in the folder: AI-Images \")\n",
        "print(f\"[*] . \")\n",
        "\n",
        "for width, height, scaleWidth, scaleHeight, num_samples in autoresolutions:\n",
        "    print(f\"[*] Generating images in {width} x {height}.... \")\n",
        "    print(f\"[*] .. displaying thumbnails of completed images...\")\n",
        "    for prompt_ref,seed,guidance_scale,num_inference_steps,prompt,negative_prompt,filter_x in auto_prompts:\n",
        "        for modelref,kista_modelname in kista_trainednames:\n",
        "            if width == 1536:\n",
        "                if filter_x == 0:\n",
        "                    continue;\n",
        "                num_inference_steps = filter_x\n",
        "            torch.cuda.empty_cache()\n",
        "            newprompt = prompt.replace(\"__token__\", kista_modelname)\n",
        "            newprompt = newprompt.replace(\"__ttoken__\", YOUR_TOKEN)\n",
        "\n",
        "            if n_override_seed:\n",
        "                seed = n_override_seed\n",
        "\n",
        "            g_cuda = torch.Generator(device='cuda')\n",
        "            g_cuda.manual_seed(seed)\n",
        "\n",
        "            if n_override_height:\n",
        "                height = n_override_height\n",
        "            if n_override_width:\n",
        "                width = n_override_width\n",
        "            if n_override_inference_steps:\n",
        "                num_inference_steps = n_override_inference_steps\n",
        "            if n_override_guidance_scale:\n",
        "                guidance_scale = n_override_guidance_scale\n",
        "            with autocast(\"cuda\"), torch.inference_mode():\n",
        "                images = pipe(\n",
        "                    newprompt,\n",
        "                    height=height,\n",
        "                    width=width,\n",
        "                    negative_prompt=negative_prompt,\n",
        "                    num_images_per_prompt=num_samples,\n",
        "                    num_inference_steps=num_inference_steps,\n",
        "                    guidance_scale=guidance_scale,\n",
        "                    generator=g_cuda\n",
        "                ).images\n",
        "            image_filenames = []\n",
        "            for img in images:\n",
        "                prefix_count = '_' + f'{saved_file_count:04d}'\n",
        "                final_id = 's' + model_trained_steps_for_filename + 'g' + f'{guidance_scale:01f}' + 'i' + f'{num_inference_steps:03d}' + 's' + f'{seed}'\n",
        "                outfilename = prompt_ref + '_' + modelref + '_' + final_id.replace(\".\", '') + prefix_count\n",
        "                image_filename = slugify(outfilename.replace(\" \", '_').replace(\"00000i\", 'i')) + '.png'\n",
        "                img.save(images_savepath + \"/\" + image_filename)\n",
        "                if \"write_exif_tags\" in globals() and callable(globals()[\"write_exif_tags\"]):\n",
        "                    params = f\"Steps: {num_inference_steps}, Width: {width}, Height: {height}, Seed: {seed}, Guidance: {guidance_scale}\" \n",
        "                    write_exif_tags(images_savepath + \"/\" + image_filename, newprompt, negative_prompt, params)\n",
        "                image_filenames.append(image_filename)\n",
        "                saved_file_count += 1\n",
        "            image_folder = images_savepath + '/'\n",
        "            grid_row = 1\n",
        "            grid_col = len(image_filenames)\n",
        "            grid_scale = 3\n",
        "            if grid_col > 1:\n",
        "                fig, axes = plt.subplots(grid_row, grid_col, figsize=(grid_col*grid_scale, grid_row*grid_scale), gridspec_kw={'hspace': 0, 'wspace': 0})\n",
        "                for j, image_filename in enumerate(image_filenames):\n",
        "                    currAxes = axes[j]\n",
        "                    currAxes.set_title(f\"{image_filename[0:5]}\")\n",
        "                    image_full_path = os.path.join(image_folder, image_filename)\n",
        "                    imgdata = mpimg.imread(image_full_path)\n",
        "                    currAxes.imshow(imgdata, cmap='gray')\n",
        "                    currAxes.axis('off')\n",
        "                plt.tight_layout()\n",
        "                plt.savefig('grid.png', dpi=72)\n",
        "                plt.show()\n",
        "            else:\n",
        "                display(img.resize((scaleWidth, scaleHeight)))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install exiftool\n",
        "from IPython.display import clear_output\n",
        "print(f\"▶️ Installing Exiftool\")\n",
        "!wget https://exiftool.org/Image-ExifTool-12.77.tar.gz\n",
        "!tar -xzvf /content/Image-ExifTool-12.77.tar.gz\n",
        "%cd Image-ExifTool-12.77\n",
        "!perl Makefile.PL\n",
        "!make test\n",
        "!sudo make install\n",
        "\n",
        "exiftool_config = '''%Image::ExifTool::UserDefined = (\n",
        "    'Image::ExifTool::PNG::TextualData' => {\n",
        "        workflow => { },\n",
        "        Parameters => { },\n",
        "        Prompt => { },\n",
        "        NegativePrompt => { }\n",
        "    }\n",
        ");'''\n",
        "with open('/content/exiftool.config', 'w+') as fw:\n",
        "    fw.write(str(exiftool_config))\n",
        "\n",
        "def write_exif_tags(png_file, Prompt, NegativePrompt, Parameters=''):\n",
        "    Prompt = Prompt.replace(\"\\\"\", \"\\\\\\\"\")\n",
        "    NegativePrompt = NegativePrompt.replace(\"\\\"\", \"\\\\\\\"\")\n",
        "    bck_file = f\"{png_file}_original\"\n",
        "    if len(str(Parameters)):\n",
        "        !exiftool -config /content/exiftool.config \"-Prompt=$Prompt\" \"-NegativePrompt=$NegativePrompt\" \"-Parameters=$Parameters\" $png_file\n",
        "    else:\n",
        "        !exiftool -config /content/exiftool.config \"-Prompt=$Prompt\" \"-NegativePrompt=$NegativePrompt\" $png_file\n",
        "    !rm -Rf $bck_file\n",
        "print(f\"☑️ Exiftool installed\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "soBvoD4e4GlU"
      },
      "source": [
        "# PART 4.2: Manual - Create AI images by prompt\n",
        "![AI Prompt](https://raw.githubusercontent.com/steinhaug/stable-diffusion/main/assets/notebook-create-images.png)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "7Re4co4kWLHx"
      },
      "outputs": [],
      "source": [
        "#@markdown Prompt instructions AKA your mini helper. Press play to output FAQ.\n",
        "print(\"The prompt, this is where you describe what you want to see. You could say An astrounaut riding a horse, boom you got it. You could add in Salvador Dali style and voila - AI magic right there. Infact there are almost 2500 artists understood in this AI model by default so just experiment and try out some ideas... Its free!\")\n",
        "print(\"\")\n",
        "print(\"To have yourself in the image use the label __token__. Here is an example prompt you can try:\")\n",
        "print(\"prompt: __token__ as magician, highly saturated colors, concept art, Dan Mumford, Lucas Cranach the Elder,mythological painting,german renaissance\")\n",
        "print(\"\")\n",
        "print(\"Its very common that you get some extra fingers, an extra arm here and there so what you often need to use is what is called the negative prompt. Basically this is instructing the AI for what NOT to have in the finnished image. So given the prompt example I gave you a great negative prompt would be this:\")\n",
        "print(\"Negative prompt: blurry| fuzzy| extra fingers| disfigured| cropped| bad fingers| deformed fingers| mutated fingers\")\n",
        "print(\"\")\n",
        "print(\"NB! Note that the negative prompt has a clear impact on the final image, as something like adding \\\"mutated fingers\\\" instructs the AI to make sure that the images does show fingers - however - not mutated...\")\n",
        "print(\"Looking to upscale your images, windows users: https://www.upscayl.org/\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "K6xoHWSsbcS3",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "#@markdown **AI-Manual - Quick mode**\n",
        "from slugify import slugify\n",
        "from os import path\n",
        "prompt = \"Photo of (__token__:3) \" #@param {type:\"string\"}\n",
        "negative_prompt = \"blurry, out of focus, missing head, full body\" #@param {type:\"string\"}\n",
        "token_name = YOUR_TOKEN + \" \" + TOKEN_GENDER + \", \" + YOUR_TOKEN\n",
        "num_samples = 1\n",
        "guidance_scale = 7.5\n",
        "num_inference_steps = 50\n",
        "width = \"512\"\n",
        "height = \"512\"\n",
        "width = int(width)\n",
        "height = int(height)\n",
        "new_seed = None\n",
        "save_images_path = \"/content/drive/MyDrive/AI-Images-Manual\"\n",
        "\n",
        "if path.exists(save_images_path) == False:\n",
        "  os.mkdir(save_images_path)\n",
        "\n",
        "x = token_name.split(\",\")\n",
        "for index, value in enumerate(x):\n",
        "    if index == 0:\n",
        "        prompt = prompt.replace(\"__token__\", value)\n",
        "    else:\n",
        "        prompt = prompt.replace(\"__token\" + str(index) + \"__\", value)\n",
        "\n",
        "if new_seed:\n",
        "    g_cuda = torch.Generator(device='cuda')\n",
        "    g_cuda.manual_seed(new_seed)\n",
        "\n",
        "if len(save_images_path):\n",
        "    tmp = save_images_path.split(\"/\")\n",
        "    if len(tmp) == 1:\n",
        "        save_images_path = \"/content/\" + save_images_path\n",
        "    from pathlib import Path\n",
        "    path = Path(save_images_path)\n",
        "    if not path.exists():\n",
        "        print(f\"[*] Create save directory...\")\n",
        "        path.mkdir(parents = False, exist_ok = False)\n",
        "    try:\n",
        "        if not image_save_count:\n",
        "            print('Darn we need this one!')\n",
        "    except NameError:\n",
        "        image_save_count = 1\n",
        "\n",
        "print(f\"[*] Prompt used: {prompt}\")\n",
        "\n",
        "with autocast(\"cuda\"), torch.inference_mode():\n",
        "    images = pipe(\n",
        "        prompt,\n",
        "        height=height,\n",
        "        width=width,\n",
        "        negative_prompt=negative_prompt,\n",
        "        num_images_per_prompt=num_samples,\n",
        "        num_inference_steps=num_inference_steps,\n",
        "        guidance_scale=guidance_scale,\n",
        "        generator=g_cuda\n",
        "    ).images\n",
        "\n",
        "for img in images:\n",
        "    display(img)\n",
        "    if len(save_images_path):\n",
        "        precount = f'{image_save_count:04d}'\n",
        "        #image_filename = slugify(precount + '_' + prompt.replace(\" \", '_')[:240]) + '.png'\n",
        "        image_filename = slugify(prompt.replace(\" \", '_')[:16] + \"_\")  + precount + '_' + prompt.replace(\" \", '_')[:200]) + '.png'\n",
        "        img.save(save_images_path + \"/\" + image_filename)\n",
        "        if \"write_exif_tags\" in globals() and callable(globals()[\"write_exif_tags\"]):\n",
        "            params = f\"Steps: {num_inference_steps}, Width: {width}, Height: {height}, Seed: {custom_seed}, Guidance: {guidance_scale}\" \n",
        "            write_exif_tags(save_images_path + \"/\" + image_filename, prompt, negative_prompt, params)\n",
        "        image_save_count += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "o6PImRrLCn8N"
      },
      "outputs": [],
      "source": [
        "#@markdown **AI-Manual - All options mode**\n",
        "from slugify import slugify\n",
        "prompt = \"The personification of the Halloween holiday played by (__ttoken__:1.95), portraited as a (__token__:1.5) with short hair and a villain's smile and a cute hat, cute cheeks, unreal engine, highly detailed, artgerm digital illustration, by Alexei Vinogradov bakery, sweets\" #@param {type:\"string\"}\n",
        "negative_prompt = \"bad anatomy, extra legs, extra arms, poorly drawn face, poorly drawn hands, poorly drawn feet, fat, disfigured, out of frame, long neck, poo art, bad hands, bad art, deformed, gun, double head, flowers,asian,hyperrealistic,child\" #@param {type:\"string\"}\n",
        "token_name = YOUR_TOKEN + \" \" + TOKEN_GENDER + \", \" + YOUR_TOKEN\n",
        "num_samples = 2 #@param {type:\"number\"}\n",
        "guidance_scale = 7.5 #@param {type:\"number\"}\n",
        "num_inference_steps = 50 #@param {type:\"number\"}\n",
        "width = \"512\" #@param [\"512\", \"768\", \"1280\", \"1536\"] {allow-input: true}\n",
        "height = \"768\" #@param [\"512\", \"768\", \"1280\", \"1536\"] {allow-input: true}\n",
        "width = int(width)\n",
        "height = int(height)\n",
        "custom_seed = None #@param {type:\"number\"}\n",
        "new_seed = custom_seed\n",
        "save_images_path = \"/content/drive/MyDrive/AI-Images-Manual\"\n",
        "\n",
        "#prompt = prompt.replace(\"__token__\", token_name)\n",
        "\n",
        "x = token_name.split(\",\")\n",
        "for index, value in enumerate(x):\n",
        "    if index == 0:\n",
        "        prompt = prompt.replace(\"__token__\", value)\n",
        "    else:\n",
        "        prompt = prompt.replace(\"__token\" + str(index) + \"__\", value)\n",
        "\n",
        "#raise Exception(1);\n",
        "\n",
        "if num_samples > 1:\n",
        "    print(\"You may need to scroll to see the rest of the images as they appear...\")\n",
        "\n",
        "if new_seed:\n",
        "    g_cuda = torch.Generator(device='cuda')\n",
        "    g_cuda.manual_seed(new_seed)\n",
        "\n",
        "if len(save_images_path):\n",
        "    tmp = save_images_path.split(\"/\")\n",
        "    if len(tmp) == 1:\n",
        "        save_images_path = \"/content/\" + save_images_path\n",
        "    from pathlib import Path\n",
        "    path = Path(save_images_path)\n",
        "    if not path.exists():\n",
        "        print(f\"[*] Create save directory...\")\n",
        "        path.mkdir(parents = False, exist_ok = False)\n",
        "    try:\n",
        "        if not image_save_count:\n",
        "            print('Darn we need this one!')\n",
        "    except NameError:\n",
        "        image_save_count = 1\n",
        "\n",
        "print(f\"[*] Prompt used: {prompt}\")\n",
        "\n",
        "with autocast(\"cuda\"), torch.inference_mode():\n",
        "    images = pipe(\n",
        "        prompt,\n",
        "        height=height,\n",
        "        width=width,\n",
        "        negative_prompt=negative_prompt,\n",
        "        num_images_per_prompt=num_samples,\n",
        "        num_inference_steps=num_inference_steps,\n",
        "        guidance_scale=guidance_scale,\n",
        "        generator=g_cuda\n",
        "    ).images\n",
        "\n",
        "for img in images:\n",
        "    display(img)\n",
        "    if len(save_images_path):\n",
        "        precount = f'{image_save_count:04d}'\n",
        "        image_filename = slugify(prompt.replace(\" \", '_')[:16] + \"_\")  + precount + '_' + prompt.replace(\" \", '_')[:200]) + '.png'\n",
        "        img.save(save_images_path + \"/\" + image_filename)\n",
        "        if \"write_exif_tags\" in globals() and callable(globals()[\"write_exif_tags\"]):\n",
        "            params = f\"Steps: {num_inference_steps}, Width: {width}, Height: {height}, Seed: {custom_seed}, Guidance: {guidance_scale}\" \n",
        "            write_exif_tags(save_images_path + \"/\" + image_filename, prompt, negative_prompt, params)\n",
        "        image_save_count += 1\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B5jbpxx_eeAj"
      },
      "source": [
        "# Part 5.0: Huggingface connect - upload and save your model for later use\n",
        "![Save](https://raw.githubusercontent.com/steinhaug/stable-diffusion/main/assets/notebook-save.png)\n",
        "<br>\n",
        "Time to complete: ca. 15 minutes\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "K0BchFE5dfez"
      },
      "outputs": [],
      "source": [
        "#@markdown **Upload and save your model to Huggingface.co**<br>\n",
        "#@markdown Your diffusers and checkpoint model is already saved in your Google Drive, <br>\n",
        "#@markdown however you can save the model for free at Huggingface.\n",
        "#@markdown This way you can free up your Google Drive space.\n",
        "\n",
        "reload_image = \"\"\"\n",
        "![Reload Setup 3/4 cell](https://raw.githubusercontent.com/steinhaug/stable-diffusion/main/assets/reload-cell-image-s.png)\n",
        "\"\"\"\n",
        "from IPython.display import Markdown\n",
        "def notify_reloader_cell():\n",
        "    try:\n",
        "        variable_value = YOUR_TOKEN\n",
        "    except KeyError:\n",
        "        display(Markdown(reload_image))\n",
        "        raise SystemExit()\n",
        "notify_reloader_cell()\n",
        "\n",
        "# - - - - - - -\n",
        "\n",
        "\n",
        "from slugify import slugify\n",
        "from huggingface_hub import HfApi, HfFolder, CommitOperationAdd\n",
        "from huggingface_hub import create_repo\n",
        "from IPython.display import display_markdown\n",
        "from IPython.display import clear_output\n",
        "from IPython.utils import capture\n",
        "from google.colab import files\n",
        "import shutil\n",
        "import time\n",
        "import os\n",
        "\n",
        "Create_repo = True\n",
        "hf_token_write = HUGGINGFACE_TOKEN\n",
        "Name_of_your_concept = YOUR_TOKEN\n",
        "\n",
        "Name_of_your_concept=Name_of_your_concept.replace(\" \",\"-\")\n",
        "hf_token = hf_token_write\n",
        "\n",
        "if not len(hf_token_write):\n",
        "    hf_token = HUGGINGFACE_TOKEN\n",
        "\n",
        "api = HfApi()\n",
        "your_username = api.whoami(token=hf_token)[\"name\"]\n",
        "repo_id = f\"{your_username}/{slugify(Name_of_your_concept)}\"\n",
        "\n",
        "print(\"\u001b[1;32mPreparing files...\")\n",
        "\n",
        "UPLOAD_DIR = \"/content/temp\"\n",
        "os.makedirs(UPLOAD_DIR, exist_ok=True)\n",
        "%cd $UPLOAD_DIR\n",
        "\n",
        "#!rm -r safety_checker feature_extractor .git\n",
        "#!rm model_index.json\n",
        "#!git init\n",
        "#!git lfs install --system --skip-repo\n",
        "#!git remote add -f origin  \"https://USER:{hf_token}@huggingface.co/runwayml/stable-diffusion-v1-5\"\n",
        "#!git config core.sparsecheckout true\n",
        "#!echo -e \"feature_extractor\\nsafety_checker\\nmodel_index.json\" > .git/info/sparse-checkout\n",
        "#!git pull origin main\n",
        "#!rm -r .git\n",
        "#%cd /content\n",
        "\n",
        "for c in concepts_list:\n",
        "    tmpInstancePrompt = c[\"instance_prompt\"]\n",
        "    tmpClassPrompt = c[\"class_prompt\"]\n",
        "    tmpImgCount = str(ret_directoryFileCount(c[\"instance_data_dir\"]))\n",
        "\n",
        "readme_text = f'''---\n",
        "license: mit\n",
        "---\n",
        "## Dreambooth for people in a hurry - Colab edition\n",
        "\n",
        "The Stable-Diffusion-v1-5 checkpoint is used as base model, and trained with custom concept.\n",
        "\n",
        "### Concept info\n",
        "\n",
        "Your full token: <b>{YOUR_TOKEN} {TOKEN_GENDER}</b>\n",
        "Example prompt: Professional headshot photo of {YOUR_TOKEN} {TOKEN_GENDER} as a magician, Tiffen Digital Diffusion / FX, 100mm\n",
        "\n",
        "Instance prompt: {tmpInstancePrompt}\n",
        "Class prompt: {tmpClassPrompt}\n",
        "\n",
        "### Model info\n",
        "\n",
        "Training images: {tmpImgCount}\n",
        "Regularization images: 50\n",
        "Model type: Diffusers, Checkpoint\n",
        "\n",
        "training_steps: 1000\n",
        "lr_scheduler: constant\n",
        "lr_warmup_steps: 0\n",
        "learning rate: 1e-6\n",
        "mixed_precision: fp16\n",
        "\n",
        "'''\n",
        "\n",
        "\n",
        "if Create_repo:\n",
        "    create_repo(repo_id,private=True, token=hf_token)\n",
        "\n",
        "    readme_file = open(\"README.md\", \"w\")\n",
        "    readme_file.write(readme_text)\n",
        "    readme_file.close()\n",
        "    operations = [\n",
        "      CommitOperationAdd(path_in_repo=\"README.md\", path_or_fileobj=\"README.md\")\n",
        "    ]\n",
        "    api.create_commit(\n",
        "      repo_id=repo_id,\n",
        "      operations=operations,\n",
        "      commit_message=f\"Init new diffusers repo\",\n",
        "      token=hf_token\n",
        "    )\n",
        "\n",
        "clear_output()\n",
        "print('Repo created, ready for file upload...')\n",
        "\n",
        "#\n",
        "# Part 2\n",
        "#\n",
        "\n",
        "from IPython.display import clear_output; clear_output();\n",
        "from slugify import slugify\n",
        "from huggingface_hub import HfApi, HfFolder, CommitOperationAdd\n",
        "from huggingface_hub import create_repo\n",
        "from IPython.display import display_markdown\n",
        "from IPython.display import clear_output\n",
        "from IPython.utils import capture\n",
        "from google.colab import files\n",
        "import shutil\n",
        "import time\n",
        "import os\n",
        "\n",
        "%cd /content/\n",
        "\n",
        "WPATH = OUTPUT_DIR + \"/1000/\"\n",
        "\n",
        "operations = [\n",
        "    CommitOperationAdd(path_in_repo=CKPT_FILENAME,path_or_fileobj=CKPT_FILEPATH)\n",
        "]\n",
        "api.create_commit(\n",
        "    repo_id=repo_id,\n",
        "    operations=operations,\n",
        "    commit_message=f\"Added checkpoint model.\",\n",
        "    token=hf_token\n",
        ")\n",
        "\n",
        "if os.path.isdir(WPATH + 'feature_extractor'):\n",
        "    api.upload_folder(\n",
        "        folder_path = WPATH + 'feature_extractor',\n",
        "        path_in_repo=\"feature_extractor\",\n",
        "        repo_id=repo_id, token=hf_token\n",
        "    )\n",
        "\n",
        "api.upload_folder(\n",
        "    folder_path=WPATH + 'scheduler',\n",
        "    path_in_repo=\"scheduler\",\n",
        "    repo_id=repo_id, token=hf_token\n",
        ")\n",
        "api.upload_folder(\n",
        "    folder_path=WPATH + 'text_encoder',\n",
        "    path_in_repo=\"text_encoder\",\n",
        "    repo_id=repo_id, token=hf_token\n",
        ")\n",
        "api.upload_folder(\n",
        "    folder_path=WPATH + 'tokenizer',\n",
        "    path_in_repo=\"tokenizer\",\n",
        "    repo_id=repo_id, token=hf_token\n",
        ")\n",
        "api.upload_folder(\n",
        "    folder_path=WPATH + 'unet',\n",
        "    path_in_repo=\"unet\",\n",
        "    repo_id=repo_id, token=hf_token\n",
        ")\n",
        "api.upload_folder(\n",
        "    folder_path=WPATH + 'vae',\n",
        "    path_in_repo=\"vae\",\n",
        "    repo_id=repo_id, token=hf_token\n",
        ")\n",
        "api.upload_folder(\n",
        "    folder_path=WPATH + 'unet',\n",
        "    path_in_repo=\"unet\",\n",
        "    repo_id=repo_id, token=hf_token\n",
        ")\n",
        "api.upload_folder(\n",
        "    folder_path=WPATH + 'vae',\n",
        "    path_in_repo=\"vae\",\n",
        "    repo_id=repo_id, token=hf_token\n",
        ")\n",
        "\n",
        "for c in concepts_list:\n",
        "    api.upload_folder(\n",
        "        folder_path=c[\"instance_data_dir\"],\n",
        "        path_in_repo=\"/dataset/training-images/\",\n",
        "        repo_id=repo_id, token=hf_token\n",
        "    )\n",
        "    api.upload_folder(\n",
        "        folder_path=c[\"class_data_dir\"],\n",
        "        path_in_repo=\"/dataset/regularization-images/\",\n",
        "        repo_id=repo_id, token=hf_token\n",
        "    )\n",
        "\n",
        "MODEL2 = WPATH + 'args.json'\n",
        "MODEL3 = WPATH + 'model_index.json'\n",
        "operations = [\n",
        "    CommitOperationAdd(path_in_repo=\"args.json\",path_or_fileobj=MODEL2),\n",
        "    CommitOperationAdd(path_in_repo=\"model_index.json\",path_or_fileobj=MODEL3)\n",
        "]\n",
        "api.create_commit(\n",
        "    repo_id=repo_id,\n",
        "    operations=operations,\n",
        "    commit_message=f\"Added my diffusers model, 1000 steps.\",\n",
        "    token=hf_token\n",
        ")\n",
        "\n",
        "import os\n",
        "if os.path.exists('/content/drive/MyDrive/AutoAI-Images'):\n",
        "    file_count = ret_directoryFileCount('/content/drive/MyDrive/AutoAI-Images')\n",
        "    if file_count:\n",
        "        api.upload_folder(\n",
        "            folder_path='/content/drive/MyDrive/AutoAI-Images',\n",
        "            path_in_repo=\"sample-images/AutoAI\",\n",
        "            repo_id=repo_id, token=hf_token\n",
        "        )\n",
        "\n",
        "clear_output();\n",
        "print('\u001b[1;32mModel succesfully uploaded to Huggingface. ✓')\n",
        "display_markdown(f'''## Model link: [huggingface repository](https://huggingface.co/{repo_id})\n",
        "''', raw=True)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "G0NV324ZcL9L",
        "qn5ILIyDJIcX",
        "PFHw44XMhlg6",
        "B5jbpxx_eeAj"
      ],
      "gpuType": "V100",
      "include_colab_link": true,
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "2.7.16 (default, Oct 10 2019, 22:02:15) \n[GCC 8.3.0]"
    },
    "vscode": {
      "interpreter": {
        "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
