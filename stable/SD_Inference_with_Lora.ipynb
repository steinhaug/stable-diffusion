{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMrTn/aVOExDCM6fxTrEgop",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/steinhaug/stable-diffusion/blob/main/stable/SD_Inference_with_Lora.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cKFwCsyrLyUK",
        "outputId": "53c387a9-e81d-49dc-fb2a-b81edaa02567"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "HF_TOKEN = userdata.get('HF_TOKEN')\n",
        "\n",
        "!huggingface-cli login --token {HF_TOKEN}\n",
        "from huggingface_hub import snapshot_download"
      ],
      "metadata": {
        "id": "CZswdd6ML7o_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@ markdown Download image sets\n",
        "import os\n",
        "SAVE_PATH = '/content/drive/MyDrive/models/SD'\n",
        "REPO_ID = 'stablediffusionapi/deliberate-v2'\n",
        "os.makedirs(f\"{SAVE_PATH}/{REPO_ID}\", exist_ok=True)\n",
        "path = snapshot_download(repo_id=REPO_ID, repo_type=\"model\", revision=\"main\", local_dir=f\"{SAVE_PATH}/{REPO_ID}\", local_dir_use_symlinks=False)"
      ],
      "metadata": {
        "id": "Ric34lrYL9e1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Install deps"
      ],
      "metadata": {
        "id": "_yMK6svbQINP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install accelerate\n",
        "!pip install peft\n",
        "!pip install -U git+https://github.com/huggingface/diffusers.git@main"
      ],
      "metadata": {
        "id": "IrXs2bSPP3iK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Inference"
      ],
      "metadata": {
        "id": "e1dIBiDGQK8A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "__Load LoRA using Diffusers LoraLoaderMixin__  \n",
        "Assume we have the LoRA file in safetensor file format, to load LoRA using Diffusers is as easy as this."
      ],
      "metadata": {
        "id": "_b9VCFTnNB8M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "to_mode = 'cuda:0'\n",
        "SAVE_PATH = '/content/drive/MyDrive/models/SD'"
      ],
      "metadata": {
        "id": "YpYap0Q9Pb7y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from diffusers import StableDiffusionPipeline\n",
        "\n",
        "text2img_pipe = StableDiffusionPipeline.from_pretrained(\n",
        "    f\"{SAVE_PATH}/stablediffusionapi/deliberate-v2\"\n",
        "    , torch_dtype = torch.float16\n",
        "    , safety_checker = None\n",
        ").to(to_mode)"
      ],
      "metadata": {
        "id": "Z7yokuCfLT6V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lora_path = \"/content/drive/MyDrive/Loras/skinny_hot_girls/output_64_32/skinny_hot_girls-10.safetensors\"\n",
        "text2img_pipe.load_lora_weights(lora_path)"
      ],
      "metadata": {
        "id": "JF2PvkSc5hTW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Just one line code: text2img_pipe.load_lora_weights(lora_path). Test with one of the famous LoRA — LowRA , this LoRA can turn the image to dark mode.\n",
        "\n",
        "Let’s test it with and without LoRA loaded."
      ],
      "metadata": {
        "id": "mhF_kzlxM7C6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from diffusers import EulerDiscreteScheduler\n",
        "\n",
        "prompt = \"\"\"\n",
        "Naked Ambition. A young woman with a rose in her hand and a pink flower in her mouth. she is wearing white stockings and is sitting on a wooden table. Nswf, totally naked. Shaved pussy. Small tits, small breasts. Normal figure.\n",
        "\"\"\"\n",
        "neg_prompt = \"\"\"\n",
        "NSFW,deformed, distorted, disfigured, poorly drawn, bad anatomy, wrong anatomy, extra limb, missing limb, floating limbs, mutated hands and fingers, disconnected limbs, mutation, mutated, ugly, disgusting, blurry, amputation\n",
        "\"\"\"\n",
        "\n",
        "text2img_pipe.scheduler = EulerDiscreteScheduler.from_config(text2img_pipe.scheduler.config)\n",
        "\n",
        "image = text2img_pipe(\n",
        "    prompt = prompt\n",
        "    , negative_prompt = neg_prompt\n",
        "    , generator = torch.Generator(to_mode).manual_seed(3135098381)\n",
        "    , num_inference_steps = 28\n",
        "    , guidance_scale = 8\n",
        "    , width = 512\n",
        "    , height = 768\n",
        ").images[0]\n",
        "display(image)"
      ],
      "metadata": {
        "id": "uIpMo1p8MYUa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "__Load LoRA using Diffusers with a weight__  \n",
        "Even though we can now load LoRA with just one line code, we still don’t see any support for the LoRA weight parameter. For example, we want less dark from the result and say add LoRA weight as 0.5. In A1111 Stable Diffusion Webui, we can give the LoRA weight as: <lora:LowRA:0.5>\n",
        "\n",
        "How can we add this 0.5 to the Diffusers package? seems there is no way, but we can hack into the process and add our value in the middle of the LoRA loading like this:"
      ],
      "metadata": {
        "id": "xCtV1vRXMm7S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text2img_pipe.unload_lora_weights()\n",
        "lora_path = \"<path/to/lora.safetensors>\"\n",
        "\n",
        "lora_w = 0.5\n",
        "text2img_pipe._lora_scale = lora_w\n",
        "\n",
        "state_dict, network_alphas = text2img_pipe.lora_state_dict(\n",
        "    lora_path\n",
        ")\n",
        "\n",
        "for key in network_alphas:\n",
        "    network_alphas[key] = network_alphas[key] * lora_w\n",
        "\n",
        "#network_alpha = network_alpha * lora_w\n",
        "text2img_pipe.load_lora_into_unet(\n",
        "    state_dict = state_dict\n",
        "    , network_alphas = network_alphas\n",
        "    , unet = text2img_pipe.unet\n",
        ")\n",
        "\n",
        "text2img_pipe.load_lora_into_text_encoder(\n",
        "    state_dict = state_dict\n",
        "    , network_alphas = network_alphas\n",
        "    , text_encoder = text2img_pipe.text_encoder\n",
        ")"
      ],
      "metadata": {
        "id": "rwP7N6ziMkod"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To reset the LoRA, simply call the unload_lora_weights function :"
      ],
      "metadata": {
        "id": "maB-qcgXMtr1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text2img_pipe.unload_lora_weights()"
      ],
      "metadata": {
        "id": "kPEqbyW0MvDc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}