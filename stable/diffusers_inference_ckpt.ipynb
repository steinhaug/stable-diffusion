{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "mount_file_id": "1wLiHeREtkfkVQxdQiLf-s2_A5Njxy87n",
      "authorship_tag": "ABX9TyMfxkLL3UpsYNID/vg9B17R",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/steinhaug/stable-diffusion/blob/main/stable/diffusers_inference_ckpt.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "from IPython.display import clear_output\n",
        "%pip install -q -U --pre triton\n",
        "%pip install -q accelerate transformers ftfy bitsandbytes==0.35.0 gradio natsort safetensors xformers\n",
        "%pip install omegaconf\n",
        "!pip install diffusers\n",
        "clear_output(); print('\u001b[1;32mDone! ✓')\n",
        "\n",
        "model_path = \"/content/sd_weights_dir\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0LC8rbUcRWx8",
        "outputId": "b22bae47-7160-4768-a2d5-9c126f9309e6"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;32mDone! ✓\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Retrieve ckpt and convert to diffusers\n",
        "%cd /content\n",
        "!wget https://github.com/ShivamShrirao/diffusers/raw/main/scripts/convert_original_stable_diffusion_to_diffusers.py -O convert_original_stable_diffusion_to_diffusers.py\n",
        "\n",
        "#checkpoint_file = \"/content/zkiste3-5454.ckpt\"\n",
        "#!wget https://huggingface.co/steinhaug/zkiste/resolve/main/zkiste3-5454.ckpt -O zkiste3-5454.ckpt\n",
        "\n",
        "checkpoint_file = \"/content/drive/MyDrive/models/zkiste2-3838.ckpt\"\n",
        "\n",
        "!mkdir {model_path}\n",
        "!python convert_original_stable_diffusion_to_diffusers.py --scheduler_type ddim --checkpoint_path {checkpoint_file} --image_size 512 --prediction_type epsilon --dump_path {model_path} --device cpu\n",
        "clear_output(); print('\u001b[1;32mDone! ✓')"
      ],
      "metadata": {
        "cellView": "form",
        "id": "FiDaPOmvY66U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Initialize stable diffusion from folder \n",
        "import torch\n",
        "from torch import autocast\n",
        "from IPython.display import display\n",
        "\n",
        "#model_path = \"/content/sd_weights_dir\"\n",
        "\n",
        "from diffusers import DiffusionPipeline\n",
        "pipe = DiffusionPipeline.from_pretrained(model_path, safety_checker=None, torch_dtype=torch.float16).to(\"cuda\")\n",
        "\n",
        "# DDIMScheduler, DPMSolverMultistepScheduler, EulerDiscreteScheduler, EulerAncestralDiscreteScheduler, DDPMScheduler, PNDMScheduler\n",
        "from diffusers import DDIMScheduler\n",
        "pipe.scheduler = DDIMScheduler.from_config(pipe.scheduler.config)\n",
        "\n",
        "pipe.enable_xformers_memory_efficient_attention()\n",
        "g_cuda = None\n",
        "\n",
        "g_cuda = torch.Generator(device='cuda')\n",
        "seed = 1\n",
        "g_cuda.manual_seed(seed)\n",
        "saved_file_count = 1;\n",
        "\n",
        "clear_output(); print('\u001b[1;32mDone! ✓')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "hvSsx9IlaA1z",
        "outputId": "ff7bd553-c34d-4a1a-d2f5-db092e526411"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;32mDone! ✓\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "YOUR_TOKEN = \"zkistebb\"\n",
        "TOKEN_GENDER = \"guy\""
      ],
      "metadata": {
        "id": "Yy3_xgcScfft"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title AI-Manual - All options mode\n",
        "prompt = \"(full-body full-length full-shot:1.3), __token__ as magician, highly saturated colors, concept art, cottagecore, Gary Larson,cartoonist\" #@param {type:\"string\"}\n",
        "negative_prompt = \"\" #@param {type:\"string\"}\n",
        "token_name = YOUR_TOKEN + \" \" + TOKEN_GENDER + \", \" + YOUR_TOKEN\n",
        "num_samples = 1 #@param {type:\"number\"}\n",
        "guidance_scale = 8.0 #@param {type:\"number\"}\n",
        "num_inference_steps = 50 #@param {type:\"number\"}\n",
        "width = \"512\" #@param [\"512\", \"768\", \"1280\", \"1536\"] {allow-input: true}\n",
        "height = \"512\" #@param [\"512\", \"768\", \"1280\", \"1536\"] {allow-input: true}\n",
        "width = int(width)\n",
        "height = int(height)\n",
        "custom_seed = 1378417749 #@param {type:\"number\"}\n",
        "new_seed = custom_seed\n",
        "save_images_path = \"/content/drive/MyDrive/AI-Images-Manual\"\n",
        "\n",
        "#prompt = prompt.replace(\"__token__\", token_name)\n",
        "\n",
        "x = token_name.split(\",\")\n",
        "for index, value in enumerate(x):\n",
        "    if index == 0:\n",
        "        prompt = prompt.replace(\"__token__\", value)\n",
        "    else:\n",
        "        prompt = prompt.replace(\"__token\" + str(index) + \"__\", value)\n",
        "\n",
        "#raise Exception(1);\n",
        "\n",
        "if new_seed:\n",
        "    g_cuda = torch.Generator(device='cuda')\n",
        "    g_cuda.manual_seed(new_seed)\n",
        "\n",
        "if len(save_images_path):\n",
        "    tmp = save_images_path.split(\"/\")\n",
        "    if len(tmp) == 1:\n",
        "        save_images_path = \"/content/\" + save_images_path\n",
        "    from pathlib import Path\n",
        "    path = Path(save_images_path)\n",
        "    if not path.exists():\n",
        "        print(f\"[*] Create save directory...\")\n",
        "        path.mkdir(parents = False, exist_ok = False)\n",
        "    try:\n",
        "        if not image_save_count:\n",
        "            print('Darn we need this one!')\n",
        "    except NameError:\n",
        "        image_save_count = 1\n",
        "\n",
        "print(f\"[*] Prompt used: {prompt}\")\n",
        "\n",
        "with autocast(\"cuda\"), torch.inference_mode():\n",
        "    images = pipe(\n",
        "        prompt,\n",
        "        height=height,\n",
        "        width=width,\n",
        "        negative_prompt=negative_prompt,\n",
        "        num_images_per_prompt=num_samples,\n",
        "        num_inference_steps=num_inference_steps,\n",
        "        guidance_scale=guidance_scale,\n",
        "        generator=g_cuda\n",
        "    ).images\n",
        "\n",
        "for img in images:\n",
        "    display(img)\n",
        "    if len(save_images_path):\n",
        "        precount = f'{image_save_count:04d}'\n",
        "        image_filename = precount + '_' + prompt.replace(\" \", '_')[:240] + '.png'\n",
        "        img.save(save_images_path + \"/\" + image_filename)\n",
        "        image_save_count += 1"
      ],
      "metadata": {
        "cellView": "form",
        "id": "BZuv33cEbpsY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Image arrays\n",
        "auto_prompts = [\n",
        "    // needs array\n",
        "]\n",
        "#  (512,512,256,256,2), (512,1080,128,270,2), (512,768,128,192,2), (512,768,128,192,2), (768,512,192,128,2), (1536,512,384,128,1)\n",
        "autoresolutions = [\n",
        "  (512,512,256,256,2)\n",
        "]"
      ],
      "metadata": {
        "id": "N2Y-bvDdzJT0"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title AI-Automatic - Create some 50+  AI-Images from your brand new trained model\n",
        "#@markdown I have put together a little \"Avatar\"-bonus pack for you, press play and let it complete and check your Google Drive folder for the completed AI Images.<br>\n",
        "#@markdown Time to complete: around XX minutes\n",
        "\n",
        "import os.path\n",
        "from os import path\n",
        "from IPython.display import display\n",
        "import ast\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "\n",
        "model_trained_steps_for_filename = 'auto'\n",
        "num_samples = 2\n",
        "images_savepath = '/content/drive/MyDrive/AI-Images'\n",
        "#models = \"('\" + YOUR_TOKEN + \"','\" + YOUR_TOKEN + \" person')\"\n",
        "models = \"('\" + YOUR_TOKEN + \"','\" + YOUR_TOKEN + \" \" + TOKEN_GENDER + \"')\"\n",
        "\n",
        "n_override_width = None\n",
        "n_override_height = None\n",
        "n_override_seed = None\n",
        "n_override_guidance_scale = None\n",
        "n_override_inference_steps = None\n",
        "\n",
        "width = 512\n",
        "height = 512\n",
        "\n",
        "kista_trainednames = ast.literal_eval('[' + models + ']')\n",
        "\n",
        "if path.exists(images_savepath) == False:\n",
        "  os.mkdir(images_savepath)\n",
        "\n",
        "\n",
        "\n",
        "print(f\"[*] All AI-Images are saved to your Google Drive in the folder: AI-Images \")\n",
        "print(f\"[*] . \")\n",
        "\n",
        "for width, height, scaleWidth, scaleHeight, num_samples in autoresolutions:\n",
        "    print(f\"[*] Generating images in {width} x {height}.... \")\n",
        "    print(f\"[*] .. displaying thumbnails of completed images...\")\n",
        "    for prompt_ref,seed,guidance_scale,num_inference_steps,prompt,negative_prompt,filter_x in auto_prompts:\n",
        "        for modelref,kista_modelname in kista_trainednames:\n",
        "            if width == 1536:\n",
        "                if filter_x == 0:\n",
        "                    continue;\n",
        "                num_inference_steps = filter_x\n",
        "            torch.cuda.empty_cache()\n",
        "            newprompt = prompt.replace(\"__token__\", kista_modelname)\n",
        "            newprompt = newprompt.replace(\"__ttoken__\", modelref)\n",
        "\n",
        "            if n_override_seed:\n",
        "                seed = n_override_seed\n",
        "\n",
        "            g_cuda = torch.Generator(device='cuda')\n",
        "            g_cuda.manual_seed(seed)\n",
        "\n",
        "            if n_override_height:\n",
        "                height = n_override_height\n",
        "            if n_override_width:\n",
        "                width = n_override_width\n",
        "            if n_override_inference_steps:\n",
        "                num_inference_steps = n_override_inference_steps\n",
        "            if n_override_guidance_scale:\n",
        "                guidance_scale = n_override_guidance_scale\n",
        "            with autocast(\"cuda\"), torch.inference_mode():\n",
        "                images = pipe(\n",
        "                    newprompt,\n",
        "                    height=height,\n",
        "                    width=width,\n",
        "                    negative_prompt=negative_prompt,\n",
        "                    num_images_per_prompt=num_samples,\n",
        "                    num_inference_steps=num_inference_steps,\n",
        "                    guidance_scale=guidance_scale,\n",
        "                    generator=g_cuda\n",
        "                ).images\n",
        "            image_filenames = []\n",
        "            for img in images:\n",
        "                prefix_count = '_' + f'{saved_file_count:04d}'\n",
        "                seed_ref     = '_' + f'{seed:04d}'\n",
        "                final_id     = 's' + model_trained_steps_for_filename + 'g' + f'{guidance_scale:01f}' + 'i' + f'{num_inference_steps:03d}' + 's' + f'{seed}'\n",
        "                #outfilename = prompt_ref + '_' + modelref + '_' + final_id.replace(\".\", '') + prefix_count\n",
        "                outfilename = prompt_ref + seed_ref + prefix_count\n",
        "                image_filename = outfilename.replace(\" \", '_').replace(\"00000i\", 'i') + '.png'\n",
        "                img.save(images_savepath + \"/\" + image_filename)\n",
        "                image_filenames.append(image_filename)\n",
        "                saved_file_count += 1\n",
        "            image_folder = images_savepath + '/'\n",
        "            grid_row = 1\n",
        "            grid_col = len(image_filenames)\n",
        "            grid_scale = 3\n",
        "            if grid_col > 1:\n",
        "                fig, axes = plt.subplots(grid_row, grid_col, figsize=(grid_col*grid_scale, grid_row*grid_scale), gridspec_kw={'hspace': 0, 'wspace': 0})\n",
        "                for j, image_filename in enumerate(image_filenames):\n",
        "                    currAxes = axes[j]\n",
        "                    currAxes.set_title(f\"{image_filename[0:24]}\")\n",
        "                    image_full_path = os.path.join(image_folder, image_filename)\n",
        "                    imgdata = mpimg.imread(image_full_path)\n",
        "                    currAxes.imshow(imgdata, cmap='gray')\n",
        "                    currAxes.axis('off')\n",
        "                plt.tight_layout()\n",
        "                plt.savefig('grid.png', dpi=72)\n",
        "                plt.show()\n",
        "            else:\n",
        "                display(img.resize((scaleWidth, scaleHeight)))\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "mB4N2EUxzJvl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# RunDiffusion FX Photorealistic\n",
        "https://civitai.com/api/download/models/88158?type=Model&format=SafeTensor&size=full&fp=fp16\n",
        "\n",
        "# RunDiffusion FX 2.5D\n",
        "https://civitai.com/api/download/models/88167?type=Model&format=SafeTensor&size=full&fp=fp16"
      ],
      "metadata": {
        "id": "ToqEqy2RC23q"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}