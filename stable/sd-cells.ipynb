{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1S6IaNYcPkHb3C1gjXuMEJabH6mnagF2k",
      "authorship_tag": "ABX9TyO8ruSjd+/+FDbFFX5iCNnl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/steinhaug/stable-diffusion/blob/main/stable/sd-cells.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os"
      ],
      "metadata": {
        "id": "DT0ZKX3YPtDp"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KZRGx68vHX11"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "OUTPUT_DIR = \"/content/drive/MyDrive/sd_weights/dreamlike-steinhaug-20\"\n",
        "\n",
        "weights_folder = OUTPUT_DIR\n",
        "keeper = \"1040\"\n",
        "keeper2 = \"1111\"\n",
        "\n",
        "do_delete_all = False\n",
        "\n",
        "folders = sorted([f for f in os.listdir(weights_folder) if f != \"0\" and os.path.isdir(weights_folder + '/' + f)], key=lambda x: int(x))\n",
        "\n",
        "for i, folder in enumerate(folders):\n",
        "    if folder == keeper or folder == keeper2:\n",
        "        do_delete_all = True\n",
        "\n",
        "for i, folder in enumerate(folders):\n",
        "    print(folder)\n",
        "    if folder == keeper or folder == keeper2:\n",
        "        print('We keep this one!')\n",
        "    else:\n",
        "        dirPapth = f'{weights_folder}/' + folder\n",
        "        if do_delete_all:\n",
        "            print(f'Deleting all files in {dirPapth}')\n",
        "            !rm -Rf {dirPapth}/scheduler/*\n",
        "            !rm -Rf {dirPapth}/text_encoder/*\n",
        "            !rm -Rf {dirPapth}/tokenizer/*\n",
        "            !rm -Rf {dirPapth}/unet/*\n",
        "            !rm -Rf {dirPapth}/vae/*\n",
        "            if os.path.isdir(dirPapth + '/args.json'):\n",
        "                !rm {dirPapth}/args.json\n",
        "            if os.path.isdir(dirPapth + '/model_index.json'):\n",
        "                !rm {dirPapth}/model_index.json\n",
        "\n",
        "print(f'Done!')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title GRID MAKER: generate a grid of preview images from the saved checkpoints\n",
        "import os\n",
        "from sys import exit\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "\n",
        "OUTPUT_DIR_2 = \"/content/drive/MyDrive/sd_weights/dreamlike-steinhaug-20\" #@param {type:\"string\"}\n",
        "\n",
        "weights_folder = OUTPUT_DIR_2\n",
        "folders = sorted([f for f in os.listdir(weights_folder) if f != \"0\"], key=lambda x: int(x))\n",
        "\n",
        "scale = 4\n",
        "breaki = 5\n",
        "\n",
        "row = len(folders)\n",
        "col = len(os.listdir(os.path.join(weights_folder, folders[0], \"samples\")))\n",
        "\n",
        "if col > breaki:\n",
        "    col = breaki\n",
        "\n",
        "fig, axes = plt.subplots(row, col, figsize=(col*scale, row*scale), gridspec_kw={'hspace': 0, 'wspace': 0})\n",
        "\n",
        "for i, folder in enumerate(folders):\n",
        "    folder_path = os.path.join(weights_folder, folder)\n",
        "    image_folder = os.path.join(folder_path, \"samples\")\n",
        "    images = [f for f in os.listdir(image_folder)]\n",
        "    for j, image in enumerate(images):\n",
        "        if row == 1:\n",
        "            currAxes = axes[j]\n",
        "        else:\n",
        "            currAxes = axes[i, j]\n",
        "        if i == 0:\n",
        "            currAxes.set_title(f\"Image {j}\")\n",
        "        if j == 0:\n",
        "            currAxes.text(-0.1, 0.5, folder, rotation=0, va='center', ha='center', transform=currAxes.transAxes)\n",
        "        image_path = os.path.join(image_folder, image)\n",
        "        img = mpimg.imread(image_path)\n",
        "        currAxes.imshow(img, cmap='gray')\n",
        "        currAxes.axis('off')\n",
        "        if j == (breaki - 1):\n",
        "            break;\n",
        "\n",
        "%cd $OUTPUT_DIR_2\n",
        "plt.savefig(f'{saved_grid_count:04d}' + \"_\" + SAMPLES_DIR + '_grid.png', dpi=72)\n",
        "plt.tight_layout()\n",
        "saved_grid_count += 1"
      ],
      "metadata": {
        "id": "UF0ETjV6ofIO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MADER BLOCKS"
      ],
      "metadata": {
        "id": "dNjfz2U29pJH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 1/2 Define the prompts to loop over \n",
        "\n",
        "auto_prompts = [\n",
        " \n",
        "  (\"101-\",\"warrior_poster\",\n",
        "  696969,8.0,50,\n",
        "  \"poster of a warrior goddess| standing alone on hill| centered| detailed gorgeous face| anime style| key visual| intricate detail| highly detailed| breathtaking| vibrant| panoramic| cinematic| Carne Griffiths| Conrad Roset| Makoto Shinkai\",\n",
        "  \"blurry| fuzzy| extra fingers| disfigured| cropped| bad fingers| deformed fingers| mutated fingers| out of frame\"\n",
        "  ),\n",
        "  (\"102-\",\"warrior_poster\",\n",
        "  696969,8.0,50,\n",
        "  \"poster of a warrior goddess| standing alone on hill| centered| detailed gorgeous face| anime style| key visual| intricate detail| highly detailed| breathtaking| vibrant| panoramic| cinematic| Carne Griffiths| Conrad Roset| Makoto Shinkai| Susanne Kathleen Mader\",\n",
        "  \"blurry| fuzzy| extra fingers| disfigured| cropped| bad fingers| deformed fingers| mutated fingers| out of frame\"\n",
        "  ),\n",
        "  (\"103-\",\"warrior_poster\",\n",
        "  696969,8.0,50,\n",
        "  \"poster of a warrior goddess| standing alone on hill| centered| detailed gorgeous face| anime style| key visual| intricate detail| highly detailed| breathtaking| vibrant| panoramic| cinematic| Carne Griffiths| Conrad Roset| Makoto Shinkai| Susanne Kathleen Mader Rondo\",\n",
        "  \"blurry| fuzzy| extra fingers| disfigured| cropped| bad fingers| deformed fingers| mutated fingers| out of frame\"\n",
        "  ),\n",
        "  (\"201-\",\"sango_dream\",\n",
        "  4289232563,7.0,30,\n",
        "  \"Sango fantasy, fantasy magic, intricate, sharp focus, illustration, highly detailed, digital painting, concept art, matte, Artgerm and Paul lewin and kehinde wiley, masterpiece\",\n",
        "  \"circles, bad anatomy| blurry| fuzzy| extra legs| extra arms| extra fingers| poorly drawn hands| poorly drawn feet| disfigured| out of frame| tiling| bad art| deformed| mutated| double face\"\n",
        "  ),\n",
        "  (\"202-\",\"sango_dream\",\n",
        "  4289232563,7.0,30,\n",
        "  \"Sango fantasy, fantasy magic, intricate, sharp focus, illustration, highly detailed, digital painting, concept art, matte, Artgerm and Paul lewin and kehinde wiley, masterpiece, Susanne Kathleen Mader\",\n",
        "  \"circles, bad anatomy| blurry| fuzzy| extra legs| extra arms| extra fingers| poorly drawn hands| poorly drawn feet| disfigured| out of frame| tiling| bad art| deformed| mutated| double face\"\n",
        "  ),\n",
        "  (\"203-\",\"sango_dream\",\n",
        "  4289232563,7.0,30,\n",
        "  \"Sango fantasy, fantasy magic, intricate, sharp focus, illustration, highly detailed, digital painting, concept art, matte, Artgerm and Paul lewin and kehinde wiley, masterpiece, Susanne Kathleen Mader Rondo\",\n",
        "  \"circles, bad anatomy| blurry| fuzzy| extra legs| extra arms| extra fingers| poorly drawn hands| poorly drawn feet| disfigured| out of frame| tiling| bad art| deformed| mutated| double face\"\n",
        "  ),\n",
        "  (\"301-\",\"megan_fox\",\n",
        "  47468,10.0,100,\n",
        "  \"Full body Portrait of Megan Fox as nubian princess,Eligent, photorealistic illustration, art by artgerm and greg rutkowski and alphonse mucha\",\n",
        "  \"\"\n",
        "  ),\n",
        "  (\"302-\",\"megan_fox\",\n",
        "  47468,10.0,100,\n",
        "  \"Full body Portrait of Megan Fox as nubian princess,Eligent, photorealistic illustration, art by artgerm and greg rutkowski and alphonse mucha, Susanne Kathleen Mader\",\n",
        "  \"\"\n",
        "  ),\n",
        "  (\"303-\",\"megan_fox\",\n",
        "  47468,10.0,100,\n",
        "  \"Full body Portrait of Megan Fox as nubian princess,Eligent, photorealistic illustration, art by artgerm and greg rutkowski and alphonse mucha, Susanne Kathleen Mader Rondo\",\n",
        "  \"\"\n",
        "  ),\n",
        "]\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "Rn4opN5f9uH1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 2/2 Execute checkpoint looping for prompts\n",
        "import torch\n",
        "from torch import autocast\n",
        "from diffusers import StableDiffusionPipeline, DDIMScheduler\n",
        "from IPython.display import display\n",
        "import os\n",
        "\n",
        "height = 512\n",
        "width = 512\n",
        "num_samples = 1\n",
        "\n",
        "#models_array = [1250,1500,1750,2000,2250,2500,2750,3000,3250,3500,3750,4000,4250,4500,4750,5000,5250,5500,5750,6000]\n",
        "models_array = [1750,2000,2250,2500,2750,3000,3250,3500,3750,4000,4250,4500,4750,5000,5250,5500,5750,6000]\n",
        "models_path  = \"/content/drive/MyDrive/sd_weights/skmader_v3/\"\n",
        "\n",
        "for trained_steps in models_array:\n",
        "    model_path = f'{models_path}{trained_steps}'\n",
        "    print('Initializing new checkpoint... ./{trained_steps}')\n",
        "    pipe = StableDiffusionPipeline.from_pretrained(model_path, safety_checker=None, torch_dtype=torch.float16).to(\"cuda\")\n",
        "    pipe.scheduler = DDIMScheduler.from_config(pipe.scheduler.config)\n",
        "    pipe.enable_xformers_memory_efficient_attention()\n",
        "    g_cuda = torch.Generator(device='cuda')\n",
        "    g_cuda.manual_seed(69)\n",
        "    for prompt_ref_pre,prompt_ref_post,seed,guidance_scale,num_inference_steps,newprompt,negative_prompt in auto_prompts:\n",
        "        images_savepath = f'/content/drive/MyDrive/sd_weights/output/{trained_steps}/samples_{prompt_ref_post}'\n",
        "        os.makedirs(images_savepath, exist_ok=True)\n",
        "        prompt_ref = prompt_ref_pre + prompt_ref_post\n",
        "        torch.cuda.empty_cache()\n",
        "        g_cuda = torch.Generator(device='cuda')\n",
        "        g_cuda.manual_seed(seed)\n",
        "        with autocast(\"cuda\"), torch.inference_mode():\n",
        "            images = pipe(\n",
        "                newprompt,\n",
        "                height=height,\n",
        "                width=width,\n",
        "                negative_prompt=negative_prompt,\n",
        "                num_images_per_prompt=num_samples,\n",
        "                num_inference_steps=num_inference_steps,\n",
        "                guidance_scale=guidance_scale,\n",
        "                generator=g_cuda\n",
        "            ).images\n",
        "        image_filenames = []\n",
        "        for img in images:\n",
        "            image_filename = prompt_ref + '.png'\n",
        "            img.save(images_savepath + \"/\" + image_filename)\n",
        "            image_filenames.append(image_filename)\n",
        "\n",
        "        image_folder = images_savepath + '/'\n",
        "        grid_row = 1\n",
        "        grid_col = len(image_filenames)\n",
        "        grid_scale = 3\n",
        "        if grid_col > 1:\n",
        "            fig, axes = plt.subplots(grid_row, grid_col, figsize=(grid_col*grid_scale, grid_row*grid_scale), gridspec_kw={'hspace': 0, 'wspace': 0})\n",
        "            for j, image_filename in enumerate(image_filenames):\n",
        "                currAxes = axes[j]\n",
        "                currAxes.set_title(f\"{image_filename[0:5]}\")\n",
        "                image_full_path = os.path.join(image_folder, image_filename)\n",
        "                imgdata = mpimg.imread(image_full_path)\n",
        "                currAxes.imshow(imgdata, cmap='gray')\n",
        "                currAxes.axis('off')\n",
        "            plt.tight_layout()\n",
        "            plt.savefig('grid.png', dpi=72)\n",
        "            plt.show()\n",
        "        else:\n",
        "            display(img.resize(( int(height / 2), int(height / 2) )))\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "s_v1OAR_9ugA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Huggingface uploader blocks"
      ],
      "metadata": {
        "id": "KMMEXgi2_kVa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from slugify import slugify\n",
        "from huggingface_hub import HfApi, HfFolder, CommitOperationAdd\n",
        "from huggingface_hub import create_repo\n",
        "from IPython.display import display_markdown\n",
        "from IPython.display import clear_output\n",
        "from IPython.utils import capture\n",
        "from google.colab import files\n",
        "import shutil\n",
        "import time\n",
        "import os\n",
        "\n",
        "Create_repo = True #@param {type:\"boolean\"}\n",
        "hf_token_write = \"\" #@param {type:\"string\"}\n",
        "Name_of_your_concept = \"\" #@param {type:\"string\"}\n",
        "\n",
        "Name_of_your_concept=Name_of_your_concept.replace(\" \",\"-\")  \n",
        "hf_token = hf_token_write\n",
        "\n",
        "if not len(hf_token_write):\n",
        "    hf_token = HUGGINGFACE_TOKEN\n",
        "\n",
        "\n",
        "api = HfApi()\n",
        "your_username = api.whoami(token=hf_token)[\"name\"]\n",
        "repo_id = f\"{your_username}/{slugify(Name_of_your_concept)}\"\n",
        "\n",
        "def bar(prg):\n",
        "    br=\"\u001b[1;33mUploading to HuggingFace : \" '\u001b[0m|'+'█' * prg + ' ' * (25-prg)+'| ' +str(prg*4)+ \"%\"\n",
        "    return br\n",
        "print(\"\u001b[1;32mLoading...\")\n",
        "\n",
        "UPLOAD_DIR = \"/content/temp\"\n",
        "\n",
        "os.makedirs(UPLOAD_DIR, exist_ok=True)\n",
        "\n",
        "%cd $UPLOAD_DIR\n",
        "!rm -r safety_checker feature_extractor .git\n",
        "!rm model_index.json\n",
        "!git init\n",
        "!git lfs install --system --skip-repo\n",
        "!git remote add -f origin  \"https://USER:{hf_token}@huggingface.co/runwayml/stable-diffusion-v1-5\"\n",
        "!git config core.sparsecheckout true\n",
        "!echo -e \"feature_extractor\\nsafety_checker\\nmodel_index.json\" > .git/info/sparse-checkout\n",
        "!git pull origin main\n",
        "!rm -r .git\n",
        "#%cd /content\n",
        "\n",
        "readme_text = f'''---\n",
        "license: creativeml-openrail-m\n",
        "tags:\n",
        "- text-to-image\n",
        "- stable-diffusion\n",
        "---\n",
        "### {Name_of_your_concept} \n",
        "'''\n",
        "#Save the readme to a file\n",
        "readme_file = open(\"README.md\", \"w\")\n",
        "readme_file.write(readme_text)\n",
        "readme_file.close()\n",
        "\n",
        "operations = [\n",
        "  CommitOperationAdd(path_in_repo=\"README.md\", path_or_fileobj=\"README.md\")\n",
        "]\n",
        "\n",
        "if Create_repo:\n",
        "  create_repo(repo_id,private=True, token=hf_token)\n",
        "  api.create_commit(\n",
        "    repo_id=repo_id,\n",
        "    operations=operations,\n",
        "    commit_message=f\"Init concept {Name_of_your_concept} repo\",\n",
        "    token=hf_token\n",
        "  )\n",
        "\n",
        "clear_output()\n",
        "print(bar(25))\n",
        "\n",
        "display_markdown(f'''## Ready... [repo link](https://huggingface.co/{repo_id})\n",
        "''', raw=True)\n"
      ],
      "metadata": {
        "id": "xXhn_XN5_mdU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from slugify import slugify\n",
        "from huggingface_hub import HfApi, HfFolder, CommitOperationAdd\n",
        "from huggingface_hub import create_repo\n",
        "from IPython.display import display_markdown\n",
        "from IPython.display import clear_output\n",
        "from IPython.utils import capture\n",
        "from google.colab import files\n",
        "import shutil\n",
        "import time\n",
        "import os\n",
        "\n",
        "MODEL1 = '/content/drive/MyDrive/alpaca-models/ggml-alpaca-7b-q4.bin'\n",
        "\n",
        "operations = [\n",
        "  CommitOperationAdd(path_in_repo=\"gpt4free/ggml-alpaca-7b-q4.bin\",path_or_fileobj=MODEL1),\n",
        "]\n",
        "api.create_commit(\n",
        "  repo_id=repo_id,\n",
        "  operations=operations,\n",
        "  commit_message=f\"Added 1 free model.\",\n",
        "  token=hf_token\n",
        ")\n"
      ],
      "metadata": {
        "id": "8wF497HW_mgB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from slugify import slugify\n",
        "from huggingface_hub import HfApi, HfFolder, CommitOperationAdd\n",
        "from huggingface_hub import create_repo\n",
        "from IPython.display import display_markdown\n",
        "from IPython.display import clear_output\n",
        "from IPython.utils import capture\n",
        "from google.colab import files\n",
        "import shutil\n",
        "import time\n",
        "import os\n",
        "\n",
        "api.upload_folder(\n",
        "  folder_path='/content/drive/MyDrive/sd_weights/weights',\n",
        "  path_in_repo=\"training/weights\",\n",
        "  repo_id=repo_id, token=hf_token\n",
        ")\n"
      ],
      "metadata": {
        "id": "5ZxUQGI3_mij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from slugify import slugify\n",
        "from huggingface_hub import HfApi, HfFolder, CommitOperationAdd\n",
        "from huggingface_hub import create_repo\n",
        "from IPython.display import display_markdown\n",
        "from IPython.display import clear_output\n",
        "from IPython.utils import capture\n",
        "from google.colab import files\n",
        "import shutil\n",
        "import time\n",
        "import os\n",
        "\n",
        "api.upload_folder(\n",
        "  folder_path='/content/drive/MyDrive/sd_weights/x_tentando_x/2814/feature_extractor',\n",
        "  path_in_repo=\"feature_extractor\",\n",
        "  repo_id=repo_id, token=hf_token\n",
        ")\n",
        "api.upload_folder(\n",
        "  folder_path='/content/drive/MyDrive/sd_weights/x_tentando_x/2814/scheduler',\n",
        "  path_in_repo=\"scheduler\",\n",
        "  repo_id=repo_id, token=hf_token\n",
        ")\n",
        "api.upload_folder(\n",
        "  folder_path='/content/drive/MyDrive/sd_weights/x_tentando_x/2814/text_encoder',\n",
        "  path_in_repo=\"text_encoder\",\n",
        "  repo_id=repo_id, token=hf_token\n",
        ")\n",
        "api.upload_folder(\n",
        "  folder_path='/content/drive/MyDrive/sd_weights/x_tentando_x/2814/tokenizer',\n",
        "  path_in_repo=\"tokenizer\",\n",
        "  repo_id=repo_id, token=hf_token\n",
        ")\n",
        "api.upload_folder(\n",
        "  folder_path='/content/drive/MyDrive/sd_weights/x_tentando_x/2814/unet',\n",
        "  path_in_repo=\"unet\",\n",
        "  repo_id=repo_id, token=hf_token\n",
        ")\n",
        "api.upload_folder(\n",
        "  folder_path='/content/drive/MyDrive/sd_weights/x_tentando_x/2814/vae',\n",
        "  path_in_repo=\"vae\",\n",
        "  repo_id=repo_id, token=hf_token\n",
        ")\n"
      ],
      "metadata": {
        "id": "taQZ3qQ9_mlC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from slugify import slugify\n",
        "from huggingface_hub import HfApi, HfFolder, CommitOperationAdd\n",
        "from huggingface_hub import create_repo\n",
        "from IPython.display import display_markdown\n",
        "from IPython.display import clear_output\n",
        "from IPython.utils import capture\n",
        "from google.colab import files\n",
        "import shutil\n",
        "import time\n",
        "import os\n",
        "\n",
        "\n",
        "MODEL1 = '/content/drive/MyDrive/sd_weights/x_tentando_x.png'\n",
        "MODEL2 = '/content/drive/MyDrive/sd_weights/x_tentando_x/2814/args.json'\n",
        "MODEL3 = '/content/drive/MyDrive/sd_weights/x_tentando_x/2814/model_index.json'\n",
        "\n",
        "operations = [\n",
        "  CommitOperationAdd(path_in_repo=\"training/x_tentando_x.png\",path_or_fileobj=MODEL1),\n",
        "  CommitOperationAdd(path_in_repo=\"args.json\",path_or_fileobj=MODEL2),\n",
        "  CommitOperationAdd(path_in_repo=\"model_index.json\",path_or_fileobj=MODEL3)\n",
        "]\n",
        "api.create_commit(\n",
        "  repo_id=repo_id,\n",
        "  operations=operations,\n",
        "  commit_message=f\"Added last diffusers files.\",\n",
        "  token=hf_token\n",
        ")"
      ],
      "metadata": {
        "id": "nsoexQXt_mnw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Checksum comparison"
      ],
      "metadata": {
        "id": "JGeehZX5_1kB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title checksum function\n",
        "import hashlib\n",
        "  \n",
        "def get_checksum(filename, hash_function):\n",
        "    \"\"\"Generate checksum for file baed on hash function (MD5 or SHA256).\n",
        " \n",
        "    Args:\n",
        "        filename (str): Path to file that will have the checksum generated.\n",
        "        hash_function (str):  Hash function name - supports MD5 or SHA256\n",
        " \n",
        "    Returns:\n",
        "        str`: Checksum based on Hash function of choice.\n",
        " \n",
        "    Raises:\n",
        "        Exception: Invalid hash function is entered.\n",
        " \n",
        "    \"\"\"\n",
        "    hash_function = hash_function.lower()\n",
        " \n",
        "    with open(filename, \"rb\") as f:\n",
        "        bytes = f.read()  # read file as bytes\n",
        "        if hash_function == \"md5\":\n",
        "            readable_hash = hashlib.md5(bytes).hexdigest()\n",
        "        elif hash_function == \"sha256\":\n",
        "            readable_hash = hashlib.sha256(bytes).hexdigest()\n",
        "        else:\n",
        "            Raise(\"{} is an invalid hash function. Please Enter MD5 or SHA256\")\n",
        " \n",
        "    return readable_hash\n",
        "#comparefiles(['/content/drive/MyDrive/alpaca-models/ggml-model-q4_0.bin', '/content/drive/MyDrive/alpaca-models/ggml-alpaca-7b-q4.bin'], '')"
      ],
      "metadata": {
        "id": "jhdOYgiw_6Fp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title calculate file 1\n",
        "import os\n",
        " \n",
        "photo = \"/content/drive/MyDrive/alpaca-models/ggml-model-q4_0.bin\"\n",
        "md5_result = get_checksum(photo, \"md5\")\n",
        "sha256_result = get_checksum(photo, \"sha256\")\n",
        " \n",
        "os.system(\"md5 {}\".format(photo))\n",
        "print('Hash Function: MD5 - Filename: {}'.format(md5_result))\n",
        " \n",
        "os.system(\"shasum -a 256 {}\".format(photo))\n",
        "print('Hash Function: SHA256 - Filename: {}'.format(sha256_result))\n"
      ],
      "metadata": {
        "id": "wmOxs3p3_6IK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title calculate file 2\n",
        "import os\n",
        " \n",
        "photo = \"/content/drive/MyDrive/alpaca-models/ggml-alpaca-7b-q4.bin\"\n",
        "md5_result = get_checksum(photo, \"md5\")\n",
        "sha256_result = get_checksum(photo, \"sha256\")\n",
        " \n",
        "os.system(\"md5 {}\".format(photo))\n",
        "print('Hash Function: MD5 - Filename: {}'.format(md5_result))\n",
        " \n",
        "os.system(\"shasum -a 256 {}\".format(photo))\n",
        "print('Hash Function: SHA256 - Filename: {}'.format(sha256_result))"
      ],
      "metadata": {
        "id": "89OF6FQ5_6K1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Celler"
      ],
      "metadata": {
        "id": "Fy7Z66BuAGCZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Free runtime memory\n",
        "exit()"
      ],
      "metadata": {
        "cellView": "form",
        "id": "r9vvC-qFAJN1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Free up CPU-RAM\n",
        "import gc\n",
        "\n",
        "# Custom Callback To Include in Callbacks List At Training Time\n",
        "class GarbageCollectorCallback(tf.keras.callbacks.Callback):\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        gc.collect()"
      ],
      "metadata": {
        "cellView": "form",
        "id": "Bsl7WAzcARkS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Free up GPU-RAM\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "cellView": "form",
        "id": "bA6xLnEjAaF2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title (Optional) Delete diffuser and old weights and only keep the ckpt to free up drive space.\n",
        "\n",
        "#@markdown [ ! ] Caution, Only execute if you are sure u want to delete the diffuser format weights and only use the ckpt.\n",
        "import shutil\n",
        "from glob import glob\n",
        "import os\n",
        "for f in glob(OUTPUT_DIR+os.sep+\"*\"):\n",
        "    if f != WEIGHTS_DIR:\n",
        "        shutil.rmtree(f)\n",
        "        print(\"Deleted\", f)\n",
        "for f in glob(WEIGHTS_DIR+\"/*\"):\n",
        "    if not f.endswith(\".ckpt\") or not f.endswith(\".json\"):\n",
        "        try:\n",
        "            shutil.rmtree(f)\n",
        "        except NotADirectoryError:\n",
        "            continue\n",
        "        print(\"Deleted\", f)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "oJM6054vARm6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Auto "
      ],
      "metadata": {
        "id": "e7g420XoAunX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Run to execute batch\n",
        "import os.path\n",
        "from os import path\n",
        "from IPython.display import display\n",
        "import ast\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "\n",
        "model_trained_steps_for_filename = 'wrong1280' #@param {type:\"string\"}\n",
        "num_samples = 1 #@param {type:\"number\"}\n",
        "images_savepath = '/content/drive/MyDrive/crazy' #@param {type:\"string\"}\n",
        "models = \"('zkistebc','zkistebc guy'),('zkisteef','zkisteef guy')\" #@param {type:\"string\"}\n",
        "models_ = \"\" #@param {type:\"string\"}\n",
        "#@markdown Syntax: ('reference name', 'trained instance name')<br>\n",
        "#@markdown Overrides leave empty if not to be used\n",
        "override_width = 512 #@param {type:\"number\"}\n",
        "override_height = 1280 #@param {type:\"number\"}\n",
        "override_seed = None #@param {type:\"number\"}\n",
        "override_guidance_scale = None #@param {type:\"number\"}\n",
        "override_inference_steps = None #@param {type:\"number\"}\n",
        "\n",
        "\n",
        "kista_trainednames = ast.literal_eval('[' + models + ']')\n",
        "\n",
        "if path.exists(images_savepath) == False:\n",
        "  os.mkdir(images_savepath)\n",
        "\n",
        "auto_prompts = [\n",
        " \n",
        "  (\"warrior_poster\",\n",
        "  696969,8.0,50,\n",
        "  \"poster of __token__ , big boobs, warrior goddess| standing alone on hill| centered| detailed gorgeous face| anime style| key visual| intricate detail| highly detailed| breathtaking| vibrant| panoramic| cinematic| Carne Griffiths| Conrad Roset| Makoto Shinkai\",\n",
        "  \"blurry| fuzzy| extra fingers| disfigured| cropped| bad fingers| deformed fingers| mutated fingers| out of frame\"\n",
        "  ),\n",
        "  (\"halloween_man_1\",\n",
        "  2971107907,7.5,50,\n",
        "  \"The personification of the Halloween holiday played by (__ttoken__:0.95), portraited as a (__token__:0.5) with short hair and a villain's smile and a cute hat, cute cheeks, unreal engine, highly detailed, artgerm digital illustration, by Alexei Vinogradov bakery, sweets, emerald eyes\",\n",
        "  \"bad anatomy, extra legs, extra arms, poorly drawn face, poorly drawn hands, poorly drawn feet, fat, disfigured, out of frame, long neck, poo art, bad hands, bad art, deformed, gun, double head, flowers,asian,hyperrealistic,child\",\n",
        "  ),\n",
        "  (\"warrior\",\n",
        "  16,8.0,75,\n",
        "  \"__token__ as strong warrior princess| centered| key visual| intricate| highly detailed| breathtaking beauty| precise lineart| vibrant| comprehensive cinematic| Carne Griffiths| Conrad Roset\",\n",
        "  \"bad anatomy, extra legs, extra arms, poorly drawn face, poorly drawn hands, poorly drawn feet, fat, disfigured, out of frame, long neck, poo art, bad hands, bad art, deformed, gun, double head, flowers,asian,hyperrealistic,child\",\n",
        "  ),\n",
        "  (\"warrior_sketch\",\n",
        "  16,8.0,75,\n",
        "  \"__token__ as strong warrior king| centered| key visual| intricate| highly detailed| breathtaking beauty| precise lineart| vibrant| comprehensive cinematic| Carne Griffiths| Conrad Roset\",\n",
        "  \"\"\n",
        "  ),\n",
        "  (\"warrior_sketch\",\n",
        "  16,8.0,25,\n",
        "  \"__token__ as strong warrior princess| centered| key visual| intricate| highly detailed| breathtaking beauty| precise lineart| vibrant| comprehensive cinematic| Carne Griffiths| Conrad Roset\",\n",
        "  \"\"\n",
        "  ),\n",
        "  (\"punk_face\",\n",
        "  422313768,7.5,50,\n",
        "  \"(__ttoken__:0.25), detailed (bladerunner:1.5) portrait of Punk (__token__:1.2), (standing hair line:2), Sheen Holographic Futuristic sci-fi fashion cyberpunk, neotokyo, synthwave, (aesthetics), futuristic, art by greg rutkowski Alexandros Pyromallis Nekro Rene Margitte\",\n",
        "  \"\"\n",
        "  ),\n",
        "  (\"Glamor_look\",\n",
        "  1654522787,7.5,50,\n",
        "  \"breathtaking beauty| (__token__:1.5) with a white dress and long blond hair floating in wind magically, elf like, extreme photorealistic, 4k, sexy figure, medium shot, illustration, EF 70mm| concept art| Duy Huynh\",\n",
        "  \"no words| watermark| bad anatomy| blurry| fuzzy| extra legs| extra arms| extra fingers| poorly drawn hands| poorly drawn feet| disfigured| out of frame| tiling| bad art| deformed| mutated| double face\"\n",
        "  ),\n",
        "  (\"Cyberpunked_1\",\n",
        "  1654522787,7.5,50,\n",
        "  \"cyberpunk (__token__:1.5) in heavy raining futuristic tokyo rooftop cyberpunk night, sci-fi, __ttoken__ fantasy, intricate, very very beautiful, elegant, neon light, highly detailed, digital painting, artstation, concept art, soft light, hdri, smooth, sharp focus, illustration| art by tian zi| craig mullins| wlop| alphonse much\",\n",
        "  \"no words| watermark| bad anatomy| blurry| fuzzy| extra legs| extra arms| extra fingers| poorly drawn hands| poorly drawn feet| disfigured| out of frame| tiling| bad art| deformed| mutated| double face\"\n",
        "  ),\n",
        "  (\"Cyberpunked_2\",\n",
        "  1654522787,8.0,50,\n",
        "  \"__token__, cyberpunk, in heavy raining futuristic tokyo rooftop cyberpunk night, sci-fi, fantasy, intricate, very very beautiful, elegant, neon light, highly detailed, digital painting, artstation, concept art, soft light, hdri, smooth, sharp focus, illustration, art by tian zi and craig mullins and wlop and alphonse much\",\n",
        "  \"((missing arms)), ((missing legs)), (((extra arms))), (((extra legs))), (fused fingers), (too many fingers), (((long neck)))\"\n",
        "  ),\n",
        "  (\"Tarrot_card\",\n",
        "  2001405895,7.0,50,\n",
        "  \"__token__ squared head on tarot card with intricate detailed frame around the outside | side profile of cyberpunk body with cyborg skull | cyberpunk | styled in Art Nouveau | insanely detailed | embellishments | high definition | concept art | digital art | vibrant\",\n",
        "  \"((missing arms)), ((missing legs)), (((extra arms))), (((extra legs))), (fused fingers), (too many fingers), (((long neck)))\"\n",
        "  ),\n",
        "  (\"Tarrot_card\",\n",
        "  2001405895,7.0,50,\n",
        "  \"__token__ squared head on tarot card with intricate detailed frame around the outside | side profile of cyberpunk body with cyborg skull | cyberpunk | styled in Art Nouveau | insanely detailed | embellishments | high definition | concept art | digital art | vibrant\",\n",
        "  \"\"\n",
        "  ),\n",
        "  (\"Cyborg\",\n",
        "  558991465,8.0,50,\n",
        "  \"__token__ pixar portrait 8 k photo, beautiful shiny white rich galactic prima ballerina clowncore russian cyborg college girl, golden ratio details, sci - fi, fantasy, cyberpunk, intricate, decadent, highly detailed, digital painting, ever after high, octane render, artstation, concept art, smooth, sharp focus, illustration, art by artgerm, loish, wlop\",\n",
        "  \"lowres| worst quality| low quality| normal quality| signature| blurry| bad anatomy| bad hands| missing fingers| extra digit| fewer digits| cropped\"\n",
        "  ),\n",
        "  (\"The_hippie\",\n",
        "  2001405895,7.0,50,\n",
        "  \"full body render of an alluring god, (__token__:1.1)  as festival hippy with tribal tattoos surrounded by a underwater ink pour and flowing liquid gallium and sacred geometry, perfect body and face, sexy (__ttoken__:0.3), cinematic, beautifully lit, by miho hirano, by karol bak, by donato giancola, 3 d, trending on artstation, octane render, 8 k\",\n",
        "  \"lowres| worst quality| low quality| normal quality| signature| blurry| bad anatomy| bad hands| missing fingers| extra digit| fewer digits| cropped\"\n",
        "  ),\n",
        "  (\"Sango_dream_1\",\n",
        "  428858956,7.0,60,\n",
        "  \"__token__, sango fantasy, fantasy magic, , intricate, sharp focus, illustration, highly detailed, digital painting, concept art, matte, Artgerm and Paul lewin and kehinde wiley, masterpiece\",\n",
        "  \"no words| watermark| bad anatomy| blurry| fuzzy| extra legs| extra arms| extra fingers| poorly drawn hands| poorly drawn feet| disfigured| out of frame| tiling| bad art| deformed| mutated| double face\"\n",
        "  ),\n",
        "  (\"Sango_dream_2\",\n",
        "  4289232563,7.0,30,\n",
        "  \"__token__,  sango fantasy, fantasy magic, , intricate, sharp focus, illustration, highly detailed, digital painting, concept art, matte, Artgerm and Paul lewin and kehinde wiley, masterpiece\",\n",
        "  \"circles, bad anatomy| blurry| fuzzy| extra legs| extra arms| extra fingers| poorly drawn hands| poorly drawn feet| disfigured| out of frame| tiling| bad art| deformed| mutated| double face\"\n",
        "  ),\n",
        "\n",
        "]\n",
        "\n",
        "for prompt_ref,seed,guidance_scale,num_inference_steps,prompt,negative_prompt in auto_prompts:\n",
        "    for modelref,kista_modelname in kista_trainednames:\n",
        "        torch.cuda.empty_cache()\n",
        "        newprompt = prompt.replace(\"__token__\", kista_modelname)\n",
        "        newprompt = newprompt.replace(\"__ttoken__\", \"zkistebc\")\n",
        "\n",
        "        if override_seed:\n",
        "            seed = override_seed\n",
        "\n",
        "        g_cuda = torch.Generator(device='cuda')\n",
        "        g_cuda.manual_seed(seed)\n",
        "\n",
        "        if override_height:\n",
        "            height = override_height\n",
        "        if override_width:\n",
        "            width = override_width\n",
        "        if override_inference_steps:\n",
        "            num_inference_steps = override_inference_steps\n",
        "        if override_guidance_scale:\n",
        "            guidance_scale = override_guidance_scale\n",
        "\n",
        "        print(f\"[*] Prompt   : {newprompt}\")\n",
        "        print(f\"[*] PromptNeg: {negative_prompt}\")\n",
        "        print(f\"[*] seed:{seed},gs:{guidance_scale},steps:{num_inference_steps},{width}x{height},\")\n",
        "        with autocast(\"cuda\"), torch.inference_mode():\n",
        "            images = pipe(\n",
        "                newprompt,\n",
        "                height=height,\n",
        "                width=width,\n",
        "                negative_prompt=negative_prompt,\n",
        "                num_images_per_prompt=num_samples,\n",
        "                num_inference_steps=num_inference_steps,\n",
        "                guidance_scale=guidance_scale,\n",
        "                generator=g_cuda\n",
        "            ).images\n",
        "\n",
        "        image_filenames = []\n",
        "\n",
        "        for img in images:\n",
        "            prefix_count = '_' + f'{saved_file_count:04d}'\n",
        "            final_id = 's' + model_trained_steps_for_filename + 'g' + f'{guidance_scale:01f}' + 'i' + f'{num_inference_steps:03d}' + 's' + f'{seed}'\n",
        "            outfilename = prompt_ref + '_' + modelref + '_' + final_id.replace(\".\", '') + prefix_count\n",
        "            image_filename = outfilename.replace(\" \", '_').replace(\"00000i\", 'i') + '.png'\n",
        "            img.save(images_savepath + \"/\" + image_filename)\n",
        "            image_filenames.append(image_filename)\n",
        "            saved_file_count += 1\n",
        "            print(f\"[*] Saved: {image_filename}\")\n",
        "            #display(img.resize((256, 256)))\n",
        "            #display(img.resize((128, 128)))\n",
        "\n",
        "        image_folder = images_savepath + '/'\n",
        "        grid_row = 1\n",
        "        grid_col = len(image_filenames)\n",
        "        grid_scale = 3\n",
        "        if grid_col > 1:\n",
        "            fig, axes = plt.subplots(grid_row, grid_col, figsize=(grid_col*grid_scale, grid_row*grid_scale), gridspec_kw={'hspace': 0, 'wspace': 0})\n",
        "            for j, image_filename in enumerate(image_filenames):\n",
        "                currAxes = axes[j]\n",
        "                currAxes.set_title(f\"{image_filename[0:5]}\")\n",
        "                image_full_path = os.path.join(image_folder, image_filename)\n",
        "                imgdata = mpimg.imread(image_full_path)\n",
        "                currAxes.imshow(imgdata, cmap='gray')\n",
        "                currAxes.axis('off')\n",
        "            plt.tight_layout()\n",
        "            plt.savefig('grid.png', dpi=72)\n",
        "            plt.show()\n",
        "        else:\n",
        "            display(img.resize(( int(height / 2), int(height / 2) )))\n"
      ],
      "metadata": {
        "id": "vmL-jkniAw6R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Run to generate image(s)\n",
        "\n",
        "prompt = \"\" #@param {type:\"string\"}\n",
        "negative_prompt = \"\" #@param {type:\"string\"}\n",
        "token_name = \"\" #@param {type:\"string\"}\n",
        "num_samples = 2 #@param {type:\"number\"}\n",
        "guidance_scale = 7 #@param {type:\"number\"}\n",
        "num_inference_steps = 50 #@param {type:\"number\"}\n",
        "width = \"512\" #@param [\"512\", \"768\", \"1280\", \"1536\"] {allow-input: true}\n",
        "height = \"512\" #@param [\"512\", \"768\", \"1280\", \"1536\"] {allow-input: true}\n",
        "width = int(width)\n",
        "height = int(height)\n",
        "new_seed = None #@param {type:\"number\"}\n",
        "save_images_path = \"/content/drive/MyDrive/output\" #@param {type:\"string\"}\n",
        "\n",
        "#prompt = prompt.replace(\"__token__\", token_name)\n",
        "\n",
        "x = token_name.split(\",\")\n",
        "for index, value in enumerate(x):\n",
        "    if index == 0:\n",
        "        prompt = prompt.replace(\"__token__\", value)\n",
        "    else:\n",
        "        prompt = prompt.replace(\"__token\" + str(index) + \"__\", value)\n",
        "\n",
        "#raise Exception(1);\n",
        "\n",
        "if new_seed:\n",
        "    g_cuda = torch.Generator(device='cuda')\n",
        "    g_cuda.manual_seed(new_seed)\n",
        "\n",
        "if len(save_images_path):\n",
        "    tmp = save_images_path.split(\"/\")\n",
        "    if len(tmp) == 1:\n",
        "        save_images_path = \"/content/\" + save_images_path\n",
        "    from pathlib import Path\n",
        "    path = Path(save_images_path)\n",
        "    if not path.exists():\n",
        "        print(f\"[*] Create save directory...\")\n",
        "        path.mkdir(parents = False, exist_ok = False)\n",
        "    try:\n",
        "        if not image_save_count:\n",
        "            print('Darn we need this one!')\n",
        "    except NameError:\n",
        "        image_save_count = 1\n",
        "\n",
        "print(f\"[*] Prompt used: {prompt}\")\n",
        "\n",
        "with autocast(\"cuda\"), torch.inference_mode():\n",
        "    images = pipe(\n",
        "        prompt,\n",
        "        height=height,\n",
        "        width=width,\n",
        "        negative_prompt=negative_prompt,\n",
        "        num_images_per_prompt=num_samples,\n",
        "        num_inference_steps=num_inference_steps,\n",
        "        guidance_scale=guidance_scale,\n",
        "        generator=g_cuda\n",
        "    ).images\n",
        "\n",
        "for img in images:\n",
        "    display(img)\n",
        "    if len(save_images_path):\n",
        "        precount = f'{image_save_count:04d}'\n",
        "        image_filename = precount + '_' + prompt.replace(\" \", '_')[:240] + '.png'\n",
        "        img.save(save_images_path + \"/\" + image_filename)\n",
        "        image_save_count += 1"
      ],
      "metadata": {
        "id": "LF3LbP6mAxdV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}