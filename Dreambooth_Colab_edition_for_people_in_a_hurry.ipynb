{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/steinhaug/stable-diffusion/blob/main/Dreambooth_Colab_edition_for_people_in_a_hurry.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BzM7j0ZSc_9c"
      },
      "source": [
        "# Dreambooth - Colab edition for people in a hurry\n",
        "\n",
        "I will get you up and running with a trained AI model of your concept, create some stunning AI Images for you, you can make your own aswell, and we will save and backup your model at huggingface website. All for free, and all without you needing to get into any juicy AI jargon or machine learning understanding. Basically, breath out breath in... you want some AI images and test it out? Lets go.. I will not bother you with any advanced syntax data modelling or coneptual understanding of blah blah ballabbba...<br>\n",
        "\n",
        "<br>Time required to complete this demo:<br>\n",
        "90 minutes, and that includes training time so lets go!\n",
        "\n",
        "---\n",
        "\n",
        "Credits: [This notebook](https://colab.research.google.com/github/steinhaug/stable-diffusion/blob/main/stable_diffusion_demonstration.ipynb) is maintained by [Steinhaug](https://github.com/steinhaug) and is derived work based on the [Dreambooth](https://github.com/ShivamShrirao/diffusers/tree/main/examples/dreambooth) notebook by [ShivamShrirao](https://github.com/ShivamShrirao/) and the [Dreambooth](https://github.com/TheLastBen/fast-stable-diffusion) notebook by [TheLastBen](https://github.com/TheLastBen).\n",
        "<br>\n",
        "[![Buy me a beer](https://raw.githubusercontent.com/steinhaug/stable-diffusion/main/assets/buy-me-a-beer.png ) ](https://steinhaug.com/donate/)\n",
        "\n",
        "<br>\n",
        "\n",
        "![Init](https://raw.githubusercontent.com/steinhaug/stable-diffusion/main/assets/notebook-setup.png)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Checklist:\n",
        "1. You have created an account on huggingface.co and retrieved your write access token\n",
        "2. You already have a google account, or you have registered a new Google Account, so you can access Drive, Colab and Gmail services.\n",
        "3. You have prepared 10 images of what you want to train the AI model to understand, they have been cropped for 512x512. (birme.net site) \n",
        "\n",
        "if thats all good... lets go!"
      ],
      "metadata": {
        "id": "mMr93d_vsOJ9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "cellView": "form",
        "id": "XU7NuMAA2drw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5bf9c18a-59b0-44e4-a8c8-8fe38ee1e661"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mon Feb 20 11:05:31 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 510.47.03    Driver Version: 510.47.03    CUDA Version: 11.6     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  NVIDIA A100-SXM...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   33C    P0    49W / 400W |      0MiB / 40960MiB |      0%      Default |\n",
            "|                               |                      |             Disabled |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "#@title System check - Verify that we are running with a GPU\n",
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title System check - Check memory\n",
        "from psutil import virtual_memory\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('Not using a high-RAM runtime')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')"
      ],
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c2LdrM72v3oL",
        "outputId": "cef0238f-3735-4e5f-b98c-7f5d551aff9f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Your runtime has 89.6 gigabytes of available RAM\n",
            "\n",
            "You are using a high-RAM runtime!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Setup 1/3: Connect and mount drive\n",
        "#@markdown You will need 8 GB free space on your Google Drive to complete this AI Demo<br>\n",
        "#@markdown Tip: If you dont have that much available, register an extra Google Account. Its free :)\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "NwjiODwM9jQ1",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e87a9c8-683e-4e67-e6f3-92cc36474a3f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Setup 2/3: Add your identifiers\n",
        "%cd /content\n",
        "HUGGINGFACE_TOKEN = \"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\" #@param {type:\"string\"}\n",
        "!mkdir -p ~/.cache\n",
        "!mkdir -p ~/.cache/huggingface\n",
        "!echo -n \"{HUGGINGFACE_TOKEN}\" > ~/.cache/huggingface/token\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "PnyTBagf2EH8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Setup 2/3: Add your identifiers\n",
        "\n",
        "%cd /content\n",
        "save_to_gdrive = False #@param {type:\"boolean\"}\n",
        "\n",
        "PARENT_DIR = \"stable_diffusion_weights_4\" #@param {type:\"string\"}\n",
        "YOUR_TOKEN = \"annelene\" #@param {type:\"string\"}\n",
        "TOKEN_CLASS = \"woman\" #@param [\"person\", \"woman\", \"man\"] {allow-input: true}\n",
        "\n",
        "YOUR_TOKEN_FULL = YOUR_TOKEN + \" \" + TOKEN_CLASS\n",
        "\n",
        "concepts_list = [\n",
        "    {\n",
        "        \"instance_prompt\":      \"portrait of x_\" + YOUR_TOKEN_FULL,\n",
        "        \"class_prompt\":         \"portrait of a woman\",\n",
        "        \"instance_data_dir\":    \"/content/drive/MyDrive/data/x_\" + YOUR_TOKEN + \"_v2\",\n",
        "        \"class_data_dir\":       \"/content/drive/MyDrive/data/a_woman-300\"\n",
        "    },\n",
        "    {\n",
        "        \"instance_prompt\":      \"x2_\" + YOUR_TOKEN_FULL,\n",
        "        \"class_prompt\":         \"a woman\",\n",
        "        \"instance_data_dir\":    \"/content/drive/MyDrive/data/x_\" + YOUR_TOKEN + \"_v2\",\n",
        "        \"class_data_dir\":       \"/content/data/woman_art-300\"\n",
        "    },\n",
        "    {\n",
        "        \"instance_prompt\":      \"photo of x_tentando Leopard Gecko\",\n",
        "        \"class_prompt\":         \"photo of a Leopard Gecko\",\n",
        "        \"instance_data_dir\":    \"/content/drive/MyDrive/data/x_tentando\",\n",
        "        \"class_data_dir\":       \"/content/drive/MyDrive/data/leopard-gecko\"\n",
        "    },\n",
        "]\n",
        "\n",
        "YOUR_TOKEN = \"x_\" + YOUR_TOKEN\n",
        "YOUR_TOKEN_FULL = \"x_\" + YOUR_TOKEN_FULL\n",
        "\n",
        "import json\n",
        "import os\n",
        "for c in concepts_list:\n",
        "    os.makedirs(c[\"instance_data_dir\"], exist_ok=True)\n",
        "\n",
        "with open(\"concepts_list.json\", \"w\") as f:\n",
        "    json.dump(concepts_list, f, indent=4)\n",
        "\n",
        "from google.colab import drive\n",
        "\n",
        "MODEL_NAME = \"runwayml/stable-diffusion-v1-5\"\n",
        "OUTPUT_DIR = PARENT_DIR + \"/\" + YOUR_TOKEN\n",
        "\n",
        "if save_to_gdrive:\n",
        "    OUTPUT_DIR = \"/content/drive/MyDrive/\" + OUTPUT_DIR\n",
        "else:\n",
        "    OUTPUT_DIR = \"/content/\" + OUTPUT_DIR\n",
        "\n",
        "!mkdir -p $OUTPUT_DIR\n",
        "\n",
        "from IPython.display import clear_output; clear_output(); print('\u001b[1;32mDone! ✓')\n",
        "print(f\"Token: {YOUR_TOKEN}\")\n",
        "print(f\"Full token: {YOUR_TOKEN_FULL}\")\n",
        "print(f\"Output dir: {OUTPUT_DIR}\")\n"
      ],
      "metadata": {
        "id": "QpN7E3zuV8SY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "174006ae-4a84-4ec3-d620-1afc713c9934"
      },
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;32mDone! ✓\n",
            "Token: x_annelene\n",
            "Full token: x_annelene woman\n",
            "Output dir: /content/stable_diffusion_weights_4/x_annelene\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "32gYIDDR1aCp",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Setup 3/3: Upload your training images, 10 in total, all 512x512 cropped\n",
        "\n",
        "import os\n",
        "from google.colab import files\n",
        "import shutil\n",
        "\n",
        "for c in concepts_list:\n",
        "    print(f\"Uploading instance images for `{c['instance_prompt']}`\")\n",
        "    uploaded = files.upload()\n",
        "    for filename in uploaded.keys():\n",
        "        dst_path = os.path.join(c['instance_data_dir'], filename)\n",
        "        shutil.move(filename, dst_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PART 1.0: Setup environment for training your model.\n",
        "![Training](https://raw.githubusercontent.com/steinhaug/stable-diffusion/main/assets/notebook-training.png)\n",
        "<br>\n",
        "What to do: Play the cells  \n",
        "_Estimated time to complete: 1hour 30 minutes_\n"
      ],
      "metadata": {
        "id": "e0xAX_SnbP1H"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "aLWXPZqjsZVV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4c98e3e3-7dfa-4288-8a42-18c88f1fb1a5",
        "cellView": "form"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;32mDone! ✓\n"
          ]
        }
      ],
      "source": [
        "#@title 1/3 Install libraries\n",
        "from IPython.display import clear_output\n",
        "%cd /content/\n",
        "!wget -q https://github.com/steinhaug/diffusers/raw/main/examples/dreambooth/train_dreambooth.py\n",
        "!wget -q https://github.com/steinhaug/diffusers/raw/main/scripts/convert_original_stable_diffusion_to_diffusers.py\n",
        "!wget -q https://github.com/steinhaug/diffusers/raw/main/scripts/convert_diffusers_to_original_stable_diffusion.py\n",
        "%pip install -qq git+https://github.com/steinhaug/diffusers\n",
        "%pip install -q -U --pre triton\n",
        "%pip install -q accelerate transformers ftfy bitsandbytes==0.35.0 gradio natsort safetensors xformers\n",
        "clear_output()\n",
        "print('\u001b[1;32mDone! ✓')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 2/3 Set up regularization images\n",
        "from pathlib import Path\n",
        "from IPython.display import clear_output\n",
        "from zipfile import ZipFile\n",
        "path = Path(\"/content/data\")\n",
        "if not path.exists():\n",
        "  path.mkdir(parents = False, exist_ok = False)\n",
        "%cd /content/data\n",
        "#!wget -O woman_art-100.zip https://huggingface.co/datasets/steinhaug/regularization/resolve/main/woman_art-100.zip\n",
        "!wget -O woman_art-300.zip https://huggingface.co/datasets/steinhaug/regularization/resolve/main/woman_art-300.zip\n",
        "with ZipFile(\"/content/data/woman_art-300.zip\", 'r') as zObject:\n",
        "    zObject.extractall(path=\"/content/data\")\n",
        "clear_output()\n",
        "print('\u001b[1;32mDone! ✓')"
      ],
      "metadata": {
        "id": "u3-a9pacZBzD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba2eecfc-64ee-4064-e399-d6e689a6912c",
        "cellView": "form"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;32mDone! ✓\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title misc, various manual\n",
        "!rm -Rf /content/stable_diffusion_weights_4\n",
        "\n",
        "#%cd /content/\n",
        "#!rm train_dreambooth.py\n",
        "#!wget -q https://github.com/steinhaug/diffusers/raw/main/examples/dreambooth/train_dreambooth.py\n",
        "\n",
        "#SAMPLE_PROMPT = '\"' + YOUR_TOKEN + \" Leopard Gecko sitting on a shoulder, highly saturated colors, concept art, Dan Mumford, Greg rutkowski\" + '\"'\n",
        "#SAMPLE_PROMPT = '\"' + YOUR_TOKEN + \" woman as strong warrior princess| centered| key visual| intricate| highly detailed| breathtaking beauty| precise lineart| vibrant| comprehensive cinematic| Carne Griffiths| Conrad Roset\" + '\"'\n",
        "#SAMPLE_PROMPT2 = '\"' + YOUR_TOKEN + \" woman\" + '\"'\n",
        "\n",
        "# 5e-6 1e-6 3e-6\n",
        "#  --mixed_precision=\"fp16\" \\\n",
        "#  --gradient_checkpointing \\\n",
        "#  --use_8bit_adam \\\n",
        "#  --gradient_accumulation_steps=1 \\\n",
        "#  --revision=\"fp16\" \\\n",
        "#MODEL_NAME = \"/content/stable_diffusion_weights/x_annelene/600\""
      ],
      "metadata": {
        "cellView": "form",
        "id": "m-HPf-0N8-uV"
      },
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Manual - delete folders\n",
        "from os import path\n",
        "\n",
        "#KEEP_SAMPLES = False #@param {type:\"boolean\"}\n",
        "TMPS_DIR = \"/content/stable_diffusion_weights_3/x_annelene/\" #@param {type:\"string\"}\n",
        "FOLDERS_TO_DELETE = \"0,100,200,300,400,500,600,700,800,900,1100,1200,1300,1400,1500,1600,1700,1800,1900,2000\" #@param {type:\"string\"}\n",
        "\n",
        "import ast\n",
        "TMPS_ARR = ast.literal_eval('[' + FOLDERS_TO_DELETE + ']')\n",
        "#TMPS_DIR = \"/content/stable_diffusion_weights_3/x_annelene/\"\n",
        "#TMPS_ARR = [0,100,200,300,400,500,600,700,800,900,1100,1200,1300,1400,1500,1600,1700,1800,1900,2000]\n",
        "\n",
        "if path.exists(TMPS_DIR) == False:\n",
        "    raise Exception(f\"[*] soft abort on 404... {TMPS_DIR} doesnt exist!\")\n",
        "\n",
        "for var_steps in TMPS_ARR:\n",
        "    PATH_TO_DELETE = TMPS_DIR + f'{var_steps}'\n",
        "    if path.exists(PATH_TO_DELETE) == False:\n",
        "        #raise Exception(f\"[*] 404... {PATH_TO_DELETE} does not exist!\")\n",
        "        print(f\"404, skipping {PATH_TO_DELETE}\")\n",
        "    else:\n",
        "        !rm -Rf $PATH_TO_DELETE\n",
        "        print(f\"Removed {PATH_TO_DELETE}\")\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "M7FmnQXqGdQZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jjcSXTp-u-Eg"
      },
      "outputs": [],
      "source": [
        "#@title 3/3 Start training - eta: 90 minutes...\n",
        "%cd /content/\n",
        "SAMPLE_PROMPT = '\"' + YOUR_TOKEN_FULL + \", Masterpiece, digital oil painting, cyberpunk style, symmetrical face\" + '\"'\n",
        "SAMPLE_PROMPT2 = '\"x2_annelene woman, Masterpiece, digital oil painting, cyberpunk style, symmetrical face\"'\n",
        "\n",
        "MODEL_NAME = \"/content/stable_diffusion_weights_2/x_annelene/500\"\n",
        "\n",
        "!accelerate launch train_dreambooth.py \\\n",
        "  --pretrained_model_name_or_path=$MODEL_NAME \\\n",
        "  --pretrained_vae_name_or_path=\"stabilityai/sd-vae-ft-mse\" \\\n",
        "  --output_dir=$OUTPUT_DIR \\\n",
        "  --revision=\"main\" \\\n",
        "  --with_prior_preservation --prior_loss_weight=1.0 \\\n",
        "  --seed=69 \\\n",
        "  --resolution=512 \\\n",
        "  --train_batch_size=1 \\\n",
        "  --train_text_encoder \\\n",
        "  --mixed_precision=\"no\" \\\n",
        "  --use_8bit_adam \\\n",
        "  --gradient_checkpointing \\\n",
        "  --gradient_accumulation_steps=1 \\\n",
        "  --learning_rate=2e-6 \\\n",
        "  --lr_scheduler=\"constant\" \\\n",
        "  --lr_warmup_steps=0 \\\n",
        "  --num_class_images=300 \\\n",
        "  --sample_batch_size=8 \\\n",
        "  --max_train_steps=2000 \\\n",
        "  --save_interval=100 \\\n",
        "  --save_min_steps=100 \\\n",
        "  --n_save_sample=8 \\\n",
        "  --save_sample_prompt=$SAMPLE_PROMPT \\\n",
        "  --save_sample_negative_prompt=\"\" \\\n",
        "  --save_sample_prompt_2=$SAMPLE_PROMPT2 \\\n",
        "  --save_sample_negative_prompt_2=\"\" \\\n",
        "  --save_sample_prompt_3=\"x_annelene woman\" \\\n",
        "  --save_sample_negative_prompt_2=\"\" \\\n",
        "  --concepts_list=\"concepts_list.json\"\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PART 2.0: Configure and load your model, ready to create AI images\n",
        "![Systemstart](https://raw.githubusercontent.com/steinhaug/stable-diffusion/main/assets/notebook-startup.png)\n",
        "<br>\n",
        "This part creates a so called .cpkt file from your trained model, and loads the envoronment needed for writing prompts.  \n",
        "  \n",
        "What do I need to do: press play, run both cells  \n",
        "_Estimated time to complete: 1 minute_\n"
      ],
      "metadata": {
        "id": "BCyzeaKdv58y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "WEIGHTS_DIR = \"/content/stable_diffusion_weights_4/x_annelene/1100\" #@param {type:\"string\"}\n",
        "#@markdown Leave empty / skip for current directory\n",
        "if WEIGHTS_DIR == \"\":\n",
        "    from natsort import natsorted\n",
        "    from glob import glob\n",
        "    import os\n",
        "    WEIGHTS_DIR = natsorted(glob(OUTPUT_DIR + os.sep + \"*\"))[-1]\n",
        "print(f\"[*] WEIGHTS_DIR={WEIGHTS_DIR}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a00bhA82j3hY",
        "outputId": "555208d8-c987-4faf-f33c-db6763cf1b9b"
      },
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[*] WEIGHTS_DIR=/content/stable_diffusion_weights_4/x_annelene/1100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## grid"
      ],
      "metadata": {
        "id": "4efVP0gx_zor"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 3/4 Generate a grid of preview images from the saved checkpoints\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "\n",
        "SAMPLES_DIR = \"samples\" #@param [\"samples\", \"samples_2\", \"samples_3\", \"samples_4\"]\n",
        "MERGE_SAMPLE_FOLDERS = True #@param {type:\"boolean\"}\n",
        "\n",
        "weights_folder = OUTPUT_DIR\n",
        "\n",
        "folders = sorted([f for f in os.listdir(weights_folder) if f != \"0\"], key=lambda x: int(x))\n",
        "\n",
        "if SAMPLES_DIR != \"samples\":\n",
        "    MERGE_SAMPLE_FOLDERS = False\n",
        "row = len(folders)\n",
        "if MERGE_SAMPLE_FOLDERS:\n",
        "    row = row * 2\n",
        "col = len(os.listdir(os.path.join(weights_folder, folders[0], SAMPLES_DIR)))\n",
        "scale = 4\n",
        "fig, axes = plt.subplots(row, col, figsize=(col*scale, row*scale), gridspec_kw={'hspace': 0, 'wspace': 0})\n",
        "\n",
        "i2 = 0\n",
        "for i, folder in enumerate(folders):\n",
        "    folder_path = os.path.join(weights_folder, folder)\n",
        "    image_folder = os.path.join(folder_path, SAMPLES_DIR)\n",
        "    images = [f for f in os.listdir(image_folder)]\n",
        "    for j, image in enumerate(images):\n",
        "        if row == 1:\n",
        "            currAxes = axes[j]\n",
        "        else:\n",
        "            currAxes = axes[i2, j]\n",
        "        if i == 0:\n",
        "            currAxes.set_title(f\"Image {j}\")\n",
        "        if j == 0:\n",
        "            if MERGE_SAMPLE_FOLDERS:\n",
        "                currAxes.text(-0.1, 0.5, \"S1 \" + folder, rotation=0, va='center', ha='center', transform=currAxes.transAxes)\n",
        "            else:\n",
        "                currAxes.text(-0.1, 0.5, folder, rotation=0, va='center', ha='center', transform=currAxes.transAxes)\n",
        "        image_path = os.path.join(image_folder, image)\n",
        "        img = mpimg.imread(image_path)\n",
        "        currAxes.imshow(img, cmap='gray')\n",
        "        currAxes.axis('off')\n",
        "\n",
        "    if MERGE_SAMPLE_FOLDERS:\n",
        "        i2 += 1\n",
        "        image_folder = os.path.join(folder_path, \"samples_2\")\n",
        "        images = [f for f in os.listdir(image_folder)]\n",
        "        for j, image in enumerate(images):\n",
        "            currAxes = axes[i2, j]\n",
        "            if j == 0:\n",
        "                currAxes.text(-0.1, 0.5, \"S2 \" + folder, rotation=0, va='center', ha='center', transform=currAxes.transAxes)\n",
        "            image_path = os.path.join(image_folder, image)\n",
        "            img = mpimg.imread(image_path)\n",
        "            currAxes.imshow(img, cmap='gray')\n",
        "            currAxes.axis('off')\n",
        "    i2 += 1\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(f'{saved_grid_count:04d}' + \"_\" + SAMPLES_DIR + '_grid.png', dpi=72)\n",
        "saved_grid_count += 1"
      ],
      "metadata": {
        "id": "P5r6x9-8juPt",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 125,
      "metadata": {
        "id": "89Az5NUxOWdy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "outputId": "761836ee-c292-45a1-b3aa-c43bb55371ef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;32mDone! ✓\n",
            "[*] Converted ckpt saved at /content/stable_diffusion_weights_4/x_annelene/1100/model.ckpt\n"
          ]
        }
      ],
      "source": [
        "#@title 2/3 Create CPKT model\n",
        "\n",
        "fp16 = True #@param {type:\"boolean\"}\n",
        "\n",
        "if WEIGHTS_DIR == \"\":\n",
        "    from natsort import natsorted\n",
        "    from glob import glob\n",
        "    import os\n",
        "    WEIGHTS_DIR = natsorted(glob(OUTPUT_DIR + os.sep + \"*\"))[-1]\n",
        "\n",
        "from os import path\n",
        "if path.exists(WEIGHTS_DIR) == False:\n",
        "  raise Exception(f\"[*] WEIGHTS_DIR does not exist!\")\n",
        "\n",
        "print(f\"[*] Creating ckpt model....\")\n",
        "\n",
        "%cd /content/\n",
        "ckpt_path = WEIGHTS_DIR + \"/model.ckpt\"\n",
        "half_arg = \"\"\n",
        "\n",
        "if fp16:\n",
        "    half_arg = \"--half\"\n",
        "!python convert_diffusers_to_original_stable_diffusion.py --model_path $WEIGHTS_DIR  --checkpoint_path $ckpt_path $half_arg\n",
        "\n",
        "from IPython.display import clear_output; clear_output(); print('\u001b[1;32mDone! ✓')\n",
        "print(f\"[*] Converted ckpt saved at {ckpt_path}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## init"
      ],
      "metadata": {
        "id": "Ag8aHB4h_4yP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "metadata": {
        "id": "gW15FjffdTID",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c008fb41-16ee-4370-b8fd-31d07eb03c4f",
        "cellView": "form"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;32mDone! ✓\n"
          ]
        }
      ],
      "source": [
        "#@title 3/3 Initialize stable diffusion from folder \n",
        "import torch\n",
        "from torch import autocast\n",
        "from diffusers import StableDiffusionPipeline, DDIMScheduler\n",
        "from IPython.display import display\n",
        "\n",
        "model_path = WEIGHTS_DIR             # If you want to use previously trained model saved in gdrive, replace this with the full path of model in gdrive\n",
        "\n",
        "pipe = StableDiffusionPipeline.from_pretrained(model_path, safety_checker=None, torch_dtype=torch.float16).to(\"cuda\")\n",
        "pipe.scheduler = DDIMScheduler.from_config(pipe.scheduler.config)\n",
        "pipe.enable_xformers_memory_efficient_attention()\n",
        "g_cuda = None\n",
        "\n",
        "g_cuda = torch.Generator(device='cuda')\n",
        "seed = 1\n",
        "g_cuda.manual_seed(seed)\n",
        "saved_file_count = 1;\n",
        "\n",
        "from IPython.display import clear_output; clear_output(); print('\u001b[1;32mDone! ✓')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PART 3.0: Auto-mode, time to create some AI Images... Press play\n",
        "![Bonus](https://raw.githubusercontent.com/steinhaug/stable-diffusion/main/assets/notebook-bonus.png)\n",
        "\n"
      ],
      "metadata": {
        "id": "on9i_ums35pT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Before you try crafting your own prompt you can play the first cell below and I will create alot of AI Images for you so you can have some fun without needing to do pretty much anything :) Can't make it simpler than this to be honest!\n",
        "\n",
        "When this is done go to the next cell and you are ready to try out yourself, I have added a quick tutorial for you so you get the hang of it. What you need to know is that great images require some effort and skill in prompting so this is actually quite reqarding work when you start playing around with it. I will make more videoes with more tips here if people are interested, but for now! Lets see some AI Magic!"
      ],
      "metadata": {
        "id": "flFar9i6cstB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Run to execute batch\n",
        "import os.path\n",
        "from os import path\n",
        "from IPython.display import display\n",
        "import ast\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "\n",
        "model_trained_steps_for_filename = 'auto' #@param {type:\"string\"}\n",
        "num_samples = 2 #@param {type:\"number\"}\n",
        "images_savepath = '/content/drive/MyDrive/AI-Images' #@param {type:\"string\"}\n",
        "\n",
        "#@markdown Syntax: ('reference name', 'trained instance name')<br>\n",
        "#@markdown Overrides leave empty if not to be used\n",
        "n_override_width = None #@param {type:\"number\"}\n",
        "n_override_height = None #@param {type:\"number\"}\n",
        "n_override_seed = None #@param {type:\"number\"}\n",
        "n_override_guidance_scale = None #@param {type:\"number\"}\n",
        "n_override_inference_steps = None #@param {type:\"number\"}\n",
        "\n",
        "width = 512\n",
        "height = 512\n",
        "\n",
        "if path.exists(images_savepath) == False:\n",
        "  os.mkdir(images_savepath)\n",
        "\n",
        "auto_prompts = [\n",
        " \n",
        "  (\"warrior_poster\",\n",
        "  696969,8.0,50,\n",
        "  \"poster of __token__ , big boobs, warrior goddess| standing alone on hill| centered| detailed gorgeous face| anime style| key visual| intricate detail| highly detailed| breathtaking| vibrant| panoramic| cinematic| Carne Griffiths| Conrad Roset| Makoto Shinkai\",\n",
        "  \"blurry| fuzzy| extra fingers| disfigured| cropped| bad fingers| deformed fingers| mutated fingers| out of frame\", 0\n",
        "  ),\n",
        "  (\"halloween_man_1\",\n",
        "  2971107907,7.5,50,\n",
        "  \"The personification of the Halloween holiday played by (__ttoken__:0.95), portraited as a (__token__:0.5) with short hair and a villain's smile and a cute hat, cute cheeks, unreal engine, highly detailed, artgerm digital illustration, by Alexei Vinogradov bakery, sweets, emerald eyes\",\n",
        "  \"bad anatomy, extra legs, extra arms, poorly drawn face, poorly drawn hands, poorly drawn feet, fat, disfigured, out of frame, long neck, poo art, bad hands, bad art, deformed, gun, double head, flowers,asian,hyperrealistic,child\", 33\n",
        "  ),\n",
        "  (\"warrior\",\n",
        "  16,8.0,75,\n",
        "  \"__token__ as strong warrior princess| centered| key visual| intricate| highly detailed| breathtaking beauty| precise lineart| vibrant| comprehensive cinematic| Carne Griffiths| Conrad Roset\",\n",
        "  \"bad anatomy, extra legs, extra arms, poorly drawn face, poorly drawn hands, poorly drawn feet, fat, disfigured, out of frame, long neck, poo art, bad hands, bad art, deformed, gun, double head, flowers,asian,hyperrealistic,child\", 100\n",
        "  ),\n",
        "  (\"warrior_sketch\",\n",
        "  16,8.0,75,\n",
        "  \"__token__ as strong warrior king| centered| key visual| intricate| highly detailed| breathtaking beauty| precise lineart| vibrant| comprehensive cinematic| Carne Griffiths| Conrad Roset\",\n",
        "  \"\", 100\n",
        "  ),\n",
        "  (\"warrior_sketch\",\n",
        "  16,8.0,25,\n",
        "  \"__token__ as strong warrior princess| centered| key visual| intricate| highly detailed| breathtaking beauty| precise lineart| vibrant| comprehensive cinematic| Carne Griffiths| Conrad Roset\",\n",
        "  \"\", 0\n",
        "  ),\n",
        "  (\"punk_face\",\n",
        "  422313768,7.5,50,\n",
        "  \"(__ttoken__:0.25), detailed (bladerunner:1.5) portrait of Punk (__token__:1.2), (standing hair line:2), Sheen Holographic Futuristic sci-fi fashion cyberpunk, neotokyo, synthwave, (aesthetics), futuristic, art by greg rutkowski Alexandros Pyromallis Nekro Rene Margitte\",\n",
        "  \"\", 0\n",
        "  ),\n",
        "  (\"Cyberpunked_1\",\n",
        "  1654522787,7.5,50,\n",
        "  \"cyberpunk (__token__:1.5) in heavy raining futuristic tokyo rooftop cyberpunk night, sci-fi, __ttoken__ fantasy, intricate, very very beautiful, elegant, neon light, highly detailed, digital painting, artstation, concept art, soft light, hdri, smooth, sharp focus, illustration| art by tian zi| craig mullins| wlop| alphonse much\",\n",
        "  \"no words| watermark| bad anatomy| blurry| fuzzy| extra legs| extra arms| extra fingers| poorly drawn hands| poorly drawn feet| disfigured| out of frame| tiling| bad art| deformed| mutated| double face\", 0\n",
        "  ),\n",
        "  (\"Cyberpunked_2\",\n",
        "  1654522787,8.0,50,\n",
        "  \"__token__, cyberpunk, in heavy raining futuristic tokyo rooftop cyberpunk night, sci-fi, fantasy, intricate, very very beautiful, elegant, neon light, highly detailed, digital painting, artstation, concept art, soft light, hdri, smooth, sharp focus, illustration, art by tian zi and craig mullins and wlop and alphonse much\",\n",
        "  \"((missing arms)), ((missing legs)), (((extra arms))), (((extra legs))), (fused fingers), (too many fingers), (((long neck)))\", 0\n",
        "  ),\n",
        "  (\"Tarrot_card\",\n",
        "  2001405895,7.0,50,\n",
        "  \"__token__ squared head on tarot card with intricate detailed frame around the outside | side profile of cyberpunk body with cyborg skull | cyberpunk | styled in Art Nouveau | insanely detailed | embellishments | high definition | concept art | digital art | vibrant\",\n",
        "  \"((missing arms)), ((missing legs)), (((extra arms))), (((extra legs))), (fused fingers), (too many fingers), (((long neck)))\", 150\n",
        "  ),\n",
        "  (\"Tarrot_card\",\n",
        "  2001405895,7.0,50,\n",
        "  \"__token__ squared head on tarot card with intricate detailed frame around the outside | side profile of cyberpunk body with cyborg skull | cyberpunk | styled in Art Nouveau | insanely detailed | embellishments | high definition | concept art | digital art | vibrant\",\n",
        "  \"\", 0\n",
        "  ),\n",
        "  (\"Cyborg\",\n",
        "  558991465,8.0,50,\n",
        "  \"__token__ pixar portrait 8 k photo, beautiful shiny white rich galactic prima ballerina clowncore russian cyborg college girl, golden ratio details, sci - fi, fantasy, cyberpunk, intricate, decadent, highly detailed, digital painting, ever after high, octane render, artstation, concept art, smooth, sharp focus, illustration, art by artgerm, loish, wlop\",\n",
        "  \"lowres| worst quality| low quality| normal quality| signature| blurry| bad anatomy| bad hands| missing fingers| extra digit| fewer digits| cropped\", 25\n",
        "  ),\n",
        "  (\"The_hippie\",\n",
        "  2001405895,7.0,50,\n",
        "  \"full body render of an alluring god, (__token__:1.1)  as festival hippy with tribal tattoos surrounded by a underwater ink pour and flowing liquid gallium and sacred geometry, perfect body and face, sexy (__ttoken__:0.3), cinematic, beautifully lit, by miho hirano, by karol bak, by donato giancola, 3 d, trending on artstation, octane render, 8 k\",\n",
        "  \"lowres| worst quality| low quality| normal quality| signature| blurry| bad anatomy| bad hands| missing fingers| extra digit| fewer digits| cropped\", 0\n",
        "  ),\n",
        "  (\"Sango_dream_1\",\n",
        "  428858956,7.0,60,\n",
        "  \"__token__, sango fantasy, fantasy magic, , intricate, sharp focus, illustration, highly detailed, digital painting, concept art, matte, Artgerm and Paul lewin and kehinde wiley, masterpiece\",\n",
        "  \"no words| watermark| bad anatomy| blurry| fuzzy| extra legs| extra arms| extra fingers| poorly drawn hands| poorly drawn feet| disfigured| out of frame| tiling| bad art| deformed| mutated| double face\", 100\n",
        "  ),\n",
        "  (\"Sango_dream_2\",\n",
        "  4289232563,7.0,30,\n",
        "  \"__token__,  sango fantasy, fantasy magic, , intricate, sharp focus, illustration, highly detailed, digital painting, concept art, matte, Artgerm and Paul lewin and kehinde wiley, masterpiece\",\n",
        "  \"circles, bad anatomy| blurry| fuzzy| extra legs| extra arms| extra fingers| poorly drawn hands| poorly drawn feet| disfigured| out of frame| tiling| bad art| deformed| mutated| double face\", 25\n",
        "  ),\n",
        "\n",
        "]\n",
        "\n",
        "#    \n",
        "autoresolutions = [\n",
        "  (512,512,256,256,2), (512,1080,128,270,2), (512,768,128,192,2), \n",
        "  (768,512,192,128,2), (1536,512,384,128,1)\n",
        "]\n",
        "\n",
        "print(f\"[*] All AI-Images are saved to your Google Drive in the folder: AI-art \")\n",
        "print(f\"[*] ... \")\n",
        "\n",
        "for width, height, scaleWidth, scaleHeight, num_samples in autoresolutions:\n",
        "    print(f\"[*] Generating images in {width} x {height}.... \")\n",
        "    print(f\"[*] .. displaying thumbnails of completed images...\")\n",
        "    for prompt_ref,seed,guidance_scale,num_inference_steps,prompt,negative_prompt,filter_x in auto_prompts:\n",
        "\n",
        "        if width == 1536:\n",
        "            if filter_x == 0:\n",
        "                continue;\n",
        "            num_inference_steps = filter_x\n",
        "\n",
        "        modelref = YOUR_TOKEN\n",
        "        torch.cuda.empty_cache()\n",
        "        newprompt = prompt.replace(\"__token__\", YOUR_TOKEN_FULL)\n",
        "        newprompt = newprompt.replace(\"__ttoken__\", YOUR_TOKEN)\n",
        "\n",
        "        if n_override_seed:\n",
        "            seed = n_override_seed\n",
        "\n",
        "        g_cuda = torch.Generator(device='cuda')\n",
        "        g_cuda.manual_seed(seed)\n",
        "\n",
        "        if n_override_height:\n",
        "            height = n_override_height\n",
        "        if n_override_width:\n",
        "            width = n_override_width\n",
        "        if n_override_inference_steps:\n",
        "            num_inference_steps = n_override_inference_steps\n",
        "        if n_override_guidance_scale:\n",
        "            guidance_scale = n_override_guidance_scale\n",
        "\n",
        "        #print(f\"[*] Prompt   : {newprompt}\")\n",
        "        #print(f\"[*] PromptNeg: {negative_prompt}\")\n",
        "        #print(f\"[*] seed:{seed},gs:{guidance_scale},steps:{num_inference_steps},{width}x{height},\")\n",
        "        with autocast(\"cuda\"), torch.inference_mode():\n",
        "            images = pipe(\n",
        "                newprompt,\n",
        "                height=height,\n",
        "                width=width,\n",
        "                negative_prompt=negative_prompt,\n",
        "                num_images_per_prompt=num_samples,\n",
        "                num_inference_steps=num_inference_steps,\n",
        "                guidance_scale=guidance_scale,\n",
        "                generator=g_cuda\n",
        "            ).images\n",
        "\n",
        "        image_filenames = []\n",
        "\n",
        "        for img in images:\n",
        "            prefix_count = '_' + f'{saved_file_count:04d}'\n",
        "            final_id = 's' + model_trained_steps_for_filename + 'g' + f'{guidance_scale:01f}' + 'i' + f'{num_inference_steps:03d}' + 's' + f'{seed}'\n",
        "            outfilename = prompt_ref + '_' + modelref + '_' + final_id.replace(\".\", '') + prefix_count\n",
        "            image_filename = outfilename.replace(\" \", '_').replace(\"00000i\", 'i') + '.png'\n",
        "            img.save(images_savepath + \"/\" + image_filename)\n",
        "            image_filenames.append(image_filename)\n",
        "            saved_file_count += 1\n",
        "\n",
        "        image_folder = images_savepath + '/'\n",
        "        grid_row = 1\n",
        "        grid_col = len(image_filenames)\n",
        "        grid_scale = 3\n",
        "        if grid_col > 1:\n",
        "            fig, axes = plt.subplots(grid_row, grid_col, figsize=(grid_col*grid_scale, grid_row*grid_scale), gridspec_kw={'hspace': 0, 'wspace': 0})\n",
        "            for j, image_filename in enumerate(image_filenames):\n",
        "                currAxes = axes[j]\n",
        "                currAxes.set_title(f\"{image_filename[0:5]}\")\n",
        "                image_full_path = os.path.join(image_folder, image_filename)\n",
        "                imgdata = mpimg.imread(image_full_path)\n",
        "                currAxes.imshow(imgdata, cmap='gray')\n",
        "                currAxes.axis('off')\n",
        "            plt.tight_layout()\n",
        "            plt.savefig('grid.png', dpi=72)\n",
        "            plt.show()\n",
        "        else:\n",
        "            display(img.resize((scaleWidth, scaleHeight)))\n"
      ],
      "metadata": {
        "id": "8Ve9PNFzhuSq",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PART 3.1: Manual - Create AI images\n",
        "![AI Prompt](https://raw.githubusercontent.com/steinhaug/stable-diffusion/main/assets/notebook-create-images.png)\n"
      ],
      "metadata": {
        "id": "soBvoD4e4GlU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Prompt instructions, mini helper. Press play to display FAQ.\n",
        "print(\"The prompt, this is where you describe what you want to see. You could say An astrounaut riding a horse, boom you got it. You could add in Salvador Dali style and voila - AI magic right there. Infact there are almost 2500 artists understood in this AI model by default so just experiment and try out some ideas... Its free!\")\n",
        "print(\"\")\n",
        "print(\"To have yourself in the image use the label __token__. Here is an example prompt you can try:\")\n",
        "print(\"prompt: __token__ as magician, highly saturated colors, concept art, Dan Mumford, Lucas Cranach the Elder,mythological painting,german renaissance\")\n",
        "print(\"\")\n",
        "print(\"Its very common that you get some extra fingers, an extra arm here and there so what you often need to use is what is called the negative prompt. Basically this is instructing the AI for what NOT to have in the finnished image. So given the prompt example I gave you a great negative prompt would be this:\")\n",
        "print(\"Negative prompt: blurry| fuzzy| extra fingers| disfigured| cropped| bad fingers| deformed fingers| mutated fingers\")\n",
        "print(\"\")\n",
        "print(\"NB! Note that the negative prompt has a clear impact on the final image, as something like adding \\\"mutated fingers\\\" instructs the AI to make sure that the images does show fingers - however - not mutated...\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "7Re4co4kWLHx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "K6xoHWSsbcS3",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "#@title AI-Manual - Quick mode\n",
        "prompt = \"Masterpiece, digital oil painting, cyberpunk style, a beautiful woman stands facing the audience, with long white hair, SOLO, exquisite facial features, big eyes, black sci-fi mask, Third Reich-style military coat, super high-detailed clothing , black leather boots, red city, behind is the scene of the explosion, the flames are soaring, depressing, weird, photo style, ultra high definition\" #@param {type:\"string\"}\n",
        "negative_prompt = \", a beautiful woman stands facing the audience, with long white hair, SOLO, exquisite facial features, big eyes, black sci-fi mask, super high-detailed clothing , black leather boots, red city, behind is the scene of the explosion, the flames are soaring, depressing, weird, photo style, ultra high definition\" #@param {type:\"string\"}\n",
        "token_name = YOUR_TOKEN + \" woman, \" + YOUR_TOKEN\n",
        "num_samples = 1\n",
        "guidance_scale = 7.5\n",
        "num_inference_steps = 50\n",
        "width = \"512\"\n",
        "height = \"512\"\n",
        "width = int(width)\n",
        "height = int(height)\n",
        "new_seed = None\n",
        "save_images_path = \"/content/drive/MyDrive/AI-Images-Manual\"\n",
        "\n",
        "#prompt = prompt.replace(\"__token__\", token_name)\n",
        "\n",
        "x = token_name.split(\",\")\n",
        "for index, value in enumerate(x):\n",
        "    if index == 0:\n",
        "        prompt = prompt.replace(\"__token__\", value)\n",
        "        prompt = prompt.replace(\"[subject]\", value)\n",
        "    else:\n",
        "        prompt = prompt.replace(\"[subject]\", value)\n",
        "        prompt = prompt.replace(\"__token\" + str(index) + \"__\", value)\n",
        "\n",
        "#raise Exception(1);\n",
        "\n",
        "if new_seed:\n",
        "    g_cuda = torch.Generator(device='cuda')\n",
        "    g_cuda.manual_seed(new_seed)\n",
        "\n",
        "if len(save_images_path):\n",
        "    tmp = save_images_path.split(\"/\")\n",
        "    if len(tmp) == 1:\n",
        "        save_images_path = \"/content/\" + save_images_path\n",
        "    from pathlib import Path\n",
        "    path = Path(save_images_path)\n",
        "    if not path.exists():\n",
        "        print(f\"[*] Create save directory...\")\n",
        "        path.mkdir(parents = False, exist_ok = False)\n",
        "    try:\n",
        "        if not image_save_count:\n",
        "            print('Darn we need this one!')\n",
        "    except NameError:\n",
        "        image_save_count = 1\n",
        "\n",
        "print(f\"[*] Prompt used: {prompt}\")\n",
        "\n",
        "with autocast(\"cuda\"), torch.inference_mode():\n",
        "    images = pipe(\n",
        "        prompt,\n",
        "        height=height,\n",
        "        width=width,\n",
        "        negative_prompt=negative_prompt,\n",
        "        num_images_per_prompt=num_samples,\n",
        "        num_inference_steps=num_inference_steps,\n",
        "        guidance_scale=guidance_scale,\n",
        "        generator=g_cuda\n",
        "    ).images\n",
        "\n",
        "for img in images:\n",
        "    display(img)\n",
        "    if len(save_images_path):\n",
        "        precount = f'{image_save_count:04d}'\n",
        "        image_filename = precount + '_' + prompt.replace(\" \", '_')[:240] + '.png'\n",
        "        img.save(save_images_path + \"/\" + image_filename)\n",
        "        image_save_count += 1"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title AI-Manual - All options mode\n",
        "prompt = \"[subject], Masterpiece, digital oil painting, cyberpunk style, symmetrical face\" #@param {type:\"string\"}\n",
        "negative_prompt = \"blurry\" #@param {type:\"string\"}\n",
        "token_name = YOUR_TOKEN + \" woman, \" + YOUR_TOKEN\n",
        "num_samples = 1 #@param {type:\"number\"}\n",
        "guidance_scale = 7.5 #@param {type:\"number\"}\n",
        "num_inference_steps = 50 #@param {type:\"number\"}\n",
        "width = \"512\" #@param [\"512\", \"768\", \"1280\", \"1536\"] {allow-input: true}\n",
        "height = \"512\" #@param [\"512\", \"768\", \"1280\", \"1536\"] {allow-input: true}\n",
        "width = int(width)\n",
        "height = int(height)\n",
        "custom_seed = None #@param {type:\"number\"}\n",
        "new_seed = custom_seed\n",
        "save_images_path = \"/content/drive/MyDrive/AI-Images-Manual\"\n",
        "\n",
        "#prompt = prompt.replace(\"__token__\", token_name)\n",
        "\n",
        "x = token_name.split(\",\")\n",
        "for index, value in enumerate(x):\n",
        "    if index == 0:\n",
        "        prompt = prompt.replace(\"__token__\", value)\n",
        "        prompt = prompt.replace(\"[subject]\", value)\n",
        "    else:\n",
        "        prompt = prompt.replace(\"[subject]\", value)\n",
        "        prompt = prompt.replace(\"__token\" + str(index) + \"__\", value)\n",
        "\n",
        "#raise Exception(1);\n",
        "\n",
        "if new_seed:\n",
        "    g_cuda = torch.Generator(device='cuda')\n",
        "    g_cuda.manual_seed(new_seed)\n",
        "\n",
        "if len(save_images_path):\n",
        "    tmp = save_images_path.split(\"/\")\n",
        "    if len(tmp) == 1:\n",
        "        save_images_path = \"/content/\" + save_images_path\n",
        "    from pathlib import Path\n",
        "    path = Path(save_images_path)\n",
        "    if not path.exists():\n",
        "        print(f\"[*] Create save directory...\")\n",
        "        path.mkdir(parents = False, exist_ok = False)\n",
        "    try:\n",
        "        if not image_save_count:\n",
        "            print('Darn we need this one!')\n",
        "    except NameError:\n",
        "        image_save_count = 1\n",
        "\n",
        "print(f\"[*] Prompt used: {prompt}\")\n",
        "\n",
        "with autocast(\"cuda\"), torch.inference_mode():\n",
        "    images = pipe(\n",
        "        prompt,\n",
        "        height=height,\n",
        "        width=width,\n",
        "        negative_prompt=negative_prompt,\n",
        "        num_images_per_prompt=num_samples,\n",
        "        num_inference_steps=num_inference_steps,\n",
        "        guidance_scale=guidance_scale,\n",
        "        generator=g_cuda\n",
        "    ).images\n",
        "\n",
        "for img in images:\n",
        "    display(img)\n",
        "    if len(save_images_path):\n",
        "        precount = f'{image_save_count:04d}'\n",
        "        image_filename = precount + '_' + prompt.replace(\" \", '_')[:240] + '.png'\n",
        "        img.save(save_images_path + \"/\" + image_filename)\n",
        "        image_save_count += 1"
      ],
      "metadata": {
        "cellView": "form",
        "id": "45sVRmGWYuJV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 4.0: Huggingface connect - upload and save your model for later use\n",
        "![Save](https://raw.githubusercontent.com/steinhaug/stable-diffusion/main/assets/notebook-save.png)\n",
        "<br>\n",
        "Time to complete: ca. 15 minutes\n"
      ],
      "metadata": {
        "id": "B5jbpxx_eeAj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 1/2 Establish the connection for huggingface.co \n",
        "\n",
        "from slugify import slugify\n",
        "from huggingface_hub import HfApi, HfFolder, CommitOperationAdd\n",
        "from huggingface_hub import create_repo\n",
        "from IPython.display import display_markdown\n",
        "from IPython.display import clear_output\n",
        "from IPython.utils import capture\n",
        "from google.colab import files\n",
        "import shutil\n",
        "import time\n",
        "import os\n",
        "\n",
        "#Create_repo = True #@param {type:\"boolean\"}\n",
        "#hf_token_write = \"\" #@param {type:\"string\"}\n",
        "#Name_of_your_concept = \"x_mamma\" #@param {type:\"string\"}\n",
        "\n",
        "Create_repo = False #@param {type:\"boolean\"}\n",
        "hf_token_write = HUGGINGFACE_TOKEN\n",
        "Name_of_your_concept = YOUR_TOKEN\n",
        "\n",
        "Name_of_your_concept=Name_of_your_concept.replace(\" \",\"-\")  \n",
        "hf_token = hf_token_write\n",
        "\n",
        "if not len(hf_token_write):\n",
        "    hf_token = HUGGINGFACE_TOKEN\n",
        "\n",
        "\n",
        "api = HfApi()\n",
        "your_username = api.whoami(token=hf_token)[\"name\"]\n",
        "repo_id = f\"{your_username}/{slugify(Name_of_your_concept)}\"\n",
        "\n",
        "def bar(prg):\n",
        "    br=\"\u001b[1;33mUploading to HuggingFace : \" '\u001b[0m|'+'█' * prg + ' ' * (25-prg)+'| ' +str(prg*4)+ \"%\"\n",
        "    return br\n",
        "print(\"\u001b[1;32mLoading...\")\n",
        "\n",
        "UPLOAD_DIR = \"/content/temp\"\n",
        "#MODEL_DIR = \"/content/drive/MyDrive/zkiste-models/zkiste2/4646\" #@param {type:\"string\"}\n",
        "\n",
        "os.makedirs(UPLOAD_DIR, exist_ok=True)\n",
        "\n",
        "%cd $UPLOAD_DIR\n",
        "!rm -r safety_checker feature_extractor .git\n",
        "!rm model_index.json\n",
        "!git init\n",
        "!git lfs install --system --skip-repo\n",
        "!git remote add -f origin  \"https://USER:{hf_token}@huggingface.co/runwayml/stable-diffusion-v1-5\"\n",
        "!git config core.sparsecheckout true\n",
        "!echo -e \"feature_extractor\\nsafety_checker\\nmodel_index.json\" > .git/info/sparse-checkout\n",
        "!git pull origin main\n",
        "!rm -r .git\n",
        "#%cd /content\n",
        "\n",
        "readme_text = f'''---\n",
        "license: creativeml-openrail-m\n",
        "tags:\n",
        "- text-to-image\n",
        "- stable-diffusion\n",
        "---\n",
        "### {Name_of_your_concept} \n",
        "My First Stable Diffusion Model!\n",
        "\n",
        "Trained token: {Name_of_your_concept} person\n",
        "Training steps: 2000\n",
        "Learning rate: 1e-6\n",
        "Training images: 10\n",
        "Regularization images: 100\n",
        "Batch size: 4\n",
        "'''\n",
        "#Save the readme to a file\n",
        "readme_file = open(\"README.md\", \"w\")\n",
        "readme_file.write(readme_text)\n",
        "readme_file.close()\n",
        "\n",
        "operations = [\n",
        "  CommitOperationAdd(path_in_repo=\"README.md\", path_or_fileobj=\"README.md\")\n",
        "]\n",
        "# CommitOperationAdd(path_in_repo=f\"{Session_Name}.ckpt\",path_or_fileobj=MDLPTH)\n",
        "\n",
        "if Create_repo:\n",
        "  create_repo(repo_id,private=True, token=hf_token)\n",
        "  api.create_commit(\n",
        "    repo_id=repo_id,\n",
        "    operations=operations,\n",
        "    commit_message=f\"Init concept {Name_of_your_concept} repo\",\n",
        "    token=hf_token\n",
        "  )\n",
        "\n",
        "clear_output()\n",
        "print(bar(25))\n",
        "\n",
        "display_markdown(f'''## Ready... [repo link](https://huggingface.co/{repo_id})\n",
        "''', raw=True)\n"
      ],
      "metadata": {
        "id": "K0BchFE5dfez",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 82
        },
        "outputId": "7ab2cbbb-b6ee-4ff0-b975-e3f4b78e0f7b"
      },
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;33mUploading to HuggingFace : \u001b[0m|█████████████████████████| 100%\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/markdown": "## Ready... [repo link](https://huggingface.co/steinhaug/x-annelene)\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 2/2 Upload your model files\n",
        "from slugify import slugify\n",
        "from huggingface_hub import HfApi, HfFolder, CommitOperationAdd\n",
        "from huggingface_hub import create_repo\n",
        "from IPython.display import display_markdown\n",
        "from IPython.display import clear_output\n",
        "from IPython.utils import capture\n",
        "from google.colab import files\n",
        "import shutil\n",
        "import time\n",
        "import os\n",
        "\n",
        "WEIGHTSPATH = '/content/drive/MyDrive/stable_diffusion_weights/' + YOUR_TOKEN + '/2000/'\n",
        "\n",
        "MODEL1 = WEIGHTSPATH + 'model.ckpt'\n",
        "\n",
        "operations = [\n",
        "  CommitOperationAdd(path_in_repo=\"model.ckpt\",path_or_fileobj=MODEL1)\n",
        "]\n",
        "api.create_commit(\n",
        "  repo_id=repo_id,\n",
        "  operations=operations,\n",
        "  commit_message=f\"Added checkpoint model.\",\n",
        "  token=hf_token\n",
        ")\n",
        "api.upload_folder(\n",
        "  folder_path = WEIGHTSPATH + 'feature_extractor',\n",
        "  path_in_repo=\"feature_extractor\",\n",
        "  repo_id=repo_id, token=hf_token\n",
        ")\n",
        "api.upload_folder(\n",
        "  folder_path=WEIGHTSPATH + 'scheduler',\n",
        "  path_in_repo=\"scheduler\",\n",
        "  repo_id=repo_id, token=hf_token\n",
        ")\n",
        "api.upload_folder(\n",
        "  folder_path=WEIGHTSPATH + 'text_encoder',\n",
        "  path_in_repo=\"text_encoder\",\n",
        "  repo_id=repo_id, token=hf_token\n",
        ")\n",
        "api.upload_folder(\n",
        "  folder_path=WEIGHTSPATH + 'tokenizer',\n",
        "  path_in_repo=\"tokenizer\",\n",
        "  repo_id=repo_id, token=hf_token\n",
        ")\n",
        "api.upload_folder(\n",
        "  folder_path=WEIGHTSPATH + 'unet',\n",
        "  path_in_repo=\"unet\",\n",
        "  repo_id=repo_id, token=hf_token\n",
        ")\n",
        "api.upload_folder(\n",
        "  folder_path=WEIGHTSPATH + 'vae',\n",
        "  path_in_repo=\"vae\",\n",
        "  repo_id=repo_id, token=hf_token\n",
        ")\n",
        "api.upload_folder(\n",
        "  folder_path=WEIGHTSPATH + 'unet',\n",
        "  path_in_repo=\"unet\",\n",
        "  repo_id=repo_id, token=hf_token\n",
        ")\n",
        "api.upload_folder(\n",
        "  folder_path=WEIGHTSPATH + 'vae',\n",
        "  path_in_repo=\"vae\",\n",
        "  repo_id=repo_id, token=hf_token\n",
        ")\n",
        "MODEL2 = WEIGHTSPATH + 'args.json'\n",
        "MODEL3 = WEIGHTSPATH + 'model_index.json'\n",
        "operations = [\n",
        "  CommitOperationAdd(path_in_repo=\"args.json\",path_or_fileobj=MODEL2),\n",
        "  CommitOperationAdd(path_in_repo=\"model_index.json\",path_or_fileobj=MODEL3)\n",
        "]\n",
        "api.create_commit(\n",
        "  repo_id=repo_id,\n",
        "  operations=operations,\n",
        "  commit_message=f\"Added my diffusers model, 2000 steps.\",\n",
        "  token=hf_token\n",
        ")\n",
        "from IPython.display import clear_output; clear_output(); print('\u001b[1;32mDone! ✓')"
      ],
      "metadata": {
        "id": "2CEXcg80er5X",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title MANUAL UPLOAD\n",
        "from slugify import slugify; from huggingface_hub import HfApi, HfFolder, CommitOperationAdd; from huggingface_hub import create_repo; from IPython.display import display_markdown; from IPython.display import clear_output; from IPython.utils import capture; from google.colab import files; import shutil; import time; import os\n",
        "\n",
        "#MODEL1 = WEIGHTS_DIR + '/model.ckpt'\n",
        "MODEL1 = \"/content/stable_diffusion_weights_4/x_annelene/1100/model.ckpt\"\n",
        "\n",
        "operations = [\n",
        "  CommitOperationAdd(path_in_repo=\"annelene-v2.ckpt\",path_or_fileobj=MODEL1)\n",
        "]\n",
        "api.create_commit(\n",
        "  repo_id=repo_id,\n",
        "  operations=operations,\n",
        "  commit_message=f\"Added checkpoint model.\",\n",
        "  token=hf_token\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 116,
          "referenced_widgets": [
            "0c196ee66ec54094881019ea5b3a2123",
            "fe1b24e51d1247349f76a411d1cad411",
            "6aac8d78bd104ca8a2b29ec22a8a51bd",
            "7d323563442b4bf4aa9bb01ecc76e6fe",
            "57d300b224894dc4acc4a60cab5e2a20",
            "825a1046789349758175d6f522cff811",
            "f8c65e209e1440a29a165a94f9ee9e43",
            "9e5a639fc2a84a2ca37ec94f79547d94",
            "d3c8c07f7d3f430cbdea8e70c9735add",
            "c9057e5ddb9a4275a15b797aa885228e",
            "0c574727a0ea45c8aaf4fb681a5cf5de",
            "de41a52201ee4bd49519efac5a86fc03",
            "ed39e4366e1f48f1952fa6efc2306fb5",
            "ff9cee8e70b7456b98c65b95535a85b0",
            "19b0bc6f67d4483f956ecb08f6dc99f7",
            "af5c706c4e0c4825ab0f81aab2f89366",
            "8c3ce70d795c4e8190bacfa3cc10c3d1",
            "b11920aa4b774ab2afd24bf10479241f",
            "84815994cb0f47dab411830933939dad",
            "23228ae2b7a542f6b84854711c0b7f4e",
            "3caf523e41ff42ab81732acaac5d03ea",
            "676e30e897af4536bc4ab508b7ef283d"
          ]
        },
        "id": "YUM1fd8I0AYx",
        "outputId": "ebb090b8-360c-4bea-e175-96ac99ffeac8"
      },
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Upload 1 LFS files:   0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0c196ee66ec54094881019ea5b3a2123"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.ckpt:   0%|          | 0.00/2.13G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "de41a52201ee4bd49519efac5a86fc03"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CommitInfo(commit_url='https://huggingface.co/steinhaug/x-annelene/commit/f330cc1aa5c382a5853fe967ee378cb11a0f4457', commit_message='Added checkpoint model.', commit_description='', oid='f330cc1aa5c382a5853fe967ee378cb11a0f4457', pr_url=None, pr_revision=None, pr_num=None)"
            ]
          },
          "metadata": {},
          "execution_count": 127
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "2.7.16 (default, Oct 10 2019, 22:02:15) \n[GCC 8.3.0]"
    },
    "vscode": {
      "interpreter": {
        "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
      }
    },
    "gpuClass": "premium",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0c196ee66ec54094881019ea5b3a2123": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fe1b24e51d1247349f76a411d1cad411",
              "IPY_MODEL_6aac8d78bd104ca8a2b29ec22a8a51bd",
              "IPY_MODEL_7d323563442b4bf4aa9bb01ecc76e6fe"
            ],
            "layout": "IPY_MODEL_57d300b224894dc4acc4a60cab5e2a20"
          }
        },
        "fe1b24e51d1247349f76a411d1cad411": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_825a1046789349758175d6f522cff811",
            "placeholder": "​",
            "style": "IPY_MODEL_f8c65e209e1440a29a165a94f9ee9e43",
            "value": "Upload 1 LFS files: 100%"
          }
        },
        "6aac8d78bd104ca8a2b29ec22a8a51bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9e5a639fc2a84a2ca37ec94f79547d94",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d3c8c07f7d3f430cbdea8e70c9735add",
            "value": 1
          }
        },
        "7d323563442b4bf4aa9bb01ecc76e6fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c9057e5ddb9a4275a15b797aa885228e",
            "placeholder": "​",
            "style": "IPY_MODEL_0c574727a0ea45c8aaf4fb681a5cf5de",
            "value": " 1/1 [00:22&lt;00:00, 22.93s/it]"
          }
        },
        "57d300b224894dc4acc4a60cab5e2a20": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "825a1046789349758175d6f522cff811": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f8c65e209e1440a29a165a94f9ee9e43": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9e5a639fc2a84a2ca37ec94f79547d94": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d3c8c07f7d3f430cbdea8e70c9735add": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c9057e5ddb9a4275a15b797aa885228e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0c574727a0ea45c8aaf4fb681a5cf5de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "de41a52201ee4bd49519efac5a86fc03": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ed39e4366e1f48f1952fa6efc2306fb5",
              "IPY_MODEL_ff9cee8e70b7456b98c65b95535a85b0",
              "IPY_MODEL_19b0bc6f67d4483f956ecb08f6dc99f7"
            ],
            "layout": "IPY_MODEL_af5c706c4e0c4825ab0f81aab2f89366"
          }
        },
        "ed39e4366e1f48f1952fa6efc2306fb5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8c3ce70d795c4e8190bacfa3cc10c3d1",
            "placeholder": "​",
            "style": "IPY_MODEL_b11920aa4b774ab2afd24bf10479241f",
            "value": "model.ckpt: 100%"
          }
        },
        "ff9cee8e70b7456b98c65b95535a85b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_84815994cb0f47dab411830933939dad",
            "max": 2132791380,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_23228ae2b7a542f6b84854711c0b7f4e",
            "value": 2132791380
          }
        },
        "19b0bc6f67d4483f956ecb08f6dc99f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3caf523e41ff42ab81732acaac5d03ea",
            "placeholder": "​",
            "style": "IPY_MODEL_676e30e897af4536bc4ab508b7ef283d",
            "value": " 2.13G/2.13G [00:22&lt;00:00, 96.1MB/s]"
          }
        },
        "af5c706c4e0c4825ab0f81aab2f89366": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8c3ce70d795c4e8190bacfa3cc10c3d1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b11920aa4b774ab2afd24bf10479241f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "84815994cb0f47dab411830933939dad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "23228ae2b7a542f6b84854711c0b7f4e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3caf523e41ff42ab81732acaac5d03ea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "676e30e897af4536bc4ab508b7ef283d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}