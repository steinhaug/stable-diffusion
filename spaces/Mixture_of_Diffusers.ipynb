{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNAxFNsyzwXa7MKT8WfZcaI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/steinhaug/stable-diffusion/blob/main/spaces/Mixture_of_Diffusers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Mixture of Diffusers\n",
        "https://github.com/albarji/mixture-of-diffusers  \n",
        "https://huggingface.co/spaces/albarji/mixture-of-diffusers"
      ],
      "metadata": {
        "id": "se1Qbik4035d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<table width=\"900\"><tr>\n",
        "<td>A charming house in the countryside, <br>\n",
        "by jakub rozalski, sunset lighting, elegant, <br>\n",
        "highly detailed, smooth, sharp focus, artstation, <br>\n",
        "stunning masterpiece</td>\n",
        "<td>A dirt road in the countryside crossing pastures, <br>\n",
        "by jakub rozalski, sunset lighting, elegant, <br>\n",
        "highly detailed, smooth, sharp focus, artstation, <br>\n",
        "stunning masterpiece</td>\n",
        "<td>An old and rusty giant robot lying on a dirt road, <br>\n",
        "by jakub rozalski, dark sunset lighting, elegant, <br>\n",
        "highly detailed, smooth, sharp focus, artstation, <br>\n",
        "stunning masterpiece</td>\n",
        "</tr></table>\n",
        "\n",
        "![3 part diffusion image](https://user-images.githubusercontent.com/9654655/195362341-bc7766c2-f5c6-40f2-b457-59277aa11027.png \"3 part diffusion image\")\n"
      ],
      "metadata": {
        "id": "ABFbvEj36_B5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Install requirements\n",
        "!pip install gradio\n",
        "!pip install mixdiff\n",
        "!pip install diffusers"
      ],
      "metadata": {
        "cellView": "form",
        "id": "LC0blFzCxDiN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Run gradio without cached examples\n",
        "from IPython.display import clear_output\n",
        "import gradio as gr\n",
        "import torch\n",
        "\n",
        "from diffusers import LMSDiscreteScheduler\n",
        "from mixdiff import StableDiffusionCanvasPipeline, Text2ImageRegion\n",
        "\n",
        "article = \"\"\"\n",
        "## Usage\n",
        "In this demo you can use Mixture of Diffusers to configure a canvas made up of 3 diffusion regions. Play around with the prompts and guidance values in each region! You can also change increment the overlap between regions if seams appear in the image.\n",
        "In the full version of Mixture of Diffusers you will find further freedom to configure the regions in the canvas. Check the [github repo](https://github.com/albarji/mixture-of-diffusers)!\n",
        "## Motivation\n",
        "Current image generation methods, such as Stable Diffusion, struggle to position objects at specific locations. While the content of the generated image (somewhat) reflects the objects present in the prompt, it is difficult to frame the prompt in a way that creates an specific composition. For instance, take a prompt expressing a complex composition such as\n",
        "> A charming house in the countryside on the left,\n",
        "> in the center a dirt road in the countryside crossing pastures,\n",
        "> on the right an old and rusty giant robot lying on a dirt road,\n",
        "> by jakub rozalski,\n",
        "> sunset lighting on the left and center, dark sunset lighting on the right\n",
        "> elegant, highly detailed, smooth, sharp focus, artstation, stunning masterpiece\n",
        "Out of a sample of 20 Stable Diffusion generations with different seeds, the generated images that align best with the prompt are the following:\n",
        "<table>\n",
        "  <tr>\n",
        "    <td><img src=\"https://user-images.githubusercontent.com/9654655/195373001-ad23b7c4-f5b1-4e5b-9aa1-294441ed19ed.png\" width=\"300\"></td>\n",
        "    <td><img src=\"https://user-images.githubusercontent.com/9654655/195373174-8d85dd96-310e-48fa-b112-d9902685f22e.png\" width=\"300\"></td>\n",
        "    <td><img src=\"https://user-images.githubusercontent.com/9654655/195373200-59eeec1e-e1b8-464d-b72e-e28a9004d269.png\" width=\"300\"></td>\n",
        "  </tr>\n",
        "</table>\n",
        "The method proposed here strives to provide a better tool for image composition by using several diffusion processes in parallel, each configured with a specific prompt and settings, and focused on a particular region of the image. You can try it out in the example above! The mixture of diffusion processes is done in a way that harmonizes the generation process, preventing \"seam\" effects in the generated image.\n",
        "Using several diffusion processes in parallel has also practical advantages when generating very large images, as the GPU memory requirements are similar to that of generating an image of the size of a single tile.\n",
        "## Responsible use\n",
        "The same recommendations as in Stable Diffusion apply, so please check the corresponding [model card](https://huggingface.co/CompVis/stable-diffusion-v1-4).\n",
        "More broadly speaking, always bear this in mind: YOU are responsible for the content you create using this tool. Do not fully blame, credit, or place the responsibility on the software.\n",
        "## Gallery\n",
        "Here are some relevant illustrations created using this software (and putting quite a few hours into them!).\n",
        "### Darkness Dawning\n",
        "![Darkness Dawning](https://images-wixmp-ed30a86b8c4ca887773594c2.wixmp.com/f/cd1358aa-80d5-4c59-b95b-cdfde5dcc4f5/dfidq8n-6da9a886-9f1c-40ae-8341-d77af9552395.png?token=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJzdWIiOiJ1cm46YXBwOjdlMGQxODg5ODIyNjQzNzNhNWYwZDQxNWVhMGQyNmUwIiwiaXNzIjoidXJuOmFwcDo3ZTBkMTg4OTgyMjY0MzczYTVmMGQ0MTVlYTBkMjZlMCIsIm9iaiI6W1t7InBhdGgiOiJcL2ZcL2NkMTM1OGFhLTgwZDUtNGM1OS1iOTViLWNkZmRlNWRjYzRmNVwvZGZpZHE4bi02ZGE5YTg4Ni05ZjFjLTQwYWUtODM0MS1kNzdhZjk1NTIzOTUucG5nIn1dXSwiYXVkIjpbInVybjpzZXJ2aWNlOmZpbGUuZG93bmxvYWQiXX0.ff6XoVBPdUbcTLcuHUpQMPrD2TaXBM_s6HfRhsARDw0)\n",
        "### Yog-Sothoth\n",
        "![Yog-Sothoth](https://images-wixmp-ed30a86b8c4ca887773594c2.wixmp.com/f/cd1358aa-80d5-4c59-b95b-cdfde5dcc4f5/dfidsq4-174dd428-2c5a-48f6-a78f-9441fb3cffea.png?token=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJzdWIiOiJ1cm46YXBwOjdlMGQxODg5ODIyNjQzNzNhNWYwZDQxNWVhMGQyNmUwIiwiaXNzIjoidXJuOmFwcDo3ZTBkMTg4OTgyMjY0MzczYTVmMGQ0MTVlYTBkMjZlMCIsIm9iaiI6W1t7InBhdGgiOiJcL2ZcL2NkMTM1OGFhLTgwZDUtNGM1OS1iOTViLWNkZmRlNWRjYzRmNVwvZGZpZHNxNC0xNzRkZDQyOC0yYzVhLTQ4ZjYtYTc4Zi05NDQxZmIzY2ZmZWEucG5nIn1dXSwiYXVkIjpbInVybjpzZXJ2aWNlOmZpbGUuZG93bmxvYWQiXX0.X42zWgsk3lYnYwuEgkifRFRH2km-npHvrdleDN3m6bA)\n",
        "### Looking through the eyes of giants\n",
        "![Looking through the eyes of giants](https://user-images.githubusercontent.com/9654655/218307148-95ce88b6-b2a3-458d-b469-daf5bd56e3a7.jpg)\n",
        "[Follow me on DeviantArt for more!](https://www.deviantart.com/albarji)\n",
        "## Acknowledgements\n",
        "First and foremost, my most sincere appreciation for the [Stable Diffusion team](https://stability.ai/blog/stable-diffusion-public-release) for releasing such an awesome model, and for letting me take part of the closed beta. Kudos also to the Hugging Face community and developers for implementing the [Diffusers library](https://github.com/huggingface/diffusers).\n",
        "Thanks to Hugging Face for providing support and a GPU spaces for running this demo. Thanks also to Instituto de Ingeniería del Conocimiento and Grupo de Aprendizaje Automático (Universidad Autónoma de Madrid) for providing GPU resources for testing and experimenting this library.\n",
        "Thanks also to the vibrant communities of the Stable Diffusion discord channel and [Lexica](https://lexica.art/), where I have learned about many amazing artists and styles. And to my friend Abril for sharing many tips on cool artists!\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "# Creater scheduler and model (similar to StableDiffusionPipeline)\n",
        "scheduler = LMSDiscreteScheduler(beta_start=0.00085, beta_end=0.012, beta_schedule=\"scaled_linear\", num_train_timesteps=1000)\n",
        "pipeline = StableDiffusionCanvasPipeline.from_pretrained(\"CompVis/stable-diffusion-v1-4\", scheduler=scheduler).to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "def generate(prompt1, prompt2, prompt3, gc1, gc2, gc3, overlap, steps, seed):\n",
        "    \"\"\"Mixture of Diffusers generation\"\"\"\n",
        "    tile_width = 640\n",
        "    tile_height = 640\n",
        "    return pipeline(\n",
        "        canvas_height=tile_height,\n",
        "        canvas_width=tile_width + (tile_width - overlap) * 2,\n",
        "        regions=[\n",
        "            Text2ImageRegion(0, tile_height, 0, tile_width, guidance_scale=gc1,\n",
        "                prompt=prompt1),\n",
        "            Text2ImageRegion(0, tile_height, tile_width - overlap, tile_width - overlap + tile_width, guidance_scale=gc2,\n",
        "                prompt=prompt2),\n",
        "            Text2ImageRegion(0, tile_height, (tile_width - overlap) * 2, (tile_width - overlap) * 2 + tile_width, guidance_scale=gc3,\n",
        "                prompt=prompt3),\n",
        "        ],\n",
        "        num_inference_steps=steps,\n",
        "        seed=seed,\n",
        "    )[\"sample\"][0]\n",
        "\n",
        "with gr.Blocks(title=\"Mixture of Diffusers\") as demo:\n",
        "    gr.HTML(\n",
        "        \"\"\"\n",
        "            <div style=\"text-align: center; max-width: 700px; margin: 0 auto;\">\n",
        "              <div\n",
        "                style=\"\n",
        "                  display: inline-flex;\n",
        "                  align-items: center;\n",
        "                  gap: 0.8rem;\n",
        "                  font-size: 1.75rem;\n",
        "                \"\n",
        "              >\n",
        "                <h1 style=\"font-weight: 1000; margin-bottom: 7px; line-height: normal;\">\n",
        "                  Mixture of Diffusers\n",
        "                </h1>\n",
        "              </div>\n",
        "              <p style=\"margin-bottom: 10px; font-size: 94%\">\n",
        "                <a href=\"https://arxiv.org/abs/2302.02412\">[Paper]</a>  <a href=\"https://github.com/albarji/mixture-of-diffusers\">[Code in Github]</a>  <a href=\"https://huggingface.co/spaces/albarji/mixture-of-diffusers?duplicate=true\">\n",
        "              </p>\n",
        "            </div>\n",
        "        \"\"\"\n",
        "    )\n",
        "    with gr.Row():\n",
        "        with gr.Column(scale=1):\n",
        "            gr.Markdown(\"### Left region\")\n",
        "            left_prompt = gr.Textbox(lines=2, label=\"Prompt (what do you want to see in the left side of the image?)\")\n",
        "            left_gs = gr.Slider(minimum=0, maximum=15, value=8, step=1, label=\"Guidance scale\")\n",
        "        with gr.Column(scale=1):\n",
        "            gr.Markdown(\"### Center region\")\n",
        "            center_prompt = gr.Textbox(lines=2, label=\"Prompt (what do you want to see in the center of the image?)\")\n",
        "            center_gs = gr.Slider(minimum=0, maximum=15, value=8, step=1, label=\"Guidance scale\")\n",
        "        with gr.Column(scale=1):\n",
        "            gr.Markdown(\"### Right region\")\n",
        "            right_prompt = gr.Textbox(lines=2, label=\"Prompt (what do you want to see in the right side of the image?)\")\n",
        "            right_gs = gr.Slider(minimum=0, maximum=15, value=8, step=1, label=\"Guidance scale\")\n",
        "    gr.Markdown(\"### General parameters\")\n",
        "    with gr.Row():\n",
        "        with gr.Column(scale=1):\n",
        "            overlap = gr.Slider(minimum=128, maximum=320, value=256, step=8, label=\"Overlap between diffusion regions\")\n",
        "        with gr.Column(scale=1):\n",
        "            steps = gr.Slider(minimum=1, maximum=50, value=15, step=1, label=\"Number of diffusion steps\")\n",
        "        with gr.Column(scale=1):\n",
        "            seed = gr.Number(value=12345, precision=0, label=\"Random seed\")\n",
        "    with gr.Row():\n",
        "        button = gr.Button(value=\"Generate\")\n",
        "    with gr.Row():\n",
        "        output = gr.Image(label=\"Generated image\")\n",
        "    \n",
        "    button.click(\n",
        "        generate, \n",
        "        inputs=[left_prompt, center_prompt, right_prompt, left_gs, center_gs, right_gs, overlap, steps, seed],\n",
        "        outputs=output\n",
        "    )\n",
        "\n",
        "    with gr.Row():\n",
        "        gr.Markdown(article)\n",
        "\n",
        "clear_output()\n",
        "demo.launch(debug=True, share=True)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "oQc9zeBU3M4d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "FY_TusMCwoEr"
      },
      "outputs": [],
      "source": [
        "#@title Run gradio with cached examples\n",
        "from IPython.display import clear_output\n",
        "import gradio as gr\n",
        "import torch\n",
        "\n",
        "from diffusers import LMSDiscreteScheduler\n",
        "from mixdiff import StableDiffusionCanvasPipeline, Text2ImageRegion\n",
        "\n",
        "article = \"\"\"\n",
        "## Usage\n",
        "In this demo you can use Mixture of Diffusers to configure a canvas made up of 3 diffusion regions. Play around with the prompts and guidance values in each region! You can also change increment the overlap between regions if seams appear in the image.\n",
        "In the full version of Mixture of Diffusers you will find further freedom to configure the regions in the canvas. Check the [github repo](https://github.com/albarji/mixture-of-diffusers)!\n",
        "## Motivation\n",
        "Current image generation methods, such as Stable Diffusion, struggle to position objects at specific locations. While the content of the generated image (somewhat) reflects the objects present in the prompt, it is difficult to frame the prompt in a way that creates an specific composition. For instance, take a prompt expressing a complex composition such as\n",
        "> A charming house in the countryside on the left,\n",
        "> in the center a dirt road in the countryside crossing pastures,\n",
        "> on the right an old and rusty giant robot lying on a dirt road,\n",
        "> by jakub rozalski,\n",
        "> sunset lighting on the left and center, dark sunset lighting on the right\n",
        "> elegant, highly detailed, smooth, sharp focus, artstation, stunning masterpiece\n",
        "Out of a sample of 20 Stable Diffusion generations with different seeds, the generated images that align best with the prompt are the following:\n",
        "<table>\n",
        "  <tr>\n",
        "    <td><img src=\"https://user-images.githubusercontent.com/9654655/195373001-ad23b7c4-f5b1-4e5b-9aa1-294441ed19ed.png\" width=\"300\"></td>\n",
        "    <td><img src=\"https://user-images.githubusercontent.com/9654655/195373174-8d85dd96-310e-48fa-b112-d9902685f22e.png\" width=\"300\"></td>\n",
        "    <td><img src=\"https://user-images.githubusercontent.com/9654655/195373200-59eeec1e-e1b8-464d-b72e-e28a9004d269.png\" width=\"300\"></td>\n",
        "  </tr>\n",
        "</table>\n",
        "The method proposed here strives to provide a better tool for image composition by using several diffusion processes in parallel, each configured with a specific prompt and settings, and focused on a particular region of the image. You can try it out in the example above! The mixture of diffusion processes is done in a way that harmonizes the generation process, preventing \"seam\" effects in the generated image.\n",
        "Using several diffusion processes in parallel has also practical advantages when generating very large images, as the GPU memory requirements are similar to that of generating an image of the size of a single tile.\n",
        "## Responsible use\n",
        "The same recommendations as in Stable Diffusion apply, so please check the corresponding [model card](https://huggingface.co/CompVis/stable-diffusion-v1-4).\n",
        "More broadly speaking, always bear this in mind: YOU are responsible for the content you create using this tool. Do not fully blame, credit, or place the responsibility on the software.\n",
        "## Gallery\n",
        "Here are some relevant illustrations created using this software (and putting quite a few hours into them!).\n",
        "### Darkness Dawning\n",
        "![Darkness Dawning](https://images-wixmp-ed30a86b8c4ca887773594c2.wixmp.com/f/cd1358aa-80d5-4c59-b95b-cdfde5dcc4f5/dfidq8n-6da9a886-9f1c-40ae-8341-d77af9552395.png?token=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJzdWIiOiJ1cm46YXBwOjdlMGQxODg5ODIyNjQzNzNhNWYwZDQxNWVhMGQyNmUwIiwiaXNzIjoidXJuOmFwcDo3ZTBkMTg4OTgyMjY0MzczYTVmMGQ0MTVlYTBkMjZlMCIsIm9iaiI6W1t7InBhdGgiOiJcL2ZcL2NkMTM1OGFhLTgwZDUtNGM1OS1iOTViLWNkZmRlNWRjYzRmNVwvZGZpZHE4bi02ZGE5YTg4Ni05ZjFjLTQwYWUtODM0MS1kNzdhZjk1NTIzOTUucG5nIn1dXSwiYXVkIjpbInVybjpzZXJ2aWNlOmZpbGUuZG93bmxvYWQiXX0.ff6XoVBPdUbcTLcuHUpQMPrD2TaXBM_s6HfRhsARDw0)\n",
        "### Yog-Sothoth\n",
        "![Yog-Sothoth](https://images-wixmp-ed30a86b8c4ca887773594c2.wixmp.com/f/cd1358aa-80d5-4c59-b95b-cdfde5dcc4f5/dfidsq4-174dd428-2c5a-48f6-a78f-9441fb3cffea.png?token=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJzdWIiOiJ1cm46YXBwOjdlMGQxODg5ODIyNjQzNzNhNWYwZDQxNWVhMGQyNmUwIiwiaXNzIjoidXJuOmFwcDo3ZTBkMTg4OTgyMjY0MzczYTVmMGQ0MTVlYTBkMjZlMCIsIm9iaiI6W1t7InBhdGgiOiJcL2ZcL2NkMTM1OGFhLTgwZDUtNGM1OS1iOTViLWNkZmRlNWRjYzRmNVwvZGZpZHNxNC0xNzRkZDQyOC0yYzVhLTQ4ZjYtYTc4Zi05NDQxZmIzY2ZmZWEucG5nIn1dXSwiYXVkIjpbInVybjpzZXJ2aWNlOmZpbGUuZG93bmxvYWQiXX0.X42zWgsk3lYnYwuEgkifRFRH2km-npHvrdleDN3m6bA)\n",
        "### Looking through the eyes of giants\n",
        "![Looking through the eyes of giants](https://user-images.githubusercontent.com/9654655/218307148-95ce88b6-b2a3-458d-b469-daf5bd56e3a7.jpg)\n",
        "[Follow me on DeviantArt for more!](https://www.deviantart.com/albarji)\n",
        "## Acknowledgements\n",
        "First and foremost, my most sincere appreciation for the [Stable Diffusion team](https://stability.ai/blog/stable-diffusion-public-release) for releasing such an awesome model, and for letting me take part of the closed beta. Kudos also to the Hugging Face community and developers for implementing the [Diffusers library](https://github.com/huggingface/diffusers).\n",
        "Thanks to Hugging Face for providing support and a GPU spaces for running this demo. Thanks also to Instituto de Ingeniería del Conocimiento and Grupo de Aprendizaje Automático (Universidad Autónoma de Madrid) for providing GPU resources for testing and experimenting this library.\n",
        "Thanks also to the vibrant communities of the Stable Diffusion discord channel and [Lexica](https://lexica.art/), where I have learned about many amazing artists and styles. And to my friend Abril for sharing many tips on cool artists!\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "# Creater scheduler and model (similar to StableDiffusionPipeline)\n",
        "scheduler = LMSDiscreteScheduler(beta_start=0.00085, beta_end=0.012, beta_schedule=\"scaled_linear\", num_train_timesteps=1000)\n",
        "pipeline = StableDiffusionCanvasPipeline.from_pretrained(\"CompVis/stable-diffusion-v1-4\", scheduler=scheduler).to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "def generate(prompt1, prompt2, prompt3, gc1, gc2, gc3, overlap, steps, seed):\n",
        "    \"\"\"Mixture of Diffusers generation\"\"\"\n",
        "    tile_width = 640\n",
        "    tile_height = 640\n",
        "    return pipeline(\n",
        "        canvas_height=tile_height,\n",
        "        canvas_width=tile_width + (tile_width - overlap) * 2,\n",
        "        regions=[\n",
        "            Text2ImageRegion(0, tile_height, 0, tile_width, guidance_scale=gc1,\n",
        "                prompt=prompt1),\n",
        "            Text2ImageRegion(0, tile_height, tile_width - overlap, tile_width - overlap + tile_width, guidance_scale=gc2,\n",
        "                prompt=prompt2),\n",
        "            Text2ImageRegion(0, tile_height, (tile_width - overlap) * 2, (tile_width - overlap) * 2 + tile_width, guidance_scale=gc3,\n",
        "                prompt=prompt3),\n",
        "        ],\n",
        "        num_inference_steps=steps,\n",
        "        seed=seed,\n",
        "    )[\"sample\"][0]\n",
        "\n",
        "with gr.Blocks(title=\"Mixture of Diffusers\") as demo:\n",
        "    gr.HTML(\n",
        "        \"\"\"\n",
        "            <div style=\"text-align: center; max-width: 700px; margin: 0 auto;\">\n",
        "              <div\n",
        "                style=\"\n",
        "                  display: inline-flex;\n",
        "                  align-items: center;\n",
        "                  gap: 0.8rem;\n",
        "                  font-size: 1.75rem;\n",
        "                \"\n",
        "              >\n",
        "                <h1 style=\"font-weight: 1000; margin-bottom: 7px; line-height: normal;\">\n",
        "                  Mixture of Diffusers\n",
        "                </h1>\n",
        "              </div>\n",
        "              <p style=\"margin-bottom: 10px; font-size: 94%\">\n",
        "                <a href=\"https://arxiv.org/abs/2302.02412\">[Paper]</a>  <a href=\"https://github.com/albarji/mixture-of-diffusers\">[Code in Github]</a>  <a href=\"https://huggingface.co/spaces/albarji/mixture-of-diffusers?duplicate=true\">\n",
        "              </p>\n",
        "            </div>\n",
        "        \"\"\"\n",
        "    )\n",
        "    with gr.Row():\n",
        "        with gr.Column(scale=1):\n",
        "            gr.Markdown(\"### Left region\")\n",
        "            left_prompt = gr.Textbox(lines=2, label=\"Prompt (what do you want to see in the left side of the image?)\")\n",
        "            left_gs = gr.Slider(minimum=0, maximum=15, value=8, step=1, label=\"Guidance scale\")\n",
        "        with gr.Column(scale=1):\n",
        "            gr.Markdown(\"### Center region\")\n",
        "            center_prompt = gr.Textbox(lines=2, label=\"Prompt (what do you want to see in the center of the image?)\")\n",
        "            center_gs = gr.Slider(minimum=0, maximum=15, value=8, step=1, label=\"Guidance scale\")\n",
        "        with gr.Column(scale=1):\n",
        "            gr.Markdown(\"### Right region\")\n",
        "            right_prompt = gr.Textbox(lines=2, label=\"Prompt (what do you want to see in the right side of the image?)\")\n",
        "            right_gs = gr.Slider(minimum=0, maximum=15, value=8, step=1, label=\"Guidance scale\")\n",
        "    gr.Markdown(\"### General parameters\")\n",
        "    with gr.Row():\n",
        "        with gr.Column(scale=1):\n",
        "            overlap = gr.Slider(minimum=128, maximum=320, value=256, step=8, label=\"Overlap between diffusion regions\")\n",
        "        with gr.Column(scale=1):\n",
        "            steps = gr.Slider(minimum=1, maximum=50, value=15, step=1, label=\"Number of diffusion steps\")\n",
        "        with gr.Column(scale=1):\n",
        "            seed = gr.Number(value=12345, precision=0, label=\"Random seed\")\n",
        "    with gr.Row():\n",
        "        button = gr.Button(value=\"Generate\")\n",
        "    with gr.Row():\n",
        "        output = gr.Image(label=\"Generated image\")\n",
        "    with gr.Row():\n",
        "        gr.Examples(\n",
        "            examples=[\n",
        "                [\n",
        "                    \"A charming house in the countryside, by jakub rozalski, sunset lighting, elegant, highly detailed, smooth, sharp focus, artstation, stunning masterpiece\",\n",
        "                    \"A dirt road in the countryside crossing pastures, by jakub rozalski, sunset lighting, elegant, highly detailed, smooth, sharp focus, artstation, stunning masterpiece\",\n",
        "                    \"An old and rusty giant robot lying on a dirt road, by jakub rozalski, dark sunset lighting, elegant, highly detailed, smooth, sharp focus, artstation, stunning masterpiece\",\n",
        "                    8, 8, 8,\n",
        "                    256,\n",
        "                    50,\n",
        "                    7178915308\n",
        "                ],\n",
        "                [\n",
        "                    \"Abstract decorative illustration, by joan miro and gustav klimt and marlina vera and loish, elegant, intricate, highly detailed, smooth, sharp focus, vibrant colors, artstation, stunning masterpiece\",\n",
        "                    \"Abstract decorative illustration, by joan miro and gustav klimt and marlina vera and loish, elegant, intricate, highly detailed, smooth, sharp focus, vibrant colors, artstation, stunning masterpiece\",\n",
        "                    \"Abstract decorative illustration, by joan miro and gustav klimt and marlina vera and loish, elegant, intricate, highly detailed, smooth, sharp focus, vibrant colors, artstation, stunning masterpiece\",\n",
        "                    8, 8, 8,\n",
        "                    256,\n",
        "                    35,\n",
        "                    21156517\n",
        "                ],\n",
        "                [\n",
        "                    \"Magical diagrams and runes written with chalk on a blackboard, elegant, intricate, highly detailed, smooth, sharp focus, artstation, stunning masterpiece\",\n",
        "                    \"Magical diagrams and runes written with chalk on a blackboard, elegant, intricate, highly detailed, smooth, sharp focus, artstation, stunning masterpiece\",\n",
        "                    \"Magical diagrams and runes written with chalk on a blackboard, elegant, intricate, highly detailed, smooth, sharp focus, artstation, stunning masterpiece\",\n",
        "                    12, 12, 12,\n",
        "                    256,\n",
        "                    35,\n",
        "                    12591765619\n",
        "                ]\n",
        "            ],\n",
        "            inputs=[left_prompt, center_prompt, right_prompt, left_gs, center_gs, right_gs, overlap, steps, seed],\n",
        "            outputs=output,\n",
        "            fn=generate,\n",
        "            cache_examples=True\n",
        "        )\n",
        "    \n",
        "    button.click(\n",
        "        generate, \n",
        "        inputs=[left_prompt, center_prompt, right_prompt, left_gs, center_gs, right_gs, overlap, steps, seed],\n",
        "        outputs=output\n",
        "    )\n",
        "\n",
        "    with gr.Row():\n",
        "        gr.Markdown(article)\n",
        "\n",
        "demo.launch(server_name=\"0.0.0.0\", debug=True, share=True)"
      ]
    }
  ]
}