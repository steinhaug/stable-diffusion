{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1wbNO6C-BUm0ovKZyctjrtt3cd8KjB-37",
      "authorship_tag": "ABX9TyMbUe56eSLbMdUe1tR6D70q",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/steinhaug/stable-diffusion/blob/main/faceswap/v_express.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# V-Express\n",
        "\n",
        "Work in progress"
      ],
      "metadata": {
        "id": "abZLtD0TAHn7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## system tools"
      ],
      "metadata": {
        "id": "nhlTFfPvAQbI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ywLeOV9n0FdR",
        "outputId": "75562bbb-b6fd-4318-d91a-54c1b3a611fe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "diffusers==0.24.0: Not installed\n",
            "imageio-ffmpeg==0.4.9: Installed\n",
            "insightface==0.7.3: Not installed\n",
            "omegaconf==2.2.3: Not installed\n",
            "onnxruntime==1.16.3: Not installed\n",
            "safetensors==0.4.2: Different version installed (0.4.3)\n",
            "torch==2.0.1: Different version installed (2.3.0+cu121)\n",
            "torchaudio==2.0.2: Different version installed (2.3.0+cu121)\n",
            "torchvision==0.15.2: Different version installed (0.18.0+cu121)\n",
            "transformers==4.30.2: Different version installed (4.41.1)\n",
            "einops==0.4.1: Not installed\n",
            "tqdm==4.66.1: Different version installed (4.66.4)\n",
            "xformers==0.0.22: Not installed\n",
            "av==11.0.0: Not installed\n"
          ]
        }
      ],
      "source": [
        "import pkg_resources\n",
        "\n",
        "# List of packages to check with their required versions\n",
        "packages_to_check = [\n",
        "    (\"diffusers\", \"0.24.0\"),\n",
        "    (\"imageio-ffmpeg\", \"0.4.9\"),\n",
        "    (\"insightface\", \"0.7.3\"),\n",
        "    (\"omegaconf\", \"2.2.3\"),\n",
        "    (\"onnxruntime\", \"1.16.3\"),\n",
        "    (\"safetensors\", \"0.4.2\"),\n",
        "    (\"torch\", \"2.0.1\"),\n",
        "    (\"torchaudio\", \"2.0.2\"),\n",
        "    (\"torchvision\", \"0.15.2\"),\n",
        "    (\"transformers\", \"4.30.2\"),\n",
        "    (\"einops\", \"0.4.1\"),\n",
        "    (\"tqdm\", \"4.66.1\"),\n",
        "    (\"xformers\", \"0.0.22\"),\n",
        "    (\"av\", \"11.0.0\"),\n",
        "]\n",
        "\n",
        "# Function to check installed packages\n",
        "def check_installed_packages(packages):\n",
        "    installed_packages = {pkg.key: pkg.version for pkg in pkg_resources.working_set}\n",
        "    result = {}\n",
        "    for package, version in packages:\n",
        "        if package in installed_packages:\n",
        "            if installed_packages[package] == version:\n",
        "                result[package] = \"Installed\"\n",
        "            else:\n",
        "                result[package] = f\"Different version installed ({installed_packages[package]})\"\n",
        "        else:\n",
        "            result[package] = \"Not installed\"\n",
        "    return result\n",
        "\n",
        "# Check the packages and print the results\n",
        "installed_packages_status = check_installed_packages(packages_to_check)\n",
        "\n",
        "for package, status in installed_packages_status.items():\n",
        "    print(f\"{package}=={packages_to_check[[pkg[0] for pkg in packages_to_check].index(package)][1]}: {status}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import subprocess\n",
        "import re\n",
        "\n",
        "# List of packages to check for latest versions\n",
        "packages_to_check = [\n",
        "    \"diffusers\",\n",
        "    \"insightface\",\n",
        "    \"omegaconf\",\n",
        "    \"onnxruntime\",\n",
        "    \"einops\",\n",
        "    \"xformers\",\n",
        "    \"av\",\n",
        "]\n",
        "\n",
        "# Function to get the latest version of a package from pip\n",
        "def get_latest_version(package):\n",
        "    result = subprocess.run([\"pip\", \"index\", \"versions\", package], capture_output=True, text=True)\n",
        "    match = re.search(r'Available versions: (.*)', result.stdout)\n",
        "    if match:\n",
        "        versions = match.group(1).split(\", \")\n",
        "        return versions[0] if versions else None\n",
        "    return None\n",
        "\n",
        "# Get the latest versions\n",
        "latest_versions = {pkg: get_latest_version(pkg) for pkg in packages_to_check}\n",
        "latest_versions\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yvZcSCOC2OHC",
        "outputId": "265a9c3a-9fd9-409b-ee6d-e75a5af07fe6"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'diffusers': '0.28.0',\n",
              " 'insightface': '0.7.3',\n",
              " 'omegaconf': '2.3.0',\n",
              " 'onnxruntime': '1.18.0',\n",
              " 'einops': '0.8.0',\n",
              " 'xformers': '0.0.26.post1',\n",
              " 'av': '12.1.0'}"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pipdeptree\n",
        "!pipdeptree > dependency_tree.txt"
      ],
      "metadata": {
        "id": "qOeYro5xwb26"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#https://download.pytorch.org/whl/cu121/xformers-0.0.26.post1-cp310-cp310-manylinux2014_x86_64.whl\n",
        "#https://download.pytorch.org/whl/cu121/xformers-0.0.26-cp310-cp310-manylinux2014_x86_64.whl\n",
        "#https://download.pytorch.org/whl/cu121/xformers-0.0.25.post1-cp310-cp310-manylinux2014_x86_64.whl\n",
        "#https://download.pytorch.org/whl/cu121/xformers-0.0.25-cp310-cp310-manylinux2014_x86_64.whl\n",
        "#https://download.pytorch.org/whl/cu121/xformers-0.0.24-cp310-cp310-manylinux2014_x86_64.whl#sha256=018f928bd37b855021d12bff57797e729604474ccc2daa5504e1e4e4a5e6e3f7\n",
        "#https://download.pytorch.org/whl/cu121/xformers-0.0.23.post1-cp310-cp310-manylinux2014_x86_64.whl#sha256=f3491e4b1077314a4535fc78c36b592a13b794eefffaa308db879f7147424a96\n",
        "#https://download.pytorch.org/whl/cu121/xformers-0.0.23-cp310-cp310-manylinux2014_x86_64.whl#sha256=f739814d5279ff81c7955b1aa6dae2f462799f663f1d5785ed965acc833ed258\n",
        "#https://download.pytorch.org/whl/cu121/xformers-0.0.22.post7-cp310-cp310-manylinux2014_x86_64.whl#sha256=44c33373976705b1f3c5729a5ed24165b21536e3d3eedc58dd60ce68d3603f89\n",
        "#https://download.pytorch.org/whl/cu121/xformers-0.0.22.post4-cp310-cp310-manylinux2014_x86_64.whl#sha256=7075114dbf698b609b599f0d35032c0b2f9a389751e8bbf4dd3c628376b0dd9c\n",
        "#https://download.pytorch.org/whl/cu121/xformers-0.0.22.post3-cp310-cp310-manylinux2014_x86_64.whl#sha256=698f79c39327f043651f5c1022c35bbde52b17200198d9ba55081556685beeb8"
      ],
      "metadata": {
        "id": "JsK-1mZ25eoP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install"
      ],
      "metadata": {
        "id": "FX456_U6AWYf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget --content-disposition https://download.pytorch.org/whl/cu121/xformers-0.0.26.post1-cp310-cp310-manylinux2014_x86_64.whl -P /content\n",
        "#!pip install xformers==0.0.22\n",
        "!pip install xformers-0.0.26.post1-cp310-cp310-manylinux2014_x86_64.whl\n",
        "%pip install -q accelerate ftfy bitsandbytes"
      ],
      "metadata": {
        "id": "Fg5_IGXl6qM8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install diffusers==0.24.0\n",
        "!pip install insightface==0.7.3\n",
        "!pip install onnxruntime==1.16.3\n",
        "!pip install einops==0.4.1\n",
        "!pip install av==11.0.0"
      ],
      "metadata": {
        "id": "jFJwspXI5HrH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install omegaconf==2.2.3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "id": "ykApR9Ox7uFt",
        "outputId": "cdc59982-cba3-4f02-8933-c598d3536bde"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting omegaconf==2.2.3\n",
            "  Downloading omegaconf-2.2.3-py3-none-any.whl (79 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/79.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.3/79.3 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting antlr4-python3-runtime==4.9.* (from omegaconf==2.2.3)\n",
            "  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/117.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.0/117.0 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: PyYAML>=5.1.0 in /usr/local/lib/python3.10/dist-packages (from omegaconf==2.2.3) (6.0.1)\n",
            "Building wheels for collected packages: antlr4-python3-runtime\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144554 sha256=5bcfc237d31a9d02c2444bd3a24008898d741f1e62f60f9e2b788f0cb2fca141\n",
            "  Stored in directory: /root/.cache/pip/wheels/12/93/dd/1f6a127edc45659556564c5730f6d4e300888f4bca2d4c5a88\n",
            "Successfully built antlr4-python3-runtime\n",
            "Installing collected packages: antlr4-python3-runtime, omegaconf\n",
            "Successfully installed antlr4-python3-runtime-4.9.3 omegaconf-2.2.3\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "pydevd_plugins"
                ]
              },
              "id": "8da0ba0499c946a9bf2c930718ccbc30"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# download the codes\n",
        "!git clone https://github.com/tencent-ailab/V-Express\n",
        "\n",
        "# download the models\n",
        "%cd V-Express\n",
        "!git lfs install\n",
        "!git clone https://huggingface.co/tk93/V-Express\n",
        "!mv V-Express/model_ckpts model_ckpts"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "01W65xjQ38a0",
        "outputId": "0b0daa40-c0f0-42bf-f726-ce4e7ba259de"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'V-Express'...\n",
            "remote: Enumerating objects: 218, done.\u001b[K\n",
            "remote: Counting objects: 100% (27/27), done.\u001b[K\n",
            "remote: Compressing objects: 100% (17/17), done.\u001b[K\n",
            "remote: Total 218 (delta 13), reused 16 (delta 10), pack-reused 191\u001b[K\n",
            "Receiving objects: 100% (218/218), 142.82 MiB | 45.92 MiB/s, done.\n",
            "Resolving deltas: 100% (48/48), done.\n",
            "/content/V-Express\n",
            "Updated git hooks.\n",
            "Git LFS initialized.\n",
            "Cloning into 'V-Express'...\n",
            "remote: Enumerating objects: 50, done.\u001b[K\n",
            "remote: Counting objects: 100% (46/46), done.\u001b[K\n",
            "remote: Compressing objects: 100% (42/42), done.\u001b[K\n",
            "remote: Total 50 (delta 5), reused 0 (delta 0), pack-reused 4 (from 1)\u001b[K\n",
            "Unpacking objects: 100% (50/50), 11.87 KiB | 1.08 MiB/s, done.\n",
            "Filtering content: 100% (12/12), 6.02 GiB | 44.45 MiB/s, done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inference"
      ],
      "metadata": {
        "id": "UpoJE6y7AySf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# https://github.com/tencent-ailab/V-Express?tab=readme-ov-file"
      ],
      "metadata": {
        "id": "sj9hR4Ax_3eF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python scripts/extract_kps_sequence_and_audio.py \\\n",
        "    --video_path \"./test_samples/short_case/10/gt.mp4\" \\\n",
        "    --kps_sequence_save_path \"./test_samples/short_case/10/kps.pth\" \\\n",
        "    --audio_save_path \"./test_samples/short_case/10/aud.mp3\""
      ],
      "metadata": {
        "id": "mtwy08FS94Fa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python inference.py \\\n",
        "    --reference_image_path \"./test_samples/short_case/10/ref.jpg\" \\\n",
        "    --audio_path \"./test_samples/short_case/10/aud.mp3\" \\\n",
        "    --kps_path \"./test_samples/short_case/10/kps.pth\" \\\n",
        "    --output_path \"./output/short_case/talk_10_no_retarget.mp4\" \\\n",
        "    --retarget_strategy \"no_retarget\" \\\n",
        "    --num_inference_steps 25"
      ],
      "metadata": {
        "id": "46I2Ohwf4GQj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}