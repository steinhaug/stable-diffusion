{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/steinhaug/stable-diffusion/blob/main/smooth_infinite_zoom.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bynW8jh187Wq",
      "metadata": {
        "id": "bynW8jh187Wq"
      },
      "source": [
        "## Smooth Infinite Zoom v1.1\n",
        "\n",
        "A user friendly colab notebook to generate infinite loop videos in minutes (works on free colab plan)\n",
        "\n",
        "#### Examples and latest version available here:  \n",
        "[![Open in Colab](https://img.shields.io/badge/steinhaug-Open%20in%20Colab-blue?logo=google-colab)](https://colab.research.google.com/github/steinhaug/stable-diffusion/blob/main/smooth_infinite_zoom.ipynb)\n",
        "\n",
        "#### Derived work from: \n",
        "[![Open in Colab](https://img.shields.io/badge/v8hid-Open%20in%20Colab-blue?logo=google-colab)](https://colab.research.google.com/github/v8hid/infinite-zoom-stable-diffusion/blob/main/smooth_infinite_zoom.ipynb)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "oIZQ7ADVr8Bf",
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oIZQ7ADVr8Bf",
        "outputId": "b03809c3-e69e-45c7-d635-9bf1051af78b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tesla T4, 15360 MiB, 9308 MiB\n"
          ]
        }
      ],
      "source": [
        "#@markdown CHECK TYPE OF GPU AND VRAM AVAILABLE   <br>\n",
        "#@markdown The notebook should work fine with the Tesla T4 GPU + 16 GB VRAM available (but to a limited extend) in the free colab plan. <br>\n",
        "#@markdown If this drops an error you need go: Runtime / Change runtime type and pick Hardvare accelarator = GPU and GPU class = Standard.\n",
        "!nvidia-smi --query-gpu=name,memory.total,memory.free --format=csv,noheader"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "master_prompt = \"a naked woman, blue and green hair, short haircut, pale skin, slim body, high detailed skin, 8k uhd, dslr, soft lighting, high quality, film grain, Fujifilm XT3\"\n",
        "master_negati = \"\"\n",
        "prompts={\n",
        "    0: \"extreme close-up of face of \" + master_prompt + \", background is city ruins\",\n",
        "    5: \"background is city ruins\"\n",
        "}\n",
        "negative_prompts={\n",
        "    0: \"\" + master_negati,\n",
        "    5: \"\" + master_negati\n",
        "}\n"
      ],
      "metadata": {
        "id": "Qz26mZq-4u7-"
      },
      "id": "Qz26mZq-4u7-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.0 Install and setup cells"
      ],
      "metadata": {
        "id": "OgAPFQ2F45ah"
      },
      "id": "OgAPFQ2F45ah"
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.1 -> 1-4 must run."
      ],
      "metadata": {
        "id": "PglmqIjq8nCL"
      },
      "id": "PglmqIjq8nCL"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "70157fc1",
      "metadata": {
        "id": "70157fc1",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@markdown 1.1 Setup static settings\n",
        "from google.colab import drive\n",
        "from types import SimpleNamespace\n",
        "import math\n",
        "def progress(progress):\n",
        "    if progress>0:\n",
        "        prg = math.ceil(progress / 4)\n",
        "    else:\n",
        "        prg = progress\n",
        "    br=\"Progress : \" '|'+'█' * prg + ' ' * (25-prg)+'| ' +str(prg*4)+ \"%\"\n",
        "    return br\n",
        "\n",
        "def Static():\n",
        "    mount_google_drive = True #@param {type:\"boolean\"}\n",
        "    if (mount_google_drive) : \n",
        "      drive.mount('/content/gdrive')\n",
        "    output_path = \"/content/drive/MyDrive/infinite-zoom\" #@param {type:\"string\"}\n",
        "    return locals()\n",
        "\n",
        "static = Static()\n",
        "static = SimpleNamespace(**static)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "VYc3IHgCTs3E",
      "metadata": {
        "id": "VYc3IHgCTs3E",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@markdown 1.2 INSTALL DEPENDENCIES.\n",
        "from IPython.display import clear_output\n",
        "\n",
        "print(\"1/3: Install missing libraries\")\n",
        "%pip install -qq transformers scipy ftfy accelerate\n",
        "%pip install -qq --upgrade diffusers[torch]\n",
        "\n",
        "print(\"2/3: Load necessary libraries\")\n",
        "import PIL\n",
        "from PIL import Image\n",
        "import requests\n",
        "from io import BytesIO\n",
        "import numpy as np\n",
        "import random\n",
        "import cv2\n",
        "import os\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
        "import torch\n",
        "from diffusers import StableDiffusionInpaintPipeline, DPMSolverMultistepScheduler\n",
        "from IPython.display import clear_output\n",
        "from datetime import datetime\n",
        "if not os.path.exists(static.output_path):\n",
        "    os.makedirs(static.output_path)\n",
        "print(\"3/3: Define helper functions\")\n",
        "def write_video(file_path, frames, fps, reversed = True, start_frame_dupe_amount = 15, last_frame_dupe_amount = 30):\n",
        "  \"\"\"\n",
        "  Writes frames to an mp4 video file\n",
        "  :param file_path: Path to output video, must end with .mp4\n",
        "  :param frames: List of PIL.Image objects\n",
        "  :param fps: Desired frame rate\n",
        "  :param reversed: if order of images to be reversed (default = True)\n",
        "  \"\"\"\n",
        "  if reversed == True:\n",
        "    frames.reverse()\n",
        "\n",
        "  w, h = frames[0].size\n",
        "  fourcc = cv2.VideoWriter_fourcc('m', 'p', '4', 'v')\n",
        "  #fourcc = cv2.VideoWriter_fourcc('h', '2', '6', '4')\n",
        "  #fourcc = cv2.VideoWriter_fourcc(*'avc1')\n",
        "  writer = cv2.VideoWriter(file_path, fourcc, fps, (w, h))\n",
        "\n",
        "## start frame duplicated \n",
        "  for x in range(start_frame_dupe_amount):  \n",
        "    np_frame = np.array(frames[0].convert('RGB'))\n",
        "    cv_frame = cv2.cvtColor(np_frame, cv2.COLOR_RGB2BGR)\n",
        "    writer.write(cv_frame)\n",
        "  \n",
        "  for frame in frames:\n",
        "      np_frame = np.array(frame.convert('RGB'))\n",
        "      cv_frame = cv2.cvtColor(np_frame, cv2.COLOR_RGB2BGR)\n",
        "      writer.write(cv_frame)\n",
        "\n",
        "## last frame duplicated \n",
        "  for x in range(last_frame_dupe_amount):  \n",
        "    np_frame = np.array(frames[len(frames) - 1].convert('RGB'))\n",
        "    cv_frame = cv2.cvtColor(np_frame, cv2.COLOR_RGB2BGR)\n",
        "    writer.write(cv_frame)\n",
        "    \n",
        "  writer.release() \n",
        "\n",
        "def image_grid(imgs, rows, cols):\n",
        "  assert len(imgs) == rows*cols\n",
        "\n",
        "  w, h = imgs[0].size\n",
        "  grid = Image.new('RGB', size=(cols*w, rows*h))\n",
        "  grid_w, grid_h = grid.size\n",
        "\n",
        "  for i, img in enumerate(imgs):\n",
        "      grid.paste(img, box=(i%cols*w, i//cols*h))\n",
        "  return grid\n",
        "\n",
        "def shrink_and_paste_on_blank(current_image, mask_width):\n",
        "  \"\"\"\n",
        "  Decreases size of current_image by mask_width pixels from each side,\n",
        "  then adds a mask_width width transparent frame, \n",
        "  so that the image the function returns is the same size as the input. \n",
        "  :param current_image: input image to transform\n",
        "  :param mask_width: width in pixels to shrink from each side\n",
        "  \"\"\"\n",
        "\n",
        "  height = current_image.height\n",
        "  width = current_image.width\n",
        "\n",
        "  #shrink down by mask_width\n",
        "  prev_image = current_image.resize((height-2*mask_width,width-2*mask_width))\n",
        "  prev_image = prev_image.convert(\"RGBA\")\n",
        "  prev_image = np.array(prev_image)\n",
        "\n",
        "  #create blank non-transparent image\n",
        "  blank_image = np.array(current_image.convert(\"RGBA\"))*0\n",
        "  blank_image[:,:,3] = 1\n",
        "\n",
        "  #paste shrinked onto blank\n",
        "  blank_image[mask_width:height-mask_width,mask_width:width-mask_width,:] = prev_image\n",
        "  prev_image = Image.fromarray(blank_image)\n",
        "\n",
        "  return prev_image\n",
        "  \n",
        "def load_img(address, res=(512, 512)):\n",
        "    if address.startswith('http://') or address.startswith('https://'):\n",
        "        image = Image.open(requests.get(address, stream=True).raw)\n",
        "    else:\n",
        "        image = Image.open(address)\n",
        "    image = image.convert('RGB')\n",
        "    image = image.resize(res, resample=Image.LANCZOS)\n",
        "    return image\n",
        "\n",
        "clear_output(); print('[1;32mDone! ✓')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bbdb396d-f01c-4b4b-9307-b0f78eaa9ffd",
      "metadata": {
        "cellView": "form",
        "id": "bbdb396d-f01c-4b4b-9307-b0f78eaa9ffd"
      },
      "outputs": [],
      "source": [
        "#@markdown 1.3 SET UP DIFFUSION PIPELINE WITH INPAINT MODEL<br><br>\n",
        "#@markdown Select inpainting model:\n",
        "model_id = 'Uminosachi/revAnimated_v121Inp-inpainting' #@param [\"saik0s/realistic_vision_inpainting\", \"Uminosachi/revAnimated_v121Inp-inpainting\", \"stabilityai/stable-diffusion-2-inpainting\", \"runwayml/stable-diffusion-inpainting\", \"ImNoOne/f222-inpainting-diffusers\",\"parlance/dreamlike-diffusion-1.0-inpainting\",\"ghunkins/stable-diffusion-liberty-inpainting\"] {allow-input: true}\n",
        "pipe = StableDiffusionInpaintPipeline.from_pretrained(\n",
        "    model_id,\n",
        "    torch_dtype=torch.float16,\n",
        ")\n",
        "pipe.scheduler = DPMSolverMultistepScheduler.from_config(pipe.scheduler.config)\n",
        "pipe = pipe.to(\"cuda\")\n",
        "def dummy(images, **kwargs):\n",
        "    return images, str(False)\n",
        "#pipe.safety_checker = dummy\n",
        "pipe.safety_checker = None\n",
        "pipe.enable_attention_slicing() #This is useful to save some memory in exchange for a small speed decrease.\n",
        "\n",
        "g_cuda = torch.Generator(device='cuda')  \n",
        "clear_output(); print('[1;32mDone! ✓')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e53e31ca-0992-425b-ba26-3906e4a974d6",
      "metadata": {
        "cellView": "form",
        "id": "e53e31ca-0992-425b-ba26-3906e4a974d6"
      },
      "outputs": [],
      "source": [
        "#@markdown 1.4 DIFFUSION SETTINGS: <br>\n",
        "#@markdown (Image output of this block will be the last image of the video)\n",
        "\n",
        "prompt = prompts[0]\n",
        "\n",
        "#@markdown Appended to all possible negative prompts in array above:\n",
        "negative_prompt = \"montage, frame, text, ugly, blur\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown Number of initial example images to generate:\n",
        "num_init_images = 1 #@param\n",
        "#@markdown Random seed (arbitrary input to make the initial image generation deterministic):\n",
        "seed = 9999 #@param\n",
        "#@markdown  The number of denoising steps (Higher number usually lead to a higher quality image at the expense of slower inference):\n",
        "num_inference_steps = 30 #@param\n",
        "#@markdown Guidance scale defines how closely generated images to be linked to the text prompt:\n",
        "guidance_scale = 6 #@param\n",
        "#@markdown Heigth (and width) of the images in pixels (= resolution of the video generated in the next block, has to be divisible with 8):\n",
        "height = 512 #@param\n",
        "width = height \n",
        "#@markdown Since the model was trained on 512 images increasing the resolution to e.g. 1024 will\n",
        "#@markdown drastically reduce its imagination, so the video will vary a lot less compared to 512\n",
        "\n",
        "current_image = PIL.Image.new(mode=\"RGBA\", size=(height, width))\n",
        "mask_image = np.array(current_image)[:,:,3] \n",
        "mask_image = Image.fromarray(255-mask_image).convert(\"RGB\")\n",
        "current_image = current_image.convert(\"RGB\")\n",
        "\n",
        "print( prompt*num_init_images )\n",
        "print( negative_prompt*num_init_images )\n",
        "\n",
        "init_images =  pipe(prompt=prompt*num_init_images,\n",
        "                    negative_prompt=negative_prompt*num_init_images,\n",
        "                    image=current_image,\n",
        "                    guidance_scale = guidance_scale,\n",
        "                    height = height,\n",
        "                    width = width, \n",
        "                    generator = g_cuda.manual_seed(seed),\n",
        "                    mask_image=mask_image, \n",
        "                    num_inference_steps=num_inference_steps)[0]\n",
        "\n",
        "image_grid(init_images, rows=1, cols=num_init_images)\n",
        "\n",
        "#@markdown We shrink the init image from the previous block and outpaint its outer frame using the same concept defined above (e.g. prompt, negative prompt, inference steps) but with a different seed. To generate an \"inifinte zoom\" video this is repeated **num_outpainting_steps** times and then rendered in reversed order.<br><br>\n",
        "#@markdown To keep the outpainted part coherent and full of new content its width has to be relatively large (e.g. **mask_width** = 128 pixels if resolution is 512*512).<br><br>\n",
        "#@markdown This on the other hand means that the generated video would be too fast and aestetically unpleasant. To slow down and smoothen the video we generate num_interpol_frames additional images between outpainted images using simple \"interpolation\".<br><br>\n",
        "#@markdown Notes:<br><ul><li>Length of the video is proportional to num_outpainting_steps * num_interpol_frames.</li>\n",
        "#@markdown <li>The time to generate the video is proportional to num_outpainting_steps.</li><li>On a T4 GPU it takes about ~7 minutes to generate the video of width = 512, num_inference_steps = 20, num_outpainting_steps = 100. With fps = 24 and num_interpol_frames = 24 the video will be about 1:40 minutes long.</li></ul>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.0 Generate Video and keyframe cells"
      ],
      "metadata": {
        "id": "AL_TU6t95dTC"
      },
      "id": "AL_TU6t95dTC"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "62b4aed2-0dae-4c39-a445-5d901e81036e",
      "metadata": {
        "cellView": "form",
        "id": "62b4aed2-0dae-4c39-a445-5d901e81036e"
      },
      "outputs": [],
      "source": [
        "#@markdown 2.1 GENERATE VIDEO - REQUIRES USER FEEDBACK WHILE RENDERING:<br>\n",
        "#@markdown For each keyframe you must select 1, 2 or 3 of generated images. If not the keyframe is re-rendered with the input as negative prompt until you select 1, 2 or 3.\n",
        "skip_manual_guideance = False  #@param {type:\"boolean\"}\n",
        "\n",
        "from PIL import Image, ImageOps\n",
        "import os.path\n",
        "from IPython.display import display\n",
        "#zoom_name = \"ladyzoom\" #@param {type:\"string\"}\n",
        "#zoom_path = \"/content/gdrive/MyDrive/infinite-zoom\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown Pick an initial image from the previous block for your video: <br> (This is only relevant if num_init_images > 1)\n",
        "init_image_selected = 1 #@param\n",
        "if num_init_images == 1:\n",
        "  init_image_selected = 0\n",
        "else:\n",
        "  init_image_selected = init_image_selected - 1\n",
        "custom_init_image = False #@param {type:\"boolean\"}\n",
        "init_image_address = \"/content/drive/MyDrive/infinite-zoom/image.png\"#@param {type:\"string\"}\n",
        "#@markdown Number of outpainting steps:\n",
        "num_outpainting_steps = 10 #@param\n",
        "#@markdown Width of the border in pixels to be outpainted during each step:\n",
        "#@markdown <br> (make sure: mask_width < image resolution / 2)\n",
        "mask_width = 128 #@param\n",
        "#@markdown Number of images to be interpolated between each outpainting step:\n",
        "num_interpol_frames = 30 #@param \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "377b2064-7c0e-404b-8366-8d03befb840a",
      "metadata": {
        "id": "377b2064-7c0e-404b-8366-8d03befb840a",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@markdown 2.2 GENERATE VIDEO - REQUIRES USER FEEDBACK WHILE RENDERING:\n",
        "\n",
        "if(custom_init_image):\n",
        "  current_image = load_img(init_image_address,(width,height))\n",
        "else :\n",
        "  current_image = init_images[init_image_selected]\n",
        "all_frames = []\n",
        "all_frames.append(current_image)\n",
        "\n",
        "log_all = []\n",
        "\n",
        "tmp_i = 0\n",
        "for i in range(num_outpainting_steps):\n",
        "  print('Generating image: ' + str(i+1) + ' / ' + str(num_outpainting_steps))\n",
        "\n",
        "  prev_image_fix = current_image\n",
        "\n",
        "  prev_image = shrink_and_paste_on_blank(current_image, mask_width)\n",
        "\n",
        "  current_image = prev_image\n",
        "  log_current_image = current_image\n",
        "\n",
        "  #create mask (black image with white mask_width width edges)\n",
        "  mask_image = np.array(current_image)[:,:,3] \n",
        "  mask_image = Image.fromarray(255-mask_image).convert(\"RGB\")\n",
        "\n",
        "  curr_key = max(k for k in prompts.keys() if k <= i)\n",
        "  curr_prompt = prompts[curr_key]\n",
        "  curr_negative_prompt = negative_prompt\n",
        "\n",
        "  if negative_prompts.__contains__(curr_key):\n",
        "    curr_negative_prompt = negative_prompts[curr_key] + negative_prompt\n",
        "\n",
        "  # new inpaint logic\n",
        "#  image_filename = zoom_path + '/' + zoom_name + '/' + str(i) + '.png'\n",
        "#  if os.path.isfile(image_filename):\n",
        "#    current_image = Image.open(image_filename)\n",
        "#  else:\n",
        "#    #inpainting step\n",
        "#    current_image = current_image.convert(\"RGB\")\n",
        "#    images = pipe(prompt=curr_prompt,\n",
        "#                  negative_prompt=curr_negative_prompt,\n",
        "#                  image=current_image,\n",
        "#                  guidance_scale = guidance_scale,\n",
        "#                  height = height,\n",
        "#                  width = width, \n",
        "#                  #this can make the whole thing deterministic but the output less exciting\n",
        "#                  #generator = g_cuda.manual_seed(seed), \n",
        "#                  mask_image=mask_image, \n",
        "#                  num_inference_steps=num_inference_steps)[0]\n",
        "#    current_image = images[0]\n",
        "\n",
        "  this_negative_prompt = curr_negative_prompt\n",
        "  repaint = True\n",
        "  while repaint:\n",
        "    images1 = pipe(prompt=curr_prompt,\n",
        "                  negative_prompt=this_negative_prompt,\n",
        "                  image=current_image,\n",
        "                  guidance_scale = guidance_scale,\n",
        "                  height = height,\n",
        "                  width = width, \n",
        "                  mask_image=mask_image, \n",
        "                  num_inference_steps=num_inference_steps)[0]\n",
        "    if skip_manual_guideance:\n",
        "      current_image = images1[0]\n",
        "      break\n",
        "\n",
        "    images2 = pipe(prompt=curr_prompt,\n",
        "                  negative_prompt=this_negative_prompt,\n",
        "                  image=current_image,\n",
        "                  guidance_scale = guidance_scale,\n",
        "                  height = height,\n",
        "                  width = width, \n",
        "                  generator = g_cuda.manual_seed(666), \n",
        "                  mask_image=mask_image, \n",
        "                  num_inference_steps=num_inference_steps)[0]\n",
        "    images3 = pipe(prompt=curr_prompt,\n",
        "                  negative_prompt=this_negative_prompt,\n",
        "                  image=current_image,\n",
        "                  guidance_scale = guidance_scale,\n",
        "                  height = height,\n",
        "                  width = width,\n",
        "                  generator = g_cuda.manual_seed(seed), \n",
        "                  mask_image=mask_image, \n",
        "                  num_inference_steps=num_inference_steps)[0]\n",
        "\n",
        "    clear_output(wait=True)\n",
        "    current_image_with_border = ImageOps.expand(current_image,border=1,fill='black')\n",
        "    display(current_image_with_border.resize((256, 256)))\n",
        "\n",
        "    fig, ((ax1, ax2, ax3)) = plt.subplots(1, 3, figsize=(12, 4), gridspec_kw={'hspace': 0, 'wspace': 0}, sharex=True, sharey=True)\n",
        "    ax1.imshow(images1[0]); ax1.axis('off'); ax1.set_title(1)\n",
        "    ax2.imshow(images2[0]); ax2.axis('off'); ax2.set_title(2)\n",
        "    ax3.imshow(images3[0]); ax3.axis('off'); ax3.set_title(3)\n",
        "    plt.show()\n",
        "\n",
        "    print(f'Negative prompt: {this_negative_prompt}')\n",
        "    what_image = input(f'Frame {tmp_i}: 1, 2 or 3? Or negative prompt: ')\n",
        "    if what_image == '1':\n",
        "      repaint = False\n",
        "      current_image = images1[0]\n",
        "    elif what_image == '2':\n",
        "      repaint = False\n",
        "      current_image = images2[0]\n",
        "    elif what_image == '3':\n",
        "      repaint = False\n",
        "      current_image = images3[0]\n",
        "    else:\n",
        "      this_negative_prompt = what_image\n",
        "      print(f'Prompt: {curr_prompt}')\n",
        "      new_prompt = input(f'New prompt: ')\n",
        "      if len(new_prompt) > 3:\n",
        "        curr_prompt = new_prompt\n",
        "\n",
        "  current_image.paste(prev_image, mask=prev_image)\n",
        "\n",
        "  interpol_image_done = True;\n",
        "\n",
        "  #interpolation steps bewteen 2 inpainted images (=sequential zoom and crop)\n",
        "  for j in range(num_interpol_frames - 1):\n",
        "    interpol_image = current_image\n",
        "    interpol_width = round(\n",
        "        (1- ( 1-2*mask_width/height )**( 1-(j+1)/num_interpol_frames ) )*height/2 \n",
        "        )\n",
        "    interpol_image = interpol_image.crop((interpol_width,\n",
        "                                          interpol_width,\n",
        "                                          width - interpol_width,\n",
        "                                          height - interpol_width))\n",
        "\n",
        "    if interpol_image_done:\n",
        "      interpol_image_raw1 = interpol_image\n",
        "\n",
        "    interpol_image = interpol_image.resize((height, width))\n",
        "\n",
        "    #paste the higher resolution previous image in the middle to avoid drop in quality caused by zooming\n",
        "    interpol_width2 = round(\n",
        "        ( 1 - (height-2*mask_width) / (height-2*interpol_width) ) / 2*height\n",
        "    )\n",
        "    prev_image_fix_crop = shrink_and_paste_on_blank(prev_image_fix, interpol_width2)\n",
        "    interpol_image.paste(prev_image_fix_crop, mask = prev_image_fix_crop)\n",
        "\n",
        "    if interpol_image_done:\n",
        "      interpol_image_done = False\n",
        "      interpol_image_raw2 = prev_image_fix_crop\n",
        "      interpol_image_raw3 = interpol_image\n",
        "\n",
        "    all_frames.append(interpol_image)\n",
        "\n",
        "  log_item = [\n",
        "      log_current_image,\n",
        "      current_image,\n",
        "      interpol_image_raw1,\n",
        "      interpol_image_raw2,\n",
        "      interpol_image,\n",
        "      curr_prompt,\n",
        "      curr_negative_prompt\n",
        "  ]\n",
        "  log_all.append(log_item)\n",
        "\n",
        "  all_frames.append(current_image)\n",
        "  clear_output(wait=True)\n",
        "  interpol_image.show()\n",
        "  \n",
        "  tmp_i += 1\n",
        "  #if tmp_i == 8:\n",
        "  #  print('Temp break, tmp_i')\n",
        "  #  break\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Debugging cells (no need to run theese)"
      ],
      "metadata": {
        "id": "Qc3RFGJw5016"
      },
      "id": "Qc3RFGJw5016"
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown Debug prompts and negative prompts\n",
        "from IPython.display import display\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image, ImageOps, ImageDraw\n",
        "\n",
        "i=0\n",
        "for img1, img2, image1, image2, image3, prompt, negative_prompt in log_all:\n",
        "\n",
        "    #draw = ImageDraw.Draw(image)\n",
        "    #draw.rectangle(((192, 192), (128, 128)), outline=(255,0,0))\n",
        "    #img_with_border = ImageOps.expand(image,border=1,fill='red')\n",
        "    w1, h1 = img1.size; w2, h2 = img2.size; w3, h3 = image1.size; w4, h4 = image2.size; w5, h5 = image3.size\n",
        "    fig, ((ax1, ax2, ax3, ax4, ax5)) = plt.subplots(1, 5, figsize=(15, 3), gridspec_kw={'hspace': 0, 'wspace': 0}, sharex=True, sharey=True)\n",
        "    ax1.imshow(img1.resize((256, 256))); ax1.axis('off'); ax1.set_title(str(w1) + ' x ' + str(h1))\n",
        "    ax2.imshow(img2.resize((256, 256))); ax2.axis('off'); ax2.set_title(str(w2) + ' x ' + str(h2))\n",
        "    ax3.imshow(image1.resize((131, 131))); ax3.axis('off'); ax3.set_title(str(w3) + ' x ' + str(h3))\n",
        "    ax4.imshow(image2.resize((256, 256))); ax4.axis('off'); ax4.set_title(str(w4) + ' x ' + str(h4))\n",
        "    ax5.imshow(image3.resize((256, 256))); ax5.axis('off'); ax5.set_title(str(w5) + ' x ' + str(h5))\n",
        "    plt.show()\n",
        "    #print(str(w1) + ' x ' + str(h1) + '. ' + str(w2) + ' x ' + str(h2) + '. ' + str(w3) + ' x ' + str(h3) + '. ' + str(w4) + ' x ' + str(h4) +  '. ' + str(w5) + ' x ' + str(h5) + '.')\n",
        "    print(f'Frame {i}')\n",
        "    print(f'Prompt: {prompt}')\n",
        "    print(f'Negative prompt: {negative_prompt}')\n",
        "\n",
        "    #if i >= 1:\n",
        "    #    break\n",
        "    i += 1\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "nzsBBT0I52xG"
      },
      "id": "nzsBBT0I52xG",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown Debug - Re-render frames\n",
        "frame_to_rerender = 4 #@param {type:\"number\"}\n",
        "pre_negpro = \"\"\n",
        "\n",
        "i=0\n",
        "for img1, img2, image1, image2, image3, prompt, negative_prompt in log_all:\n",
        "    if i == frame_to_rerender:\n",
        "\n",
        "        if negative_prompt == 'negative_prompt':\n",
        "            negative_prompt = ''\n",
        "\n",
        "        w1, h1 = img1.size; w2, h2 = img2.size; w3, h3 = image1.size; w4, h4 = image2.size; w5, h5 = image3.size\n",
        "        fig, ((ax1, ax2, ax3, ax4, ax5)) = plt.subplots(1, 5, figsize=(15, 3), gridspec_kw={'hspace': 0, 'wspace': 0}, sharex=True, sharey=True)\n",
        "        ax1.imshow(img1.resize((256, 256))); ax1.axis('off'); ax1.set_title(str(w1) + ' x ' + str(h1))\n",
        "        ax2.imshow(img2.resize((256, 256))); ax2.axis('off'); ax2.set_title(str(w2) + ' x ' + str(h2))\n",
        "        ax3.imshow(image1.resize((131, 131))); ax3.axis('off'); ax3.set_title(str(w3) + ' x ' + str(h3))\n",
        "        ax4.imshow(image2.resize((256, 256))); ax4.axis('off'); ax4.set_title(str(w4) + ' x ' + str(h4))\n",
        "        ax5.imshow(image3.resize((256, 256))); ax5.axis('off'); ax5.set_title(str(w5) + ' x ' + str(h5))\n",
        "        plt.show()\n",
        "\n",
        "        images1 = pipe(prompt=prompt,\n",
        "                    negative_prompt=pre_negpro + negative_prompt,\n",
        "                    image=img1,\n",
        "                    guidance_scale = guidance_scale,\n",
        "                    height = height,\n",
        "                    width = width, \n",
        "                    mask_image=mask_image, \n",
        "                    num_inference_steps=num_inference_steps)[0]\n",
        "        images2 = pipe(prompt=prompt,\n",
        "                    negative_prompt=pre_negpro + negative_prompt,\n",
        "                    image=img1,\n",
        "                    guidance_scale = guidance_scale,\n",
        "                    height = height,\n",
        "                    width = width, \n",
        "                    mask_image=mask_image, \n",
        "                    num_inference_steps=num_inference_steps)[0]\n",
        "        images3 = pipe(prompt=prompt,\n",
        "                    negative_prompt=pre_negpro + negative_prompt,\n",
        "                    image=img1,\n",
        "                    guidance_scale = guidance_scale,\n",
        "                    height = height,\n",
        "                    width = width, \n",
        "                    mask_image=mask_image, \n",
        "                    num_inference_steps=num_inference_steps)[0]\n",
        "\n",
        "        fig, ((ax1, ax2, ax3)) = plt.subplots(1, 3, figsize=(15, 5), gridspec_kw={'hspace': 0, 'wspace': 0}, sharex=True, sharey=True)\n",
        "\n",
        "        ax1.imshow(images1[0]); ax1.axis('off'); ax1.set_title(zoom_name + '/' + str(i) + '.png A')\n",
        "        ax2.imshow(images2[0]); ax2.axis('off'); ax2.set_title(zoom_name + '/' + str(i) + '.png B')\n",
        "        ax3.imshow(images3[0]); ax3.axis('off'); ax3.set_title(zoom_name + '/' + str(i) + '.png C')\n",
        "        plt.show()\n",
        "\n",
        "    i += 1\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "UkR7YDWw520N"
      },
      "id": "UkR7YDWw520N",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.0 Finalize Video, generate and save your video"
      ],
      "metadata": {
        "id": "rZfnpWan53Nr"
      },
      "id": "rZfnpWan53Nr"
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown 3.1 CREATE VIDEO, RENDER MP4 FRAMES.\n",
        "video_file_name = \"manual_infinite_zoom\" #@param {type:\"string\"}\n",
        "#@markdown frames per second:\n",
        "fps = 30 #@param\n",
        "now = datetime.now()\n",
        "date_time = now.strftime(\"%m-%d-%Y_%H-%M-%S\")\n",
        "#@markdown Duplicates the first and last frames, use to add a delay before animation based on playback fps (15 = 0.5 seconds @ 30fps)\n",
        "start_frame_dupe_amount = 15 #@param\n",
        "last_frame_dupe_amount = 15 #@param\n",
        "write_video(os.path.join(static.output_path, video_file_name + \"_out_\"+date_time+\".mp4\"), all_frames, fps, False, start_frame_dupe_amount, last_frame_dupe_amount)\n",
        "write_video(os.path.join(static.output_path, video_file_name + \"_in_\"+date_time+\".mp4\"), all_frames, fps, True, start_frame_dupe_amount, last_frame_dupe_amount)\n",
        "#@markdown Once this block is finished, download your video from the \"Files\" folder menu on the left (output_path).\n",
        "print(f'Video saved in: {output_path}')\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "YNWofEVc6ArE"
      },
      "id": "YNWofEVc6ArE",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "uGFjrJkTOUZt",
      "metadata": {
        "cellView": "form",
        "id": "uGFjrJkTOUZt"
      },
      "outputs": [],
      "source": [
        "#@markdown 3.2 CHECK SOME (equally spaced) FRAMES OF THE VIDEO:\n",
        "num_of_frames_to_chk = 4 #@param\n",
        "num_of_frames_to_chk = min(num_of_frames_to_chk, len(all_frames))\n",
        "idx = np.round(np.linspace(0, len(all_frames) - 1, num_of_frames_to_chk)).astype(int)\n",
        "image_grid(list(all_frames[i] for i in idx), rows = 1, cols = num_of_frames_to_chk)\n",
        "#@markdown (This is relatively slow but still faster in some cases then to download the complete video in the previous block)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "db751f19a851203103a0bb17a8ccebdb9f60364948df4a7f3512c43de08ae3e7"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}