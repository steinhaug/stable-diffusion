{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/steinhaug/stable-diffusion/blob/main/tool/nogui__demucs_and_whisper.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Mount Google Drive"
      ],
      "metadata": {
        "id": "A76lsOF56lIN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Drive at /content/drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "WdmgnE19jrJQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0840e8bd-356b-4a6e-8632-ed59a205249b"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Refresh Drive connection\n",
        "drive.mount(\"/content/drive\", force_remount=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Wx2VZ2teF4L",
        "outputId": "a208655c-ab9f-4853-cd52-33baabd6bd6a"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GPU Mode: Stem Splitting (VOICE, BASS, etc)"
      ],
      "metadata": {
        "id": "bZ0mCU9Mo9Oj"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "79JbZGcAqX3p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "79326db9-8cb1-4e66-f178-7a3d9359a4ce",
        "collapsed": true
      },
      "source": [
        "# Install the demucs library by Facebook research\n",
        "!python3 -m pip install -U git+https://github.com/facebookresearch/demucs#egg=demucs"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting demucs\n",
            "  Cloning https://github.com/facebookresearch/demucs to /tmp/pip-install-g92vrxp3/demucs_23ff90c2f5954f49b1e5b9981e0de8a1\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/facebookresearch/demucs /tmp/pip-install-g92vrxp3/demucs_23ff90c2f5954f49b1e5b9981e0de8a1\n",
            "  Resolved https://github.com/facebookresearch/demucs to commit e976d93ecc3865e5757426930257e200846a520a\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting dora-search (from demucs)\n",
            "  Downloading dora_search-0.1.12.tar.gz (87 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.1/87.1 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.10/dist-packages (from demucs) (0.8.0)\n",
            "Collecting julius>=0.2.3 (from demucs)\n",
            "  Downloading julius-0.2.7.tar.gz (59 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.6/59.6 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting lameenc>=1.2 (from demucs)\n",
            "  Downloading lameenc-1.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_28_x86_64.whl.metadata (803 bytes)\n",
            "Collecting openunmix (from demucs)\n",
            "  Downloading openunmix-1.3.0-py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from demucs) (6.0.2)\n",
            "Requirement already satisfied: torch>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from demucs) (2.4.1+cu121)\n",
            "Collecting torchaudio<2.1,>=0.8 (from demucs)\n",
            "  Downloading torchaudio-2.0.2-cp310-cp310-manylinux1_x86_64.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from demucs) (4.66.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->demucs) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->demucs) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->demucs) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->demucs) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->demucs) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->demucs) (2024.6.1)\n",
            "Collecting torch>=1.8.1 (from demucs)\n",
            "  Downloading torch-2.0.1-cp310-cp310-manylinux1_x86_64.whl.metadata (24 kB)\n",
            "Collecting nvidia-cuda-nvrtc-cu11==11.7.99 (from torch>=1.8.1->demucs)\n",
            "  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu11==11.7.99 (from torch>=1.8.1->demucs)\n",
            "  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cuda-cupti-cu11==11.7.101 (from torch>=1.8.1->demucs)\n",
            "  Downloading nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu11==8.5.0.96 (from torch>=1.8.1->demucs)\n",
            "  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu11==11.10.3.66 (from torch>=1.8.1->demucs)\n",
            "  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cufft-cu11==10.9.0.58 (from torch>=1.8.1->demucs)\n",
            "  Downloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu11==10.2.10.91 (from torch>=1.8.1->demucs)\n",
            "  Downloading nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusolver-cu11==11.4.0.1 (from torch>=1.8.1->demucs)\n",
            "  Downloading nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu11==11.7.4.91 (from torch>=1.8.1->demucs)\n",
            "  Downloading nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu11==2.14.3 (from torch>=1.8.1->demucs)\n",
            "  Downloading nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu11==11.7.91 (from torch>=1.8.1->demucs)\n",
            "  Downloading nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting triton==2.0.0 (from torch>=1.8.1->demucs)\n",
            "  Downloading triton-2.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.0 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.8.1->demucs) (71.0.4)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.8.1->demucs) (0.44.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.8.1->demucs) (3.30.3)\n",
            "Collecting lit (from triton==2.0.0->torch>=1.8.1->demucs)\n",
            "  Downloading lit-18.1.8-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting omegaconf (from dora-search->demucs)\n",
            "  Downloading omegaconf-2.3.0-py3-none-any.whl.metadata (3.9 kB)\n",
            "Collecting retrying (from dora-search->demucs)\n",
            "  Downloading retrying-1.3.4-py3-none-any.whl.metadata (6.9 kB)\n",
            "Collecting submitit (from dora-search->demucs)\n",
            "  Downloading submitit-1.5.2-py3-none-any.whl.metadata (7.9 kB)\n",
            "Collecting treetable (from dora-search->demucs)\n",
            "  Downloading treetable-0.2.5.tar.gz (10 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from openunmix->demucs) (1.26.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.1->demucs) (2.1.5)\n",
            "Collecting antlr4-python3-runtime==4.9.* (from omegaconf->dora-search->demucs)\n",
            "  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.0/117.0 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: six>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from retrying->dora-search->demucs) (1.16.0)\n",
            "Requirement already satisfied: cloudpickle>=1.2.1 in /usr/local/lib/python3.10/dist-packages (from submitit->dora-search->demucs) (2.2.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.1->demucs) (1.3.0)\n",
            "Downloading lameenc-1.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_28_x86_64.whl (239 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m239.8/239.8 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchaudio-2.0.2-cp310-cp310-manylinux1_x86_64.whl (4.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m68.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torch-2.0.1-cp310-cp310-manylinux1_x86_64.whl (619.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m619.9/619.9 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl (11.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.8/11.8 MB\u001b[0m \u001b[31m59.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m21.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.3/849.3 kB\u001b[0m \u001b[31m29.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux2014_x86_64.whl (168.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.4/168.4 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl (54.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.6/54.6 MB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl (102.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.6/102.6 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl (173.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m173.2/173.2 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl (177.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.1/177.1 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl (98 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.6/98.6 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading triton-2.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (63.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.3/63.3 MB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading openunmix-1.3.0-py3-none-any.whl (40 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.0/40.0 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading omegaconf-2.3.0-py3-none-any.whl (79 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading retrying-1.3.4-py3-none-any.whl (11 kB)\n",
            "Downloading submitit-1.5.2-py3-none-any.whl (74 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.9/74.9 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lit-18.1.8-py3-none-any.whl (96 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.4/96.4 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: demucs, julius, dora-search, antlr4-python3-runtime, treetable\n",
            "  Building wheel for demucs (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for demucs: filename=demucs-4.1.0a2-py3-none-any.whl size=83540 sha256=f98a28845c64ea9ad05cd1084763ceb2afcd139c61451000158f6f3f9b3c9b65\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-2thox0ey/wheels/45/e4/ca/7791f04b554e5433713e22900eaf11595e27c454fb65ac30ab\n",
            "  Building wheel for julius (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for julius: filename=julius-0.2.7-py3-none-any.whl size=21869 sha256=89255c5fb1d183bd9eaa5e6001f803bfba47b739270bd66134af0af437f42a48\n",
            "  Stored in directory: /root/.cache/pip/wheels/b9/b2/05/f883527ffcb7f2ead5438a2c23439aa0c881eaa9a4c80256f4\n",
            "  Building wheel for dora-search (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for dora-search: filename=dora_search-0.1.12-py3-none-any.whl size=75092 sha256=64973ed4309066ecd4bcdb80d850986f7382c9ebd021f0c6e1155d70d56e52df\n",
            "  Stored in directory: /root/.cache/pip/wheels/b1/c2/c0/bea5cc405497284d584b958f293ef32c23bad42ae5e44d973c\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144554 sha256=4f8d5cf6b4c46f905573097188e32ca260b610e615eca0e401c9145754ef54a9\n",
            "  Stored in directory: /root/.cache/pip/wheels/12/93/dd/1f6a127edc45659556564c5730f6d4e300888f4bca2d4c5a88\n",
            "  Building wheel for treetable (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for treetable: filename=treetable-0.2.5-py3-none-any.whl size=7332 sha256=9836d63a1706e0c84a2a8fa165919ba3635679950c723219c6ee2e08fe74bb06\n",
            "  Stored in directory: /root/.cache/pip/wheels/72/55/0e/91c3655bdb162446f8a7cd477579397544454a63ae7c599c0c\n",
            "Successfully built demucs julius dora-search antlr4-python3-runtime treetable\n",
            "Installing collected packages: lit, lameenc, antlr4-python3-runtime, treetable, submitit, retrying, omegaconf, nvidia-nvtx-cu11, nvidia-nccl-cu11, nvidia-cusparse-cu11, nvidia-curand-cu11, nvidia-cufft-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cuda-cupti-cu11, nvidia-cublas-cu11, nvidia-cusolver-cu11, nvidia-cudnn-cu11, triton, torch, torchaudio, openunmix, julius, dora-search, demucs\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.4.1+cu121\n",
            "    Uninstalling torch-2.4.1+cu121:\n",
            "      Successfully uninstalled torch-2.4.1+cu121\n",
            "  Attempting uninstall: torchaudio\n",
            "    Found existing installation: torchaudio 2.4.1+cu121\n",
            "    Uninstalling torchaudio-2.4.1+cu121:\n",
            "      Successfully uninstalled torchaudio-2.4.1+cu121\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchvision 0.19.1+cu121 requires torch==2.4.1, but you have torch 2.0.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed antlr4-python3-runtime-4.9.3 demucs-4.1.0a2 dora-search-0.1.12 julius-0.2.7 lameenc-1.7.0 lit-18.1.8 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-cupti-cu11-11.7.101 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 nvidia-cufft-cu11-10.9.0.58 nvidia-curand-cu11-10.2.10.91 nvidia-cusolver-cu11-11.4.0.1 nvidia-cusparse-cu11-11.7.4.91 nvidia-nccl-cu11-2.14.3 nvidia-nvtx-cu11-11.7.91 omegaconf-2.3.0 openunmix-1.3.0 retrying-1.3.4 submitit-1.5.2 torch-2.0.1 torchaudio-2.0.2 treetable-0.2.5 triton-2.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "znCvBifRrO-b",
        "cellView": "form"
      },
      "source": [
        "#@title **Basic Configuration**\n",
        "\n",
        "# Customize the following options!\n",
        "model = \"htdemucs_ft\" #\"htdemucs_ft\n",
        "extensions = [\"mp3\", \"wav\", \"ogg\", \"flac\"]  # we will look for all those file types.\n",
        "two_stems = None   # only separate one stems from the rest, for instance\n",
        "# two_stems = \"vocals\"\n",
        "\n",
        "# Options for the output audio.\n",
        "mp3 = True\n",
        "mp3_rate = 320\n",
        "float32 = False  # output as float 32 wavs, unsused if 'mp3' is True.\n",
        "int24 = False    # output as int24 wavs, unused if 'mp3' is True.\n",
        "# You cannot set both `float32 = True` and `int24 = True` !!\n",
        "\n",
        "\n",
        "# @markdown **`in_path`**: Choose source folder, music files\n",
        "in_path = '/content/drive/MyDrive/demucs/split_parts' # @param {type:\"string\"}\n",
        "\n",
        "# @markdown **`out_path`**: Choose save folder for stems\n",
        "out_path = '/content/drive/MyDrive/demucs/other_stems' # @param {type:\"string\"}\n",
        "\n",
        "\n",
        "import io\n",
        "from pathlib import Path\n",
        "import select\n",
        "from shutil import rmtree\n",
        "import subprocess as sp\n",
        "import sys\n",
        "from typing import Dict, Tuple, Optional, IO\n",
        "\n",
        "from google.colab import files\n",
        "\n",
        "def find_files(in_path):\n",
        "    out = []\n",
        "    for file in Path(in_path).iterdir():\n",
        "        if file.suffix.lower().lstrip(\".\") in extensions:\n",
        "            out.append(file)\n",
        "    return out\n",
        "\n",
        "def copy_process_streams(process: sp.Popen):\n",
        "    def raw(stream: Optional[IO[bytes]]) -> IO[bytes]:\n",
        "        assert stream is not None\n",
        "        if isinstance(stream, io.BufferedIOBase):\n",
        "            stream = stream.raw\n",
        "        return stream\n",
        "\n",
        "    p_stdout, p_stderr = raw(process.stdout), raw(process.stderr)\n",
        "    stream_by_fd: Dict[int, Tuple[IO[bytes], io.StringIO, IO[str]]] = {\n",
        "        p_stdout.fileno(): (p_stdout, sys.stdout),\n",
        "        p_stderr.fileno(): (p_stderr, sys.stderr),\n",
        "    }\n",
        "    fds = list(stream_by_fd.keys())\n",
        "\n",
        "    while fds:\n",
        "        # `select` syscall will wait until one of the file descriptors has content.\n",
        "        ready, _, _ = select.select(fds, [], [])\n",
        "        for fd in ready:\n",
        "            p_stream, std = stream_by_fd[fd]\n",
        "            raw_buf = p_stream.read(2 ** 16)\n",
        "            if not raw_buf:\n",
        "                fds.remove(fd)\n",
        "                continue\n",
        "            buf = raw_buf.decode()\n",
        "            std.write(buf)\n",
        "            std.flush()\n",
        "\n",
        "def separate(inp=None, outp=None):\n",
        "    inp = inp or in_path\n",
        "    outp = outp or out_path\n",
        "    cmd = [\"python3\", \"-m\", \"demucs.separate\", \"-o\", str(outp), \"-n\", model]\n",
        "    if mp3:\n",
        "        cmd += [\"--mp3\", f\"--mp3-bitrate={mp3_rate}\"]\n",
        "    if float32:\n",
        "        cmd += [\"--float32\"]\n",
        "    if int24:\n",
        "        cmd += [\"--int24\"]\n",
        "    if two_stems is not None:\n",
        "        cmd += [f\"--two-stems={two_stems}\"]\n",
        "    files = [str(f) for f in find_files(inp)]\n",
        "    if not files:\n",
        "        print(f\"No valid audio files in {in_path}\")\n",
        "        return\n",
        "    print(\"Going to separate the files:\")\n",
        "    print('\\n'.join(files))\n",
        "    print(\"With command: \", \" \".join(cmd))\n",
        "    p = sp.Popen(cmd + files, stdout=sp.PIPE, stderr=sp.PIPE)\n",
        "    copy_process_streams(p)\n",
        "    p.wait()\n",
        "    if p.returncode != 0:\n",
        "        print(\"Command failed, something went wrong.\")\n",
        "\n",
        "\n",
        "def from_upload():\n",
        "    out_path = Path('separated')\n",
        "    in_path = Path('tmp_in')\n",
        "\n",
        "    if in_path.exists():\n",
        "        rmtree(in_path)\n",
        "    in_path.mkdir()\n",
        "\n",
        "    if out_path.exists():\n",
        "        rmtree(out_path)\n",
        "    out_path.mkdir()\n",
        "\n",
        "    uploaded = files.upload()\n",
        "    for name, content in uploaded.items():\n",
        "        (in_path / name).write_bytes(content)\n",
        "    separate(in_path, out_path)\n"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gr9OJvf-tYyt",
        "cellView": "form",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6bdce879-cb8a-4e17-805b-c8f0dd61a35a"
      },
      "source": [
        "#@title Process **in_path** folder.\n",
        "#@markdown For large files 10+ minutes, consider splitting into smaller chunks if colab crashes. Larger files require more Vram,\n",
        "\n",
        "#@markdown **execute seperate()**\n",
        "\n",
        "# This can be quite slow, in particular the loading, and saving from GDrive. Please be patient!\n",
        "# This is from google drive! Also, this will separate all the files inside the MyDrive/demucs folder,\n",
        "# so when you are happy with the results, remove the songs from there.\n",
        "separate()"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Going to separate the files:\n",
            "/content/drive/MyDrive/demucs/split_parts/part_8.mp3\n",
            "/content/drive/MyDrive/demucs/split_parts/part_4.mp3\n",
            "/content/drive/MyDrive/demucs/split_parts/part_3.mp3\n",
            "/content/drive/MyDrive/demucs/split_parts/part_2.mp3\n",
            "/content/drive/MyDrive/demucs/split_parts/part_6.mp3\n",
            "/content/drive/MyDrive/demucs/split_parts/part_5.mp3\n",
            "/content/drive/MyDrive/demucs/split_parts/part_7.mp3\n",
            "/content/drive/MyDrive/demucs/split_parts/part_1.mp3\n",
            "With command:  python3 -m demucs.separate -o /content/drive/MyDrive/demucs/other_stems/ -n htdemucs_ft --mp3 --mp3-bitrate=320\n",
            "Selected model is a bag of 4 models. You will see that many progress bars per track.\n",
            "Separated tracks will be stored in /content/drive/MyDrive/demucs/other_stems/htdemucs_ft\n",
            "Separating track /content/drive/MyDrive/demucs/split_parts/part_8.mp3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████████████████████████████████████████████████████████████████| 333.45/333.45 [00:19<00:00, 17.28seconds/s]\n",
            "100%|██████████████████████████████████████████████████████████████████████| 333.45/333.45 [00:12<00:00, 25.95seconds/s]\n",
            "100%|██████████████████████████████████████████████████████████████████████| 333.45/333.45 [00:13<00:00, 25.45seconds/s]\n",
            "100%|██████████████████████████████████████████████████████████████████████| 333.45/333.45 [00:13<00:00, 25.45seconds/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Separating track /content/drive/MyDrive/demucs/split_parts/part_4.mp3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████████████████████████████████████████████████████████████████| 333.45/333.45 [00:13<00:00, 24.43seconds/s]\n",
            "100%|██████████████████████████████████████████████████████████████████████| 333.45/333.45 [00:13<00:00, 24.43seconds/s]\n",
            "100%|██████████████████████████████████████████████████████████████████████| 333.45/333.45 [00:13<00:00, 24.80seconds/s]\n",
            "100%|██████████████████████████████████████████████████████████████████████| 333.45/333.45 [00:13<00:00, 24.37seconds/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Separating track /content/drive/MyDrive/demucs/split_parts/part_3.mp3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████████████████████████████████████████████████████████████████| 333.45/333.45 [00:13<00:00, 24.62seconds/s]\n",
            "100%|██████████████████████████████████████████████████████████████████████| 333.45/333.45 [00:13<00:00, 24.09seconds/s]\n",
            "100%|██████████████████████████████████████████████████████████████████████| 333.45/333.45 [00:13<00:00, 24.18seconds/s]\n",
            "100%|██████████████████████████████████████████████████████████████████████| 333.45/333.45 [00:13<00:00, 24.39seconds/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Separating track /content/drive/MyDrive/demucs/split_parts/part_2.mp3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████████████████████████████████████████████████████████████████| 333.45/333.45 [00:13<00:00, 24.90seconds/s]\n",
            "100%|██████████████████████████████████████████████████████████████████████| 333.45/333.45 [00:13<00:00, 24.77seconds/s]\n",
            "100%|██████████████████████████████████████████████████████████████████████| 333.45/333.45 [00:14<00:00, 23.79seconds/s]\n",
            "100%|██████████████████████████████████████████████████████████████████████| 333.45/333.45 [00:13<00:00, 24.41seconds/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Separating track /content/drive/MyDrive/demucs/split_parts/part_6.mp3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████████████████████████████████████████████████████████████████| 333.45/333.45 [00:13<00:00, 24.83seconds/s]\n",
            "100%|██████████████████████████████████████████████████████████████████████| 333.45/333.45 [00:13<00:00, 24.67seconds/s]\n",
            "100%|██████████████████████████████████████████████████████████████████████| 333.45/333.45 [00:13<00:00, 24.47seconds/s]\n",
            "100%|██████████████████████████████████████████████████████████████████████| 333.45/333.45 [00:13<00:00, 24.49seconds/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Separating track /content/drive/MyDrive/demucs/split_parts/part_5.mp3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████████████████████████████████████████████████████████████████| 333.45/333.45 [00:13<00:00, 24.82seconds/s]\n",
            "100%|██████████████████████████████████████████████████████████████████████| 333.45/333.45 [00:13<00:00, 24.64seconds/s]\n",
            "100%|██████████████████████████████████████████████████████████████████████| 333.45/333.45 [00:13<00:00, 24.36seconds/s]\n",
            "100%|██████████████████████████████████████████████████████████████████████| 333.45/333.45 [00:13<00:00, 24.40seconds/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Separating track /content/drive/MyDrive/demucs/split_parts/part_7.mp3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████████████████████████████████████████████████████████████████| 333.45/333.45 [00:13<00:00, 24.71seconds/s]\n",
            "100%|██████████████████████████████████████████████████████████████████████| 333.45/333.45 [00:13<00:00, 24.26seconds/s]\n",
            "100%|██████████████████████████████████████████████████████████████████████| 333.45/333.45 [00:13<00:00, 24.14seconds/s]\n",
            "100%|██████████████████████████████████████████████████████████████████████| 333.45/333.45 [00:13<00:00, 24.52seconds/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Separating track /content/drive/MyDrive/demucs/split_parts/part_1.mp3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████████████████████████████████████████████████████████████████| 333.45/333.45 [00:13<00:00, 24.81seconds/s]\n",
            "100%|██████████████████████████████████████████████████████████████████████| 333.45/333.45 [00:13<00:00, 24.48seconds/s]\n",
            "100%|██████████████████████████████████████████████████████████████████████| 333.45/333.45 [00:13<00:00, 24.40seconds/s]\n",
            "100%|██████████████████████████████████████████████████████████████████████| 333.45/333.45 [00:13<00:00, 24.44seconds/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v__3gMJawTD0"
      },
      "source": [
        "# This is manual upload and download :)\n",
        "from_upload()\n",
        "!zip -r separated.zip separated\n",
        "files.download('./separated.zip')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# open-ai whisper"
      ],
      "metadata": {
        "id": "_YeFIpn0XpuL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title install whisper library by openai\n",
        "!pip install -U openai-whisper\n",
        "#!pip install git+https://github.com/openai/whisper.git\n"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rjU-Dx2tXo-d",
        "outputId": "5e4d3605-cbb7-454e-d0b9-a18cc2a01efa"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai-whisper\n",
            "  Downloading openai-whisper-20240930.tar.gz (800 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/800.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m153.6/800.5 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m798.7/800.5 kB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m800.5/800.5 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (0.60.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (1.26.4)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (2.0.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (4.66.5)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (10.5.0)\n",
            "Collecting tiktoken (from openai-whisper)\n",
            "  Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: triton>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton>=2.0.0->openai-whisper) (3.30.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from triton>=2.0.0->openai-whisper) (3.16.1)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton>=2.0.0->openai-whisper) (18.1.8)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->openai-whisper) (0.43.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper) (2024.9.11)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (3.1.4)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (11.7.101)\n",
            "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (8.5.0.96)\n",
            "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (11.10.3.66)\n",
            "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (10.9.0.58)\n",
            "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (10.2.10.91)\n",
            "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (11.4.0.1)\n",
            "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (11.7.4.91)\n",
            "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (2.14.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (11.7.91)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch->openai-whisper) (71.0.4)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch->openai-whisper) (0.44.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2024.8.30)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->openai-whisper) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->openai-whisper) (1.3.0)\n",
            "Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m39.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: openai-whisper\n",
            "  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openai-whisper: filename=openai_whisper-20240930-py3-none-any.whl size=803321 sha256=076f25e0efa2b34fe02a0a3ac32eada3c2e020af07f73db4cf30d07c26d159e6\n",
            "  Stored in directory: /root/.cache/pip/wheels/dd/4a/1f/d1c4bf3b9133c8168fe617ed979cab7b14fe381d059ffb9d83\n",
            "Successfully built openai-whisper\n",
            "Installing collected packages: tiktoken, openai-whisper\n",
            "Successfully installed openai-whisper-20240930 tiktoken-0.7.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Quick explernation\n",
        "# Syntax:\n",
        "# !whisper [audio_file_paths...] --model [model_name]\n",
        "\n",
        "# Required VRAM in parentheses\n",
        "# models english only: medium.en, small.en\n",
        "# models: small (2gb), medium (5gb), large (10gb)\n",
        "\n",
        "# speed: 1x large, 2x medium, 4x small, 8x turbo"
      ],
      "metadata": {
        "cellView": "form",
        "id": "g9U-jQuH-jW3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CD into the folder first, so that transcribed files are saved correctly\n",
        "%cd \"/content/drive/MyDrive/demucs/other_stems/htdemucs_ft/part_8/\"\n",
        "!whisper \"/content/drive/MyDrive/demucs/other_stems/htdemucs_ft/part_8/vocals.mp3\" --model medium.en"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6C_xNdeLoqDk",
        "outputId": "3d317c15-32ca-46fa-8b74-b3e49e8f9316"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[00:00.000 --> 00:08.560]  After laughter comes tears\n",
            "[00:30.000 --> 00:58.000]  I'd like to go back a few years\n",
            "[00:58.000 --> 01:10.000]  I'd like to hold back my sorrow\n",
            "[01:10.000 --> 01:20.000]  I wonder if I can hold them till tomorrow\n",
            "[01:20.000 --> 01:32.000]  After laughter comes tears\n",
            "[01:32.000 --> 01:44.000]  I'm so alive\n",
            "[01:45.000 --> 01:46.000]  I told you so\n",
            "[01:46.000 --> 01:48.000]  Niggas better act like they motherfuckin' know\n",
            "[01:48.000 --> 01:50.000]  When I get the mic up in these\n",
            "[01:50.000 --> 01:52.000]  The whole motherfuckin' joint\n",
            "[01:52.000 --> 01:54.000]  Freeze time I said stop, let her drop\n",
            "[01:54.000 --> 01:56.000]  Them niggas are like the delicious\n",
            "[01:56.000 --> 01:58.000]  That suspicious ass silent night\n",
            "[01:58.000 --> 02:00.000]  So you can save it for the featherhead chicks\n",
            "[02:00.000 --> 02:04.000]  Quick to get hit cause she don't write her own shit\n",
            "[02:04.000 --> 02:06.000]  And I ain't tryna diss nobody\n",
            "[02:06.000 --> 02:08.000]  Fuck that hot jacket\n",
            "[02:08.000 --> 02:11.000]  See I'm about to get stupid hard in the air on Jupiter\n",
            "[02:11.000 --> 02:14.000]  Callin' all cars for 16, 18, 20 bars\n",
            "[02:14.000 --> 02:16.000]  Bein' smoked like cigars, niggas\n",
            "[02:16.000 --> 02:18.000]  Cause I flip and put bitches in the trash can\n",
            "[02:18.000 --> 02:20.000]  Shit, I keep the grill\n",
            "[02:20.000 --> 02:21.000]  Motherfuckers know the deal\n",
            "[02:21.000 --> 02:22.000]  Who's that boo?\n",
            "[02:22.000 --> 02:24.000]  Put you in that baby blue\n",
            "[02:24.000 --> 02:26.000]  Yeah, lampin' on chrome\n",
            "[02:26.000 --> 02:28.000]  So nigga, duck the marquee cut\n",
            "[02:28.000 --> 02:30.000]  Hit me off and maybe you can watch the butt\n",
            "[02:30.000 --> 02:32.000]  Cars are too real as jet skis\n",
            "[02:32.000 --> 02:34.000]  Can't get realer, catchin' the tail\n",
            "[02:34.000 --> 02:36.000]  Sippin' on tequila\n",
            "[02:36.000 --> 02:38.000]  Meanwhile, Chris Styles laid in the car\n",
            "[02:38.000 --> 02:40.000]  Fuck the dog, I got the bar for you, boy\n",
            "[02:40.000 --> 02:42.480] ree\n",
            "[02:57.540 --> 03:01.240]  So nigga try to slow this shit down\n",
            "[03:01.240 --> 03:03.540]  What's it all about, like tag motherfucker\n",
            "[03:03.540 --> 03:04.860]  Your ass is out\n",
            "[03:04.860 --> 03:07.940]  Wrong rings around on your home steez\n",
            "[03:07.940 --> 03:09.940]  bitch nigga please, can't fuck with me\n",
            "[03:09.940 --> 03:14.940]  The funk knew up the trunk, past the skunk, so we can get lifted off this junk\n",
            "[03:14.940 --> 03:16.940]  Straight from the trunk, my shit is all sunk\n",
            "[03:16.940 --> 03:19.940]  Nigga can't swim, so your ass got stunk\n",
            "[03:19.940 --> 03:22.940]  Punk cause I'm focused, never say you never notice\n",
            "[03:22.940 --> 03:25.940]  If you're on corral, I'm busting out lotus\n",
            "[03:25.940 --> 03:28.940]  I got the float nigga, no need for the light bulb nigga\n",
            "[03:28.940 --> 03:31.940]  Shit get out of hand, poo poo the trigger\n",
            "[03:31.940 --> 03:34.940]  The bigger one the shot run, the one shine like sun\n",
            "[03:34.940 --> 03:37.940]  Players wanna scoop, shorty with the snakeskin ankle boot\n",
            "[03:37.940 --> 03:41.940]  But shitting this EE, the 3 EE scoop, the bitch got Lou\n",
            "[03:41.940 --> 03:47.940]  Who wanna step, we'll sit, the quest\n",
            "[04:01.940 --> 04:03.940]  Niggers know the rule, was not with Baby Blue\n",
            "[04:03.940 --> 04:06.940]  Pushin that blue cord, fuck with this and get floored\n",
            "[04:06.940 --> 04:11.740]  I got chicks that make niggas want to drink Step up in the rink and get dead, it stink\n",
            "[04:11.740 --> 04:15.260]  Cause I hate that crab and that cat backstabbing that\n",
            "[04:15.260 --> 04:18.860]  Nah, I ain't having that So I'm canceling hoes on the regular\n",
            "[04:18.860 --> 04:21.940]  Rolling on the one-two Cause I'm a soul of a boo\n",
            "[04:21.940 --> 04:25.020]  Mackin' one deep in the jig Niggas giving me a beat\n",
            "[04:25.020 --> 04:28.860]  And no I don't speak So now balling me a bitch don't mean nothin'\n",
            "[04:28.860 --> 04:31.740]  Anyway, nigga, I'ma shine even on a cloudy day\n",
            "[04:31.740 --> 04:35.800]  Like the Mo' Mo's keepin' it real For all of those grumpy hoes creeping with\n",
            "[04:35.800 --> 04:39.320]  John Doe All y'all chickens claiming y'all cuttin'\n",
            "[04:39.320 --> 04:42.920]  Never let another nigga of a dingy man roll a dog in your puttin'\n",
            "[04:42.920 --> 04:46.760]  Spots to get black, cold, coolin' in the poof with the fuckin' top drop\n",
            "[04:46.760 --> 04:48.760]  Who wants nappas in the crash?\n",
            "[04:48.760 --> 04:51.760]  Mr. Buckneck and Mr. Rich, they're a sick\n",
            "[04:51.760 --> 04:53.760]  Who wants nappas in the crash?\n",
            "[04:53.760 --> 04:56.760]  Mr. Buckneck and Mr. Rich, they're a sick\n",
            "[04:56.760 --> 04:58.760]  Who wants nappas in the crash?\n",
            "[04:58.760 --> 05:01.760]  Mr. Buckneck and Mr. Rich, they're a sick\n",
            "[05:01.760 --> 05:03.760]  Who wants nappas in the crash?\n",
            "[05:03.760 --> 05:06.720]  Mr. Buckneck and Mr. Rich, they're a sick\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!whisper \"/content/drive/MyDrive/demucs/other_stems/htdemucs_ft/part_7/vocals.mp3\" --model medium.en\n",
        "!whisper \"/content/drive/MyDrive/demucs/other_stems/htdemucs_ft/part_6/vocals.mp3\" --model medium.en\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bfvijJUTpnLj",
        "outputId": "21cc7f9e-4b4c-4230-8839-b6fcc7c254f3"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[00:00.000 --> 00:02.000]  .\n",
            "[00:30.000 --> 00:32.000]  .\n",
            "[01:00.000 --> 01:02.000]  .\n",
            "[01:30.000 --> 01:32.000]  .\n",
            "[02:00.000 --> 02:02.000]  .\n",
            "[02:30.000 --> 02:32.000]  .\n",
            "[03:00.000 --> 03:02.000]  .\n",
            "[03:30.000 --> 03:32.000]  .\n",
            "[04:00.000 --> 04:02.000]  .\n",
            "[04:30.000 --> 04:32.000]  .\n",
            "[05:00.000 --> 05:02.000]  .\n",
            "[05:30.000 --> 05:32.000]  .\n",
            "[00:00.000 --> 00:08.000]  So far, so far, everybody so far, so far, so far, everybody so far, so far, so far, everybody so far, so far.\n",
            "[00:08.000 --> 00:14.400]  A, B, C, D, P, O, T, L, S, D, and L, F, E, R, M, E, D, M, T, N, S, D, P,\n",
            "[00:14.400 --> 00:23.000]  H, V, I, N, C, O, P, N, L, S, D, N, C, O, P, O, T, N, A, B, C, N, L, N, D,\n",
            "[00:23.000 --> 00:36.000]  help us down there. Help us down there. Help us down.\n",
            "[00:36.000 --> 00:48.000]  L, S, D, M, P, O, T, D, M, T, L, S, D, P, C, O, P, N, F, L, M, E,\n",
            "[00:48.000 --> 00:50.000]  here comes the cat, have a whammy.\n",
            "[00:50.000 --> 00:56.000]  So far, so far, everybody so far, so far, so far, everybody so far, so far.\n",
            "[00:56.000 --> 01:05.000]  High, high, high, high, high, high, high, high, high, high, high, high.\n",
            "[01:05.000 --> 01:11.000]  L, S, D, got a whole army, L, S, D got a whole army.\n",
            "[01:14.000 --> 01:19.000]  I'm a cop. I'm smoking pot. I'm a dope, I'm a cop. I'm a pusher.\n",
            "[01:19.000 --> 01:35.320]  getting high I want to be ahead I want to get stone\n",
            "[01:49.000 --> 02:02.000]  kumotare komuru oka no ue totsujo tosora ni podo no kua\n",
            "[02:02.000 --> 02:09.000]  ayashiki sake bionari no e akuma no usito\n",
            "[02:09.000 --> 02:23.000]  so no kishuyo ipiaye ipiaye\n",
            "[02:23.000 --> 02:35.000]  kumoma no maboroshi jibashi rumanako ikaru tsu no\n",
            "[02:35.000 --> 02:41.000]  ikarini kuru e rushi no mure\n",
            "[02:41.000 --> 02:48.000]  unarito tomo ni haku iki wa hono tomo e pe\n",
            "[02:48.000 --> 03:00.000]  kakepe yuku ipiaye ipiaye\n",
            "[03:00.000 --> 03:22.000]  kumoma no maboroshi\n",
            "[03:23.000 --> 03:34.000]  oka beni tachi shikaboi osore wa nana ki tatazume ba\n",
            "[03:34.000 --> 03:42.000]  ayashi no tishu akumoma yori hanashikaketari\n",
            "[03:42.000 --> 03:53.000]  ni ipiaye ipiaye\n",
            "[03:53.000 --> 04:00.000]  kumoma no maboroshi\n",
            "[04:00.000 --> 04:11.000]  hiroku hatenaki o zorao akuma no usio ite yuku\n",
            "[04:11.000 --> 04:19.000]  kurushimi haten tokimonaki warera wa jinokuro\n",
            "[04:19.000 --> 04:31.000]  kishu naruzo ipiaye ipiaye\n",
            "[04:31.000 --> 04:48.000]  maboroshi no usio maboroshi no kishuyo\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!whisper \"/content/drive/MyDrive/demucs/other_stems/htdemucs_ft/part_5/vocals.mp3\" --model medium.en\n",
        "!whisper \"/content/drive/MyDrive/demucs/other_stems/htdemucs_ft/part_4/vocals.mp3\" --model medium.en\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4M-tI0-9pqfV",
        "outputId": "1991496e-9636-475c-ad8f-48b5fe03b89f"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[00:00.000 --> 00:09.600]  on that thing. Maybe I'm just like my father too. Maybe I'm just like my mother.\n",
            "[00:11.200 --> 00:18.000]  She's never satisfied. He never satisfied. While I'm screaming at each other,\n",
            "[00:20.000 --> 00:24.960]  this is what it sounds like when love's crying.\n",
            "[00:30.000 --> 00:48.000]  Talking just means standing in the middle of the school.\n",
            "[00:48.000 --> 01:04.000]  This is what it sounds like when love's crying.\n",
            "[01:48.000 --> 02:00.000]  Wanna be. Wanna have fun. Girls. Wanna have fun.\n",
            "[02:18.000 --> 02:44.000]  Girls. Wanna have fun. Girls. Wanna have fun.\n",
            "[02:48.000 --> 03:00.000]  Girls.\n",
            "[03:18.000 --> 03:30.000]  Girls.\n",
            "[03:30.000 --> 03:46.000]  Wanna have fun.\n",
            "[03:46.000 --> 04:04.000]  Girls. Wanna have fun.\n",
            "[04:04.000 --> 04:24.000]  Girls. Wanna have fun. Girls. Wanna have fun.\n",
            "[04:24.000 --> 04:44.000]  Girls. Wanna have fun. Girls. Wanna have fun.\n",
            "[04:44.000 --> 05:00.000]  Girls. Wanna have fun.\n",
            "[05:00.000 --> 05:14.000]  Girls.\n",
            "[05:14.000 --> 05:32.000]  Girls.\n",
            "[00:00.000 --> 00:25.080]  Oh, I've got tears in my eyes, baby Oh, those tears are for you\n",
            "[00:25.080 --> 00:46.680]  Oh, oh, oh, oh, oh, oh, oh, oh Once I know I had to find my soul, I'll let\n",
            "[00:46.680 --> 00:54.800]  you know Once I know I had to find my soul, I'll let\n",
            "[00:54.800 --> 01:02.920]  you know Once I know I had to find my soul, I'll let\n",
            "[01:02.920 --> 01:11.000]  you know Once I know I had to find my soul, I'll let\n",
            "[01:11.000 --> 01:35.880]  you know\n",
            "[01:35.880 --> 01:59.720]  you know Once I know I had to find my soul, I'll let\n",
            "[01:59.720 --> 02:27.720]  you know Once I know I had to find my soul, I'll let\n",
            "[02:27.720 --> 02:42.760]  you know Once I know I had to find my soul, I'll let\n",
            "[02:42.760 --> 02:53.760]  you know Once I know I had to find my soul, I'll let\n",
            "[02:53.760 --> 03:21.760]  you know Once I know I had to find my soul, I'll let\n",
            "[03:21.760 --> 03:49.760]  you know Once I know I had to find my soul, I'll let\n",
            "[03:49.760 --> 04:17.760]  you know Once I know I had to find my soul, I'll let\n",
            "[04:17.760 --> 04:45.760]  you know Once I know I had to find my soul, I'll let\n",
            "[04:45.760 --> 05:13.760]  you know Once I know I had to find my soul, I'll let\n",
            "[05:13.760 --> 05:31.760]  you know Once I know I had to find my soul, I'll let\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!whisper \"/content/drive/MyDrive/demucs/other_stems/htdemucs_ft/Easy For You (Extended Vocal Version) [feat. CHARLO]/vocals.mp3\" --model medium.en\n",
        "# htdemucs_ft model\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eag-tGtBdDe5",
        "outputId": "d0b51652-4206-4a98-ff2a-e8e45af5abc0"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[00:00.000 --> 00:02.000]  .\n",
            "[00:30.000 --> 00:32.000]  .\n",
            "[01:00.000 --> 01:02.000]  .\n",
            "[01:30.000 --> 01:32.000]  .\n",
            "[02:00.000 --> 02:02.000]  .\n",
            "[02:30.000 --> 02:32.000]  .\n",
            "[03:00.000 --> 03:02.000]  .\n",
            "[03:30.000 --> 03:32.000]  .\n",
            "[04:00.000 --> 04:02.000]  .\n",
            "[04:30.000 --> 04:32.000]  Now I'm sitting here\n",
            "[04:32.000 --> 04:34.000]  Cause I don't really know\n",
            "[04:34.000 --> 04:36.000]  The big reason here\n",
            "[04:36.000 --> 04:38.000]  Are we taking care\n",
            "[04:38.000 --> 04:40.000]  Are we strangers now\n",
            "[04:40.000 --> 04:42.000]  Is it easy for you\n",
            "[04:42.000 --> 04:44.000]  To see all that now\n",
            "[04:44.000 --> 04:46.000]  Are we strangers now\n",
            "[04:46.000 --> 04:48.000]  Or we meet somehow\n",
            "[04:48.000 --> 04:50.000]  In our dreams and our hopes\n",
            "[04:50.000 --> 04:52.000]  And our feelings out\n",
            "[04:52.000 --> 04:54.000]  In our dreams and our hopes\n",
            "[04:54.000 --> 04:56.000]  And our feelings out\n",
            "[04:56.000 --> 04:58.000]  In our dreams and our hopes\n",
            "[04:58.000 --> 05:00.000]  And our feelings out\n",
            "[05:28.000 --> 05:30.000]  .\n",
            "[05:58.000 --> 06:00.000]  .\n",
            "[06:28.000 --> 06:30.000]  .\n",
            "[06:58.000 --> 07:00.000]  .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# tool: splitting large MP3 files"
      ],
      "metadata": {
        "id": "ag-RQL8om2Ak"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Install libraries\n",
        "!pip install pydub\n",
        "!apt-get install ffmpeg"
      ],
      "metadata": {
        "collapsed": true,
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MKGkqU5Ol5jj",
        "outputId": "2aa696d0-a317-4aed-e6f8-63e11c74f08a"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pydub\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Installing collected packages: pydub\n",
            "Successfully installed pydub-0.25.1\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 49 not upgraded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Functions for splitting\n",
        "from pydub import AudioSegment\n",
        "import math\n",
        "import os\n",
        "\n",
        "def split_mp3_into_parts(mp3_file_path, output_dir='split_parts', parts=4):\n",
        "    # Load the MP3 file\n",
        "    audio = AudioSegment.from_mp3(mp3_file_path)\n",
        "\n",
        "    # Calculate duration of each part\n",
        "    duration_ms = len(audio)\n",
        "    part_duration_ms = math.ceil(duration_ms / parts)\n",
        "\n",
        "    # Create output directory if it doesn't exist\n",
        "    if not os.path.exists(output_dir):\n",
        "        os.makedirs(output_dir)\n",
        "\n",
        "    # Split the audio and save parts\n",
        "    for i in range(parts):\n",
        "        start_time = i * part_duration_ms\n",
        "        end_time = min(start_time + part_duration_ms, duration_ms)\n",
        "        part_audio = audio[start_time:end_time]\n",
        "\n",
        "        # Export each part as a new MP3 file\n",
        "        part_filename = os.path.join(output_dir, f'part_{i+1}.mp3')\n",
        "        part_audio.export(part_filename, format=\"mp3\")\n",
        "        print(f'Exported {part_filename}')\n",
        "\n",
        "# Example usage, splits in 4 save in ./split_parts\n",
        "#split_mp3_into_parts('/content/drive/MyDrive/demucs/other/Sin Cognito # 1.mp3')"
      ],
      "metadata": {
        "cellView": "form",
        "id": "QOr9sRzzl81k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Split cmd\n",
        "# Syntax\n",
        "# split_mp3_into_parts( (string) file_path, (string) save_dir, (int) parts )\n",
        "\n",
        "# Example:\n",
        "# split_mp3_into_parts( 'myAudio.mp3', './splitFiles/', 3 )"
      ],
      "metadata": {
        "id": "OShsf7IB-Eri"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CPU mode for stem splitting (no GPU)\n",
        "\n",
        "[source link](https://colab.research.google.com/drive/1nLVmRk3Je_v965fsLmYtRGpLqW3Nt37M)\n"
      ],
      "metadata": {
        "id": "WaoMfI_5oNMo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Set up\n",
        "\n",
        "# @markdown **TLDR**; upload your audio files a folder named `inputs`, and hit `Ctrl + F9`.\n",
        "# @markdown\n",
        "# @markdown Once done (a matter of minutes), separated music sources will become available under `outputs`.\n",
        "\n",
        "# @markdown **`inputs_folder`**: Choose which folder to take unseparated music from. Supported files include `.mp3`, `.wav`, `.ogg` or `.flac`.\n",
        "inputs_folder = 'inputs' # @param {type:\"string\"}\n",
        "\n",
        "# @markdown **`outputs_folder`**: Choose which folder separated sources will be output to.\n",
        "outputs_folder = 'outputs' # @param {type:\"string\"}\n",
        "\n",
        "# @markdown **`karaoke_mode`**: Separate vocals from the rest of the accompaniment. This will mix the files after separating the mix fully, so this won't be faster or use less memory.\n",
        "karaoke_mode = False # @param {type:\"boolean\"}\n",
        "\n",
        "# @markdown **`output_format`**: How outputs will be saved.\n",
        "output_format = \"mp3 - 160 kbps\" # @param [\"mp3 - 160 kbps\", \"mp3 - 320 kbps\", \"wav - 16 bit\", \"wav - 24 bit\", \"wav - 32 bit (float)\"] {allow-input: true}\n",
        "\n",
        "# @markdown **`model`**: Choose which model is used for separation:\n",
        "# @markdown - `htdemucs`: first version of Hybrid Transformer Demucs. Trained on MusDB + 800 songs. Default model.\n",
        "# @markdown - `htdemucs_ft`: fine-tuned version of `htdemucs`, separation will take 4 times more time\n",
        "# @markdown     but might be a bit better. Same training set as `htdemucs`.\n",
        "# @markdown - `htdemucs_6s`: 6 sources version of `htdemucs`, with `piano` and `guitar` being added as sources.\n",
        "# @markdown     Note that the `piano` source is not working great at the moment.\n",
        "# @markdown - `hdemucs_mmi`: Hybrid Demucs v3, retrained on MusDB + 800 songs.\n",
        "# @markdown - `mdx`: trained only on MusDB HQ, winning model on track A at the [MDX][mdx] challenge.\n",
        "# @markdown - `mdx_extra`: trained with extra training data (**including MusDB test set**), ranked 2nd on the track B\n",
        "# @markdown     of the [MDX][mdx] challenge.\n",
        "# @markdown - `mdx_q`, `mdx_extra_q`: quantized version of the previous models. Smaller download and storage\n",
        "# @markdown     but quality can be slightly worse.\n",
        "# @markdown - `SIG`: where `SIG` is a single model from the [model zoo](docs/training.md#model-zoo).\n",
        "# @markdown\n",
        "# @markdown [mdx]: https://www.aicrowd.com/challenges/music-demixing-challenge-ismir-2021\n",
        "\n",
        "model = 'htdemucs_ft' # @param [\"htdemucs\", \"htdemucs_ft\", \"htdemucs_6s\", \"hdemucs_mmi\", \"mdx\", \"mdx_extra\", \"mdx_q\", \"mdx_extra_q\"] {allow-input: true}\n",
        "\n",
        "!mkdir -p {inputs_folder}"
      ],
      "metadata": {
        "cellView": "form",
        "id": "5HlWedhEoTea"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Separate music sources"
      ],
      "metadata": {
        "id": "nA3qS-bnoZ6q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Install dependenies\n",
        "\n",
        "has_gpu = !nvidia-smi > /dev/null 2>&1 && echo 1\n",
        "if has_gpu:\n",
        "  print(\"Using GPU packages\")\n",
        "  !pip install -qU git+https://github.com/adefossez/demucs#egg=demucs\n",
        "else:\n",
        "  # avoid installing dependencies to get rid of CUDA dependency\n",
        "  print(\"Using CPU packages; separation will be slow. Consider switching to a GPU-enabled runtime\")\n",
        "  !git clone https://github.com/adefossez/demucs.git\n",
        "  !pip install -q -e demucs -r demucs/requirements_minimal.txt --no-deps\n",
        "  !pip install -q treetable omegaconf submitit retrying\n",
        "  !pip install -q torch==2.0.1 torchaudio==2.0.2 --index-url https://download.pytorch.org/whl/cpu\n",
        "\n",
        "# Test that everything is in place\n",
        "!python3 -m demucs.separate --list-models"
      ],
      "metadata": {
        "cellView": "form",
        "id": "Uskqg7lmobvO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# @title Run model\n",
        "\n",
        "import re\n",
        "\n",
        "inputs = !find {inputs_folder} -name *.mp3 -o -name *.flac -o -name *.wav -o -name *.ogg || echo error\n",
        "if inputs[-1] == \"error\":\n",
        "  raise RuntimeError(f'Please make sure you have uploaded your audio files under \"{inputs_folder}\" folder')\n",
        "\n",
        "extra_flags = \"\"\n",
        "if karaoke_mode:\n",
        "  extra_flags += \" --two-stems=vocals\"\n",
        "if output_format == \"wav - 16 bit\":\n",
        "  pass\n",
        "elif output_format == \"wav - 24 bit\":\n",
        "  extra_flags += \" --int24\"\n",
        "elif output_format == \"wav - 32 bit (float)\":\n",
        "  extra_flags += \" --float32\"\n",
        "elif output_format.startswith(\"mp3\"):\n",
        "  bitrate = int(re.search('([0-9]{2,3}) kbps', output_format).group(1))\n",
        "  extra_flags += f\" --mp3 --mp3-bitrate={bitrate}\"\n",
        "\n",
        "inputs_str = \" \".join(f'\"{s}\"' for s in inputs)\n",
        "\n",
        "!python3 -m demucs.separate -o {outputs_folder} -n {model} {extra_flags} {inputs_str}"
      ],
      "metadata": {
        "cellView": "form",
        "id": "R9Xrix-TohE9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}