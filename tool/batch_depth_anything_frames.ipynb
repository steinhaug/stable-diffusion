{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/steinhaug/stable-diffusion/blob/main/tool/batch_depth_anything_frames.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "W5pwcOpck-Uf"
      },
      "outputs": [],
      "source": [
        "#@title Batch Depth-Anything frames\n",
        "#@markdown ![Visitors](https://api.visitorbadge.io/api/combined?path=https%3A%2F%2Fgithub.com%2Fsteinhaug%2Fstable-diffusion%2Fblob%2Fmain%2Fbatch_depth_anything_frames.ipynb&countColor=%23263759&style=flat)\n",
        "#@markdown <a href=\"https://github.com/steinhaug/\" target=\"_blank\"><img alt=\"Open Github profile\" src=\"https://img.shields.io/badge/Steinhaug-Profile-black?logo=github\"></a>\n",
        "\n",
        "#@markdown [![Buy me a beer](https://raw.githubusercontent.com/steinhaug/stable-diffusion/main/assets/buy-me-a-beer.png ) ](https://steinhaug.com/donate/)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kaJwZvw5jaeY"
      },
      "source": [
        "# Installer blocks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YmVzG5qQkaeI"
      },
      "source": [
        "Make sure all blocks are completed, you may need to restart after downgrading torch. If you need to restart, just continue runnig the blocks."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aIZ1aLhlPR5R"
      },
      "outputs": [],
      "source": [
        "%cd /content\n",
        "!git clone https://github.com/LiheYoung/Depth-Anything\n",
        "%cd Depth-Anything\n",
        "!pip install kaleido cohere openai tiktoken\n",
        "!pip install fastapi python-multipart uvicorn\n",
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 670
        },
        "id": "c31v7zz9a_kc",
        "outputId": "6ad839bc-f0db-47a1-afaa-af2068819df1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting torch==2.1.0\n",
            "  Downloading torch-2.1.0-cp310-cp310-manylinux1_x86_64.whl (670.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m670.2/670.2 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0) (4.9.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0) (2.18.1)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0) (12.1.105)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0) (2.1.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.1.0) (12.3.101)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.1.0) (2.1.4)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.1.0) (1.3.0)\n",
            "Installing collected packages: torch\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.1.2\n",
            "    Uninstalling torch-2.1.2:\n",
            "      Successfully uninstalled torch-2.1.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "xformers 0.0.23.post1 requires torch==2.1.2, but you have torch 2.1.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed torch-2.1.0\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "torch",
                  "torchgen"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Downgrade torch, xformers requires v2.1.0\n",
        "!pip install torch==2.1.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CjVgRC75cClA",
        "outputId": "a88d18cc-2e5e-447f-e7a7-36de0ea29ccf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Installed PyTorch version: 2.1.0+cu121\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "def check_torch_version():\n",
        "    return torch.__version__\n",
        "torch_version = check_torch_version()\n",
        "print(f\"Installed PyTorch version: {torch_version}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W7Z7Lx1gXyiG"
      },
      "outputs": [],
      "source": [
        "!pip install --pre torch\n",
        "!pip install xformers pytorch_lightning numpy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pX0P-Sdnjhzf"
      },
      "source": [
        "# Initialize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "cellView": "form",
        "id": "UJ76cwHZp1El"
      },
      "outputs": [],
      "source": [
        "#@title Mount gDrive and load Notebook functions\n",
        "from IPython.display import display, Markdown, clear_output\n",
        "from pathlib import Path\n",
        "inip = Path(\"/content/drive/MyDrive\")\n",
        "if not inip.is_dir():\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "gdrive_save_folder = \"/content/drive/MyDrive/depth_frames\"\n",
        "\n",
        "depth_anything_init = False\n",
        "\n",
        "import os, sys\n",
        "from tqdm import tqdm\n",
        "\n",
        "_B=True\n",
        "_A=False\n",
        "def return__isValidDir(directory):\n",
        "    if os.path.isdir(directory):return _B\n",
        "    else:return _A\n",
        "\n",
        "def return__fileCount(directory_path):\n",
        "    file_count = 0\n",
        "\n",
        "    for root, dirs, files in os.walk(directory_path):\n",
        "        file_count += len(files)\n",
        "\n",
        "    return file_count\n",
        "\n",
        "def resettable_progress_meter(maximum, progress):\n",
        "    bar_length = 40\n",
        "    progress_ratio = progress / maximum\n",
        "    bar = int(bar_length * progress_ratio)\n",
        "\n",
        "    sys.stdout.write(\"\\r[{}{}] {}%\".format(\"=\" * bar, \" \" * (bar_length - bar), int(progress_ratio * 100)))\n",
        "    sys.stdout.flush()\n",
        "\n",
        "    if progress == maximum:\n",
        "        sys.stdout.write(\"\\n\")\n",
        "        sys.stdout.flush()\n",
        "\n",
        "def return__folderName(directory_path, verify_folder=False):\n",
        "\n",
        "    if not verify_folder:\n",
        "        return os.path.basename(os.path.normpath(directory_path))\n",
        "\n",
        "    # Ensure the path is a valid directory\n",
        "    if os.path.isdir(directory_path):\n",
        "        # Split the path into components and get the last one\n",
        "        last_folder_name = os.path.basename(os.path.normpath(directory_path))\n",
        "        return last_folder_name\n",
        "    else:\n",
        "        return None  # Return None for invalid paths\n",
        "\n",
        "def move_file(source_file, destination_file, copyOnly=False):\n",
        "    file_size = os.path.getsize(source_file)\n",
        "\n",
        "    with open(source_file, \"rb\") as src_file, \\\n",
        "         open(destination_file, \"wb\") as dest_file, \\\n",
        "         tqdm(total=file_size, unit=\"B\", unit_scale=True, desc=\"Moving file\", ncols=80) as progress:\n",
        "\n",
        "        chunk_size = 1024 * 1024  # 1 MB\n",
        "        bytes_copied = 0\n",
        "\n",
        "        while True:\n",
        "            chunk = src_file.read(chunk_size)\n",
        "\n",
        "            if not chunk:\n",
        "                break\n",
        "\n",
        "            dest_file.write(chunk)\n",
        "            bytes_copied += len(chunk)\n",
        "            progress.update(len(chunk))\n",
        "\n",
        "    if not copyOnly:\n",
        "        os.remove(source_file)\n",
        "        print(f\"File '{source_file}' moved to '{destination_file}'.\")\n",
        "    else:\n",
        "        print(f\"File '{source_file}' copied to '{destination_file}'.\")\n",
        "\n",
        "def copy_file(source_file, destination_file):\n",
        "    return move_file(source_file, destination_file, True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "0raZq8Zsp8Kk"
      },
      "outputs": [],
      "source": [
        "video_file = \"/content/video1.mkv.mp4\"\n",
        "frames_directory = \"/content/frames/video1mkv_\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jQcrAes_qBLR"
      },
      "source": [
        "# Process video, copy ZIPs of frames and depth frames into gDrive\n",
        "\n",
        "Run all cells or do them manually"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OTt4VmpXqMGm"
      },
      "source": [
        "## 1.0 Xtract frames and crop frames"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CxqnuAvcqO7x",
        "outputId": "a1935810-07e7-4019-aee9-bdaf32f13902"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1199 frames extracted into /content/frames/video1mkv_\n"
          ]
        }
      ],
      "source": [
        "#@title . 1.1 Extract frames\n",
        "if not return__isValidDir(frames_directory):\n",
        "    os.makedirs(frames_directory)\n",
        "\n",
        "!ffmpeg -i {video_file} -vf \"scale=910:512\" {frames_directory}/c01_%04d.png\n",
        "\n",
        "total_progress = return__fileCount(frames_directory)\n",
        "clear_output();print(f'{total_progress} frames extracted into {frames_directory}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cLBhjSDeqTWJ",
        "outputId": "f5a2d3ee-820f-441e-8c72-03fdf3c1acc6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Frames cropped into 768x512\n"
          ]
        }
      ],
      "source": [
        "#@title . 1.2 Crop frames\n",
        "\n",
        "import cv2\n",
        "import os\n",
        "import sys\n",
        "\n",
        "def process_images(input_directory, output_directory, target_width=768, target_height=512):\n",
        "\n",
        "    n_progress = 1\n",
        "\n",
        "    # Create the output directory if it doesn't exist\n",
        "    if not os.path.exists(output_directory):\n",
        "        os.makedirs(output_directory)\n",
        "\n",
        "    # Get a list of all files in the input directory\n",
        "    image_files = [f for f in os.listdir(input_directory) if f.lower().endswith(('.png', '.jpg', '.jpeg', '.gif', '.bmp'))]\n",
        "\n",
        "    for image_file in image_files:\n",
        "        input_path = os.path.join(input_directory, image_file)\n",
        "        output_path = os.path.join(output_directory, image_file)\n",
        "\n",
        "        img = cv2.imread(input_path)\n",
        "        if img is None:\n",
        "            print(f\"Error: Unable to read the image at {input_path}\")\n",
        "            return\n",
        "        height, width, _ = img.shape\n",
        "        crop_x = max(0, (width - target_width) // 2)\n",
        "        crop_y = max(0, (height - target_height) // 2)\n",
        "        cropped_img = img[crop_y:crop_y + target_height, crop_x:crop_x + target_width]\n",
        "        cv2.imwrite(output_path, cropped_img)\n",
        "\n",
        "        resettable_progress_meter(total_progress, n_progress)\n",
        "        n_progress = n_progress + 1\n",
        "\n",
        "process_images(frames_directory, frames_directory)\n",
        "\n",
        "clear_output();print(f'Frames cropped into 768x512')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "868c7lZEqWVf"
      },
      "source": [
        "## 2.0 Create depth maps"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203,
          "referenced_widgets": [
            "f7d54df993924436ab4313164d817da3",
            "9c635ad8d0ce4b42ad4c179afc58a10a",
            "4799bb2fbcd743ba9c603b56b7ea766b",
            "32860f6bd1d74a5ea5cee8531657fc37",
            "54fef6a34151446390648e35e64bfd2e",
            "ff5c4166392640a7bc14628b1af95941",
            "a30067df9ead4dddb41cb25672fd70f0",
            "f43719a49b834b1698e9edb6bcf00b23",
            "7323ae667d0948629d3c45e04ffe63af",
            "d48e428f722a499ca43f507eeb85a27a",
            "4da5d15dfd1046bdada3b6abca209220",
            "91dd4cb71df8460dba4cdefac68d6996",
            "743a17ba48ab425d97f1bcc406fc9745",
            "2ff1eaf3148e4b34bcfa8dd55d76a28c",
            "e79c3cce7d5647b6ab8dd14f9c567a82",
            "316dafb3363f40a3b98da56162e77b8f",
            "9f5ecd8be56741a8a6182cb9785dd97b",
            "14e1dd6257df4d92a477cdfa86542add",
            "02219ba6e92b4c949297cc60b99dcf0b",
            "ec28caf4a2b145119a57ebe3bef73153",
            "f220ea26ae524a9a9baf969f7b77a72c",
            "0b608d85812549d5b570adf9410ef29f"
          ]
        },
        "id": "ZMuulzWl_sW0",
        "outputId": "e6c5ba3d-597a-4670-8832-7d320ff0634f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/Depth-Anything\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f7d54df993924436ab4313164d817da3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "91dd4cb71df8460dba4cdefac68d6996",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/1.34G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#@title . 2.1 Initialise Depth Anything\n",
        "%cd /content/Depth-Anything\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "from PIL import Image\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torchvision.transforms import Compose\n",
        "import tempfile\n",
        "from gradio_imageslider import ImageSlider\n",
        "\n",
        "from depth_anything.dpt import DepthAnything\n",
        "from depth_anything.util.transform import Resize, NormalizeImage, PrepareForNet\n",
        "\n",
        "if not depth_anything_init:\n",
        "    DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "    model = DepthAnything.from_pretrained('LiheYoung/depth_anything_vitl14').to(DEVICE)\n",
        "\n",
        "    transform = Compose([\n",
        "            Resize(\n",
        "                width=518,\n",
        "                height=518,\n",
        "                resize_target=False,\n",
        "                keep_aspect_ratio=True,\n",
        "                ensure_multiple_of=14,\n",
        "                resize_method='lower_bound',\n",
        "                image_interpolation_method=cv2.INTER_CUBIC,\n",
        "            ),\n",
        "            NormalizeImage(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "            PrepareForNet(),\n",
        "    ])\n",
        "\n",
        "    depth_anything_init = True\n",
        "\n",
        "\n",
        "def predict_depth(model, image):\n",
        "    return model(image)\n",
        "\n",
        "def create_depth_map(image):\n",
        "    original_image = image.copy()\n",
        "\n",
        "    h, w = image.shape[:2]\n",
        "\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) / 255.0\n",
        "    image = transform({'image': image})['image']\n",
        "    image = torch.from_numpy(image).unsqueeze(0).to(DEVICE)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        depth = predict_depth(model, image)\n",
        "\n",
        "    depth = F.interpolate(depth[None], (h, w), mode='bilinear', align_corners=False)[0, 0]\n",
        "\n",
        "    raw_depth = Image.fromarray(depth.cpu().numpy().astype('uint16'))\n",
        "    tmp = tempfile.NamedTemporaryFile(suffix='.png', delete=False)\n",
        "    raw_depth.save(tmp.name)\n",
        "\n",
        "    depth = (depth - depth.min()) / (depth.max() - depth.min()) * 255.0\n",
        "    depth = depth.cpu().numpy().astype(np.uint8)\n",
        "    colored_depth = cv2.applyColorMap(depth, cv2.COLORMAP_INFERNO)[:, :, ::-1]\n",
        "\n",
        "    return colored_depth\n",
        "    return [(original_image, colored_depth), tmp.name]\n",
        "\n",
        "# Load image as numpy.ndarray\n",
        "def load_image(image_path):\n",
        "    # Read the image using OpenCV\n",
        "    image = cv2.imread(image_path)\n",
        "\n",
        "    # Check if the image was successfully loaded\n",
        "    if image is None:\n",
        "        raise FileNotFoundError(f\"Image not found at path: {image_path}\")\n",
        "\n",
        "    # Convert the image to a NumPy array\n",
        "    image_array = np.array(image)\n",
        "\n",
        "    return image_array\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RM1mkNgbqkFb",
        "outputId": "33995ca7-492d-443b-f9db-c2291df4fab1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Depth frames completed!\n"
          ]
        }
      ],
      "source": [
        "#@title . 2.2 Process frames\n",
        "import cv2, os\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "def process_images(input_directory, output_directory):\n",
        "\n",
        "    # Create the output directory if it doesn't exist\n",
        "    if not os.path.exists(output_directory):\n",
        "        os.makedirs(output_directory, exist_ok=True)\n",
        "\n",
        "    # Get a list of all files in the input directory\n",
        "    image_files = [f for f in os.listdir(input_directory) if f.lower().endswith(('.png', '.jpg', '.jpeg', '.gif', '.bmp'))]\n",
        "\n",
        "    n_progress = 1\n",
        "    for image_file in image_files:\n",
        "        input_path = os.path.join(input_directory, image_file)\n",
        "        output_path = os.path.join(output_directory, image_file)\n",
        "\n",
        "        image_data = load_image(input_path)\n",
        "        depth_data = create_depth_map(image_data)\n",
        "        final_image = Image.fromarray(depth_data)\n",
        "        final_image.save(output_path)\n",
        "\n",
        "        resettable_progress_meter(total_progress, n_progress)\n",
        "        n_progress = n_progress + 1\n",
        "\n",
        "process_images(frames_directory, f\"{frames_directory}_depth\")\n",
        "clear_output();print('Depth frames completed!')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ajm8ofDErKT4"
      },
      "source": [
        "## 3.0 zip it up"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "onVtWz2srPI7",
        "outputId": "e2c9cdd3-2ca9-48fe-e7f0-3703cca0ca5b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Zip file 'video1mkv__frames.zip' created successfully.\n",
            "Zip file 'video1mkv__frames_depth.zip' created successfully.\n"
          ]
        }
      ],
      "source": [
        "#@title . 3.1 Create zip files of frames and frames_depth folders\n",
        "import os\n",
        "import zipfile\n",
        "\n",
        "def zip_directory(directory_path, zip_file_path):\n",
        "    with zipfile.ZipFile(zip_file_path, 'w') as zipf:\n",
        "        for root, dirs, files in os.walk(directory_path):\n",
        "            for file in files:\n",
        "                file_path = os.path.join(root, file)\n",
        "                arcname = os.path.relpath(file_path, directory_path)\n",
        "                zipf.write(file_path, arcname=arcname)\n",
        "\n",
        "batch_name = return__folderName(frames_directory)\n",
        "\n",
        "zip_directory(frames_directory, f\"/content/{batch_name}_frames.zip\")\n",
        "print(f\"Zip file '{batch_name}_frames.zip' created successfully.\")\n",
        "zip_directory(f\"{frames_directory}_depth\", f\"/content/{batch_name}_frames_depth.zip\")\n",
        "print(f\"Zip file '{batch_name}_frames_depth.zip' created successfully.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BmOlOeDRrSEQ",
        "outputId": "18d6e28e-17d3-4886-f865-78b9222c81bb"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Moving file: 100%|████████████████████████████| 528M/528M [00:02<00:00, 259MB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "File '/content/video1mkv__frames.zip' copied to '/content/drive/MyDrive/depth_frames/video1mkv__frames.zip'.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Moving file: 100%|████████████████████████████| 114M/114M [00:00<00:00, 277MB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "File '/content/video1mkv__frames_depth.zip' copied to '/content/drive/MyDrive/depth_frames/video1mkv__frames_depth.zip'.\n"
          ]
        }
      ],
      "source": [
        "#@title . 3.2 Copy zips into gDrive\n",
        "copy_file(f\"/content/{batch_name}_frames.zip\", f\"{gdrive_save_folder}/{batch_name}_frames.zip\")\n",
        "copy_file(f\"/content/{batch_name}_frames_depth.zip\", f\"{gdrive_save_folder}/{batch_name}_frames_depth.zip\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mV2uJ_hzrTz1"
      },
      "source": [
        "# Addendum"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EjNNqbaNfeQc"
      },
      "source": [
        "\n",
        "<h1>Some benchmarking</h1>\n",
        "\n",
        "Imagesize: 1100 pcs  \n",
        "\n",
        "__Cropping images__  \n",
        "PIL image: 198s  \n",
        "OpenCV: 46s  \n",
        "OpenCV is approximately 4.3 X faster  \n",
        "\n",
        "__Calculating depth images__  \n",
        "Without xFormers: 1100s  \n",
        "With xFormers: 900s  \n",
        "Installing xFormers gives a 1.2 X speedup in processing  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "v_e--DE-_1gz"
      },
      "outputs": [],
      "source": [
        "#@title code reference: Complete working Inference for calculating depth map\n",
        "\n",
        "%cd /content/Depth-Anything\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "from PIL import Image\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torchvision.transforms import Compose\n",
        "import tempfile\n",
        "from gradio_imageslider import ImageSlider\n",
        "\n",
        "from depth_anything.dpt import DepthAnything\n",
        "from depth_anything.util.transform import Resize, NormalizeImage, PrepareForNet\n",
        "\n",
        "if not depth_anything_init:\n",
        "    DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "    model = DepthAnything.from_pretrained('LiheYoung/depth_anything_vitl14').to(DEVICE)\n",
        "\n",
        "    transform = Compose([\n",
        "            Resize(\n",
        "                width=518,\n",
        "                height=518,\n",
        "                resize_target=False,\n",
        "                keep_aspect_ratio=True,\n",
        "                ensure_multiple_of=14,\n",
        "                resize_method='lower_bound',\n",
        "                image_interpolation_method=cv2.INTER_CUBIC,\n",
        "            ),\n",
        "            NormalizeImage(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "            PrepareForNet(),\n",
        "    ])\n",
        "\n",
        "    depth_anything_init = True\n",
        "\n",
        "\n",
        "def predict_depth(model, image):\n",
        "    return model(image)\n",
        "\n",
        "def create_depth_map(image):\n",
        "    original_image = image.copy()\n",
        "\n",
        "    h, w = image.shape[:2]\n",
        "\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) / 255.0\n",
        "    image = transform({'image': image})['image']\n",
        "    image = torch.from_numpy(image).unsqueeze(0).to(DEVICE)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        depth = predict_depth(model, image)\n",
        "\n",
        "    depth = F.interpolate(depth[None], (h, w), mode='bilinear', align_corners=False)[0, 0]\n",
        "\n",
        "    raw_depth = Image.fromarray(depth.cpu().numpy().astype('uint16'))\n",
        "    tmp = tempfile.NamedTemporaryFile(suffix='.png', delete=False)\n",
        "    raw_depth.save(tmp.name)\n",
        "\n",
        "    depth = (depth - depth.min()) / (depth.max() - depth.min()) * 255.0\n",
        "    depth = depth.cpu().numpy().astype(np.uint8)\n",
        "    colored_depth = cv2.applyColorMap(depth, cv2.COLORMAP_INFERNO)[:, :, ::-1]\n",
        "\n",
        "    return colored_depth\n",
        "    return [(original_image, colored_depth), tmp.name]\n",
        "\n",
        "# Load image as numpy.ndarray\n",
        "def load_image(image_path):\n",
        "    # Read the image using OpenCV\n",
        "    image = cv2.imread(image_path)\n",
        "\n",
        "    # Check if the image was successfully loaded\n",
        "    if image is None:\n",
        "        raise FileNotFoundError(f\"Image not found at path: {image_path}\")\n",
        "\n",
        "    # Convert the image to a NumPy array\n",
        "    image_array = np.array(image)\n",
        "\n",
        "    return image_array\n",
        "\n",
        "image_data = load_image(\"/content/input.png\")\n",
        "depth_data = create_depth_map(image_data)\n",
        "final_image = Image.fromarray(depth_data)\n",
        "final_image.save(f\"/content/output.png\")\n",
        "plt.imshow(depth_data)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "authorship_tag": "ABX9TyMsad/uFzrDR43L5TsSAl9K",
      "gpuType": "T4",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "02219ba6e92b4c949297cc60b99dcf0b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0b608d85812549d5b570adf9410ef29f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "14e1dd6257df4d92a477cdfa86542add": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2ff1eaf3148e4b34bcfa8dd55d76a28c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_02219ba6e92b4c949297cc60b99dcf0b",
            "max": 1341418857,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ec28caf4a2b145119a57ebe3bef73153",
            "value": 1341418857
          }
        },
        "316dafb3363f40a3b98da56162e77b8f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "32860f6bd1d74a5ea5cee8531657fc37": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d48e428f722a499ca43f507eeb85a27a",
            "placeholder": "​",
            "style": "IPY_MODEL_4da5d15dfd1046bdada3b6abca209220",
            "value": " 116/116 [00:00&lt;00:00, 7.65kB/s]"
          }
        },
        "4799bb2fbcd743ba9c603b56b7ea766b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f43719a49b834b1698e9edb6bcf00b23",
            "max": 116,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7323ae667d0948629d3c45e04ffe63af",
            "value": 116
          }
        },
        "4da5d15dfd1046bdada3b6abca209220": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "54fef6a34151446390648e35e64bfd2e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7323ae667d0948629d3c45e04ffe63af": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "743a17ba48ab425d97f1bcc406fc9745": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9f5ecd8be56741a8a6182cb9785dd97b",
            "placeholder": "​",
            "style": "IPY_MODEL_14e1dd6257df4d92a477cdfa86542add",
            "value": "pytorch_model.bin: 100%"
          }
        },
        "91dd4cb71df8460dba4cdefac68d6996": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_743a17ba48ab425d97f1bcc406fc9745",
              "IPY_MODEL_2ff1eaf3148e4b34bcfa8dd55d76a28c",
              "IPY_MODEL_e79c3cce7d5647b6ab8dd14f9c567a82"
            ],
            "layout": "IPY_MODEL_316dafb3363f40a3b98da56162e77b8f"
          }
        },
        "9c635ad8d0ce4b42ad4c179afc58a10a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ff5c4166392640a7bc14628b1af95941",
            "placeholder": "​",
            "style": "IPY_MODEL_a30067df9ead4dddb41cb25672fd70f0",
            "value": "config.json: 100%"
          }
        },
        "9f5ecd8be56741a8a6182cb9785dd97b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a30067df9ead4dddb41cb25672fd70f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d48e428f722a499ca43f507eeb85a27a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e79c3cce7d5647b6ab8dd14f9c567a82": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f220ea26ae524a9a9baf969f7b77a72c",
            "placeholder": "​",
            "style": "IPY_MODEL_0b608d85812549d5b570adf9410ef29f",
            "value": " 1.34G/1.34G [00:11&lt;00:00, 166MB/s]"
          }
        },
        "ec28caf4a2b145119a57ebe3bef73153": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f220ea26ae524a9a9baf969f7b77a72c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f43719a49b834b1698e9edb6bcf00b23": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f7d54df993924436ab4313164d817da3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9c635ad8d0ce4b42ad4c179afc58a10a",
              "IPY_MODEL_4799bb2fbcd743ba9c603b56b7ea766b",
              "IPY_MODEL_32860f6bd1d74a5ea5cee8531657fc37"
            ],
            "layout": "IPY_MODEL_54fef6a34151446390648e35e64bfd2e"
          }
        },
        "ff5c4166392640a7bc14628b1af95941": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
