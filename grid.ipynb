{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPuSxvzCQxaHRgyGhLxXRWt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/steinhaug/stable-diffusion/blob/main/grid.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "NJMlwVY9PdW9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "saved_grid_count = 1"
      ],
      "metadata": {
        "id": "fFGL1sAhQGiC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "whHAATjbO04G"
      },
      "outputs": [],
      "source": [
        "#@title 3/4 Generate a grid of preview images from the saved checkpoints\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "\n",
        "OUTPUT_DIR = \"/content/drive/MyDrive/sd_weights/skmader/\" #@param {type:\"string\"}\n",
        "SAMPLES_DIR = \"samples_4\" #@param [\"samples\", \"samples_2\", \"samples_3\", \"samples_4\"]\n",
        "MERGE_SAMPLE_FOLDERS = False #@param {type:\"boolean\"}\n",
        "\n",
        "weights_folder = OUTPUT_DIR\n",
        "\n",
        "folders = sorted([f for f in os.listdir(weights_folder) if f != \"0\"], key=lambda x: int(x))\n",
        "\n",
        "if SAMPLES_DIR != \"samples\":\n",
        "    MERGE_SAMPLE_FOLDERS = False\n",
        "row = len(folders)\n",
        "if MERGE_SAMPLE_FOLDERS:\n",
        "    row = row * 2\n",
        "col = len(os.listdir(os.path.join(weights_folder, folders[0], SAMPLES_DIR)))\n",
        "scale = 4\n",
        "fig, axes = plt.subplots(row, col, figsize=(col*scale, row*scale), gridspec_kw={'hspace': 0, 'wspace': 0})\n",
        "\n",
        "i2 = 0\n",
        "for i, folder in enumerate(folders):\n",
        "    folder_path = os.path.join(weights_folder, folder)\n",
        "    image_folder = os.path.join(folder_path, SAMPLES_DIR)\n",
        "    images = [f for f in os.listdir(image_folder)]\n",
        "    for j, image in enumerate(images):\n",
        "        if row == 1:\n",
        "            currAxes = axes[j]\n",
        "        else:\n",
        "            currAxes = axes[i2, j]\n",
        "        if i == 0:\n",
        "            currAxes.set_title(f\"Image {j}\")\n",
        "        if j == 0:\n",
        "            if MERGE_SAMPLE_FOLDERS:\n",
        "                currAxes.text(-0.1, 0.5, \"S1 \" + folder, rotation=0, va='center', ha='center', transform=currAxes.transAxes)\n",
        "            else:\n",
        "                currAxes.text(-0.1, 0.5, folder, rotation=0, va='center', ha='center', transform=currAxes.transAxes)\n",
        "        image_path = os.path.join(image_folder, image)\n",
        "        img = mpimg.imread(image_path)\n",
        "        currAxes.imshow(img, cmap='gray')\n",
        "        currAxes.axis('off')\n",
        "\n",
        "    if MERGE_SAMPLE_FOLDERS:\n",
        "        i2 += 1\n",
        "        image_folder = os.path.join(folder_path, \"samples_2\")\n",
        "        images = [f for f in os.listdir(image_folder)]\n",
        "        for j, image in enumerate(images):\n",
        "            currAxes = axes[i2, j]\n",
        "            if j == 0:\n",
        "                currAxes.text(-0.1, 0.5, \"S2 \" + folder, rotation=0, va='center', ha='center', transform=currAxes.transAxes)\n",
        "            image_path = os.path.join(image_folder, image)\n",
        "            img = mpimg.imread(image_path)\n",
        "            currAxes.imshow(img, cmap='gray')\n",
        "            currAxes.axis('off')\n",
        "    i2 += 1\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(f'{saved_grid_count:04d}' + \"_\" + SAMPLES_DIR + '_grid.png', dpi=72)\n",
        "saved_grid_count += 1"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content\n",
        "!git clone https://huggingface.co/4bit/WizardLM-13B-Uncensored-4bit-128g\n"
      ],
      "metadata": {
        "id": "pEAABPLmAEtJ",
        "outputId": "571e27b8-815e-4937-b708-d129201a449f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Cloning into 'WizardLM-13B-Uncensored-4bit-128g'...\n",
            "remote: Enumerating objects: 16, done.\u001b[K\n",
            "remote: Counting objects: 100% (16/16), done.\u001b[K\n",
            "remote: Compressing objects: 100% (14/14), done.\u001b[K\n",
            "remote: Total 16 (delta 0), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (16/16), 478.81 KiB | 1.84 MiB/s, done.\n",
            "Encountered 1 file(s) that may not have been copied correctly on Windows:\n",
            "\t4bit-128g.safetensors\n",
            "\n",
            "See: `git lfs help smudge` for more details.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# UPLOAD PARTS"
      ],
      "metadata": {
        "id": "jKsK6xAKfVZF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Install dep.\n",
        "!pip install --upgrade huggingface_hub\n",
        "def bar(prg):\n",
        "    br=\"\u001b[1;33mProgress.... : \" '\u001b[0m|'+'█' * prg + ' ' * (25-prg)+'| ' +str(prg*4)+ \"%\"\n",
        "    return br\n",
        "#print(\"\u001b[1;32mLogging into huggingface...\")\n",
        "#print(bar(25))"
      ],
      "metadata": {
        "cellView": "form",
        "id": "nfz7fpublBXp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 1/2 Establish the connection for huggingface.co \n",
        "\n",
        "from slugify import slugify\n",
        "import shutil, time, os\n",
        "from google.colab import files\n",
        "from huggingface_hub import HfApi, HfFolder, CommitOperationAdd, create_repo\n",
        "from IPython.display import display_markdown, clear_output\n",
        "from IPython.utils import capture\n",
        "\n",
        "UPLOAD_DIR = \"/content/temp\"\n",
        "os.makedirs(UPLOAD_DIR, exist_ok=True)\n",
        "\n",
        "hf_token = \"\" #@param {type:\"string\"}\n",
        "#@markdown . . _Read/ write token for your Huggingface account_\n",
        "Create_repo = False #@param {type:\"boolean\"}\n",
        "#@markdown . . _Check for initializing a new repo, uncheck for upadting existsing repo_\n",
        "hf_repo_name = \"models-bck\" #@param {type:\"string\"}\n",
        "#@markdown . . _Name of repo_\n",
        "\n",
        "hf_repo_name=hf_repo_name.replace(\" \",\"-\")  \n",
        "\n",
        "api = HfApi()\n",
        "your_username = api.whoami(token=hf_token)[\"name\"]\n",
        "repo_id = f\"{your_username}/{slugify(hf_repo_name)}\"\n",
        "\n",
        "readme_text = f'''---\n",
        "license: mit\n",
        "---\n",
        "### Hello world\n",
        "'''\n",
        "\n",
        "if Create_repo:\n",
        "  create_repo(repo_id,private=True, token=hf_token)\n",
        "\n",
        "  readme_file = open(\"README.md\", \"w\")\n",
        "  readme_file.write(readme_text)\n",
        "  readme_file.close()\n",
        "  operations = [\n",
        "    CommitOperationAdd(path_in_repo=\"README.md\", path_or_fileobj=\"README.md\")\n",
        "  ]\n",
        "  api.create_commit(\n",
        "    repo_id=repo_id,\n",
        "    operations=operations,\n",
        "    commit_message=f\"Init repo\",\n",
        "    token=hf_token_write\n",
        "  )\n",
        "\n",
        "clear_output()\n",
        "\n",
        "display_markdown(f'''### Connection ready... [repo link](https://huggingface.co/{repo_id})\n",
        "''', raw=True)\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "fl1A4zv-f97M",
        "outputId": "90093c2c-5824-42df-81e2-e698af28b86d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 58
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/markdown": "### Connection ready... [repo link](https://huggingface.co/steinhaug/models-bck)\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title functions\n",
        "from slugify import slugify; from huggingface_hub import HfApi, HfFolder, CommitOperationAdd; from IPython.display import display_markdown, clear_output; from IPython.utils import capture; from google.colab import files; import shutil, time, os\n",
        "operations = [\n",
        "  CommitOperationAdd(path_in_repo=\"added_tokens.json\",path_or_fileobj=\"/content/vKUFUzrUTxZmKaL/added_tokens.json\"),\n",
        "  CommitOperationAdd(path_in_repo=\"config.json\",path_or_fileobj=\"/content/vKUFUzrUTxZmKaL/config.json\"),\n",
        "  CommitOperationAdd(path_in_repo=\"pytorch_model.bin.index.json\",path_or_fileobj=\"/content/vKUFUzrUTxZmKaL/pytorch_model.bin.index.json\"),\n",
        "  CommitOperationAdd(path_in_repo=\"special_tokens_map.json\",path_or_fileobj=\"/content/vKUFUzrUTxZmKaL/special_tokens_map.json\"),\n",
        "  CommitOperationAdd(path_in_repo=\"tokenizer.json\",path_or_fileobj=\"/content/vKUFUzrUTxZmKaL/tokenizer.json\"),\n",
        "  CommitOperationAdd(path_in_repo=\"tokenizer_config.json\",path_or_fileobj=\"/content/vKUFUzrUTxZmKaL/tokenizer_config.json\"),\n",
        "  CommitOperationAdd(path_in_repo=\"vocab.json\",path_or_fileobj=\"/content/vKUFUzrUTxZmKaL/vocab.json\"),\n",
        "  CommitOperationAdd(path_in_repo=\"merges.txt\",path_or_fileobj=\"/content/vKUFUzrUTxZmKaL/merges.txt\")\n",
        "]\n",
        "api.create_commit(\n",
        "  repo_id=repo_id,\n",
        "  operations=operations,\n",
        "  commit_message=f\"Adding files\",\n",
        "  token=hf_token\n",
        ")\n",
        "\n",
        "api.upload_folder(\n",
        "  folder_path = '/content/..path../feature_extractor',\n",
        "  path_in_repo=\"feature_extractor\",\n",
        "  repo_id=repo_id, token=hf_token\n",
        ")\n",
        "clear_output(); print('\u001b[1;32mDone! ✓')\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "Rn5TSnR3g3BC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 1/2 Upload the large files, delete them when done\n",
        "from slugify import slugify; from huggingface_hub import HfApi, HfFolder, CommitOperationAdd; from IPython.display import display_markdown, clear_output; from IPython.utils import capture; from google.colab import files; import shutil, time, os\n",
        "operations = [\n",
        "  CommitOperationAdd(path_in_repo=\"WizardLM-13B-Uncensored-4bit-128g/4bit-128g.safetensors\",path_or_fileobj=\"/content/WizardLM-13B-Uncensored-4bit-128g/4bit-128g.safetensors\"),\n",
        "]\n",
        "api.create_commit(\n",
        "  repo_id=repo_id,\n",
        "  operations=operations,\n",
        "  commit_message=f\"Adding WizardLM 13B\",\n",
        "  token=hf_token\n",
        ")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "L2527qDnAqmg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 2/2 Upload rest of files.\n",
        "from slugify import slugify; from huggingface_hub import HfApi, HfFolder, CommitOperationAdd; from IPython.display import display_markdown, clear_output; from IPython.utils import capture; from google.colab import files; import shutil, time, os\n",
        "api.upload_folder(\n",
        "  folder_path = '/content/WizardLM-13B-Uncensored-4bit-128g',\n",
        "  path_in_repo=\"WizardLM-13B-Uncensored-4bit-128g\",\n",
        "  repo_id=repo_id, token=hf_token\n",
        ")\n",
        "clear_output(); print('\u001b[1;32mDone! ✓')\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "zjr0dB1PCTRi"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}