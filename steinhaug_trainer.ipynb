{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/steinhaug/stable-diffusion/blob/main/steinhaug_trainer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Before you start:  \n",
        "Start by saving a copy to drive, and use the copy instead. This way you will be able to save your progress while running it. When you switch to the copy, make sure you are not running multiple sessions - under runtime select manage sessions and make sure you have killed all your sessions before you start running your saved copy.\n",
        "\n",
        "This notebook is based on the [ShivamShrirao](https://github.com/ShivamShrirao/diffusers/tree/main/examples/dreambooth) and [TheLastBen](https://colab.research.google.com/github/TheLastBen/fast-stable-diffusion/blob/main/fast-DreamBooth.ipynb) Dreambooth colab.\n",
        "\n",
        "NB! This requires custom editing for each run. If you are looking for a automated dreambooth check out this one, [Dreambooth Colab Edition - for people in a hurry](https://colab.research.google.com/github/steinhaug/stable-diffusion/blob/main/Dreambooth_Colab_edition_for_people_in_a_hurry.ipynb)."
      ],
      "metadata": {
        "id": "1wJYg6DovNp8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XU7NuMAA2drw",
        "outputId": "79121fac-719c-4464-f7ff-040bffc59c53"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tesla T4, 15360 MiB, 15101 MiB\n"
          ]
        }
      ],
      "source": [
        "#@markdown Check type of GPU and VRAM available.\n",
        "!nvidia-smi --query-gpu=name,memory.total,memory.free --format=csv,noheader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BzM7j0ZSc_9c"
      },
      "source": [
        "https://github.com/ShivamShrirao/diffusers/tree/main/examples/dreambooth"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wnTMyW41cC1E"
      },
      "source": [
        "## Install Requirements"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "aLWXPZqjsZVV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f22fff06-8e6a-4d79-e853-cc4dfb13a0d1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;32mDone! âœ“\n"
          ]
        }
      ],
      "source": [
        "from IPython.display import clear_output\n",
        "!wget -q https://github.com/steinhaug/diffusers/raw/main/examples/dreambooth/train_dreambooth.py\n",
        "!wget -q https://github.com/steinhaug/diffusers/raw/main/scripts/convert_original_stable_diffusion_to_diffusers.py\n",
        "!wget -q https://github.com/steinhaug/diffusers/raw/main/scripts/convert_diffusers_to_original_stable_diffusion.py\n",
        "%pip install -qq git+https://github.com/steinhaug/diffusers\n",
        "%pip install -q -U --pre triton\n",
        "%pip install -q accelerate transformers ftfy bitsandbytes==0.35.0 gradio natsort safetensors xformers\n",
        "clear_output()\n",
        "print('\u001b[1;32mDone! âœ“')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Connect and mount drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "NwjiODwM9jQ1",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "579a90fd-28f0-4afc-ca6e-1124cd58e0e4"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "y4lqqWT_uxD2",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f21eccc4-11d0-4beb-b7ff-8bfba1f51bf9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;32mDone! âœ“\n"
          ]
        }
      ],
      "source": [
        "#@title Login to HuggingFace ðŸ¤—\n",
        "\n",
        "#@markdown You need to accept the model license before downloading or using the Stable Diffusion weights. Please, visit the [model card](https://huggingface.co/runwayml/stable-diffusion-v1-5), read the license and tick the checkbox if you agree. You have to be a registered user in ðŸ¤— Hugging Face Hub, and you'll also need to use an access token for the code to work.\n",
        "# https://huggingface.co/settings/tokens\n",
        "#!mkdir -p ~/.huggingface\n",
        "#HUGGINGFACE_TOKEN = \"\" #@param {type:\"string\"}\n",
        "#!echo -n \"{HUGGINGFACE_TOKEN}\" > ~/.huggingface/token\n",
        "\n",
        "!mkdir -p ~/.cache\n",
        "!mkdir -p ~/.cache/huggingface\n",
        "HUGGINGFACE_TOKEN = \"\" #@param {type:\"string\"}\n",
        "!echo -n \"{HUGGINGFACE_TOKEN}\" > ~/.cache/huggingface/token\n",
        "clear_output(); print('\u001b[1;32mDone! âœ“')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Connect and enable huggingface api for file downloads"
      ],
      "metadata": {
        "id": "H79ZK-AFt_eN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Download files from huggingface? Run to Install HuggingFace API for file transfers \n",
        "from IPython.display import clear_output\n",
        "!pip install --upgrade huggingface_hub\n",
        "!mkdir /content/huggface_cache\n",
        "clear_output()\n",
        "from huggingface_hub import notebook_login\n",
        "notebook_login()"
      ],
      "metadata": {
        "cellView": "form",
        "id": "ez9NFdGxt8ws"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import hf_hub_download\n",
        "hf_hub_download(repo_id=\"steinhaug/zkiste\", filename=\"zkiste3-5050.ckpt\", cache_dir=\"/content/huggface_cache\")\n",
        "#hf_hub_download(repo_id=\"steinhaug/zkiste\", filename=\"zkiste2-4646.ckpt\", cache_dir=\"/content/huggface_cache\")\n",
        "#hf_hub_download(repo_id=\"steinhaug/zkiste\", filename=\"zkiste-6464.ckpt\", cache_dir=\"/content/huggface_cache\")\n"
      ],
      "metadata": {
        "id": "qlpFnyMeuh06"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G0NV324ZcL9L"
      },
      "source": [
        "## Settings and run"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Rxg0y5MBudmd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f98d3978-5fc7-46e5-cd2e-4f4d193f46dc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "[*] Weights will be saved at /content/drive/MyDrive/sd_weights/skmader\n"
          ]
        }
      ],
      "source": [
        "#@markdown If model weights should be saved directly in google drive (takes around 4-5 GB).\n",
        "save_to_gdrive = True #@param {type:\"boolean\"}\n",
        "if save_to_gdrive:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "#@markdown Name/Path of the initial model.\n",
        "MODEL_NAME = \"sd-dreambooth-library/disco-diffusion-style\" #@param [\"sd-dreambooth-library/disco-diffusion-style\", \"runwayml/stable-diffusion-v1-5\"] {allow-input: true}\n",
        "#@markdown Enter the directory name to save model at.\n",
        "OUTPUT_DIR = \"sd_weights/skmader\" #@param {type:\"string\"}\n",
        "if save_to_gdrive:\n",
        "    OUTPUT_DIR = \"/content/drive/MyDrive/\" + OUTPUT_DIR\n",
        "else:\n",
        "    OUTPUT_DIR = \"/content/\" + OUTPUT_DIR\n",
        "print(f\"[*] Weights will be saved at {OUTPUT_DIR}\")\n",
        "!mkdir -p $OUTPUT_DIR"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "IsVfXsB8vJGc"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qn5ILIyDJIcX"
      },
      "source": [
        "## Start Training"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use the table below to choose the best flags based on your memory and speed requirements. Tested on Tesla T4 GPU.\n",
        "\n",
        "\n",
        "| `fp16` | `train_batch_size` | `gradient_accumulation_steps` | `gradient_checkpointing` | `use_8bit_adam` | GB VRAM usage | Speed (it/s) |\n",
        "| ---- | ------------------ | ----------------------------- | ----------------------- | --------------- | ---------- | ------------ |\n",
        "| fp16 | 1                  | 1                             | TRUE                    | TRUE            | 9.92       | 0.93         |\n",
        "| no   | 1                  | 1                             | TRUE                    | TRUE            | 10.08      | 0.42         |\n",
        "| fp16 | 2                  | 1                             | TRUE                    | TRUE            | 10.4       | 0.66         |\n",
        "| fp16 | 1                  | 1                             | FALSE                   | TRUE            | 11.17      | 1.14         |\n",
        "| no   | 1                  | 1                             | FALSE                   | TRUE            | 11.17      | 0.49         |\n",
        "| fp16 | 1                  | 2                             | TRUE                    | TRUE            | 11.56      | 1            |\n",
        "| fp16 | 2                  | 1                             | FALSE                   | TRUE            | 13.67      | 0.82         |\n",
        "| fp16 | 1                  | 2                             | FALSE                   | TRUE            | 13.7       | 0.83          |\n",
        "| fp16 | 1                  | 1                             | TRUE                    | FALSE           | 15.79      | 0.77         |\n"
      ],
      "metadata": {
        "id": "7n-Wlswavqtv"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ioxxvHoicPs"
      },
      "source": [
        "Add `--gradient_checkpointing` flag for around 9.92 GB VRAM usage.\n",
        "\n",
        "remove `--use_8bit_adam` flag for full precision. Requires 15.79 GB with `--gradient_checkpointing` else 17.8 GB.\n",
        "\n",
        "remove `--train_text_encoder` flag to reduce memory usage further, degrades output quality."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 1/2 Download regularization images\n",
        "from zipfile import ZipFile\n",
        "!mkdir /content/data/\n",
        "%cd /content/data/\n",
        "!wget https://huggingface.co/datasets/ProGamerGov/StableDiffusion-v1-5-Regularization-Images/resolve/main/artwork_style_neg_text_v1-5_mse_vae_dpm2SaKarras50_cfg7_n4200.zip -O artwork_style_n4200.zip \n",
        "with ZipFile(\"/content/data/artwork_style_n4200.zip\", 'r') as zObject:\n",
        "    zObject.extractall(path=\"/content/data\")\n",
        "\n",
        "import os\n",
        "import shutil\n",
        "from pathlib import Path\n",
        "\n",
        "# - - -\n",
        "# Copy n files from src to dst\n",
        "# - - -\n",
        "# Example: copy_nfiles(src,dst,500)\n",
        "# Copies first 500 files from src to dst then stops.\n",
        "def copy_nfiles(src, dst, max_n):\n",
        "    path = Path(dst)\n",
        "    if not path.exists():\n",
        "        path.mkdir(parents = False, exist_ok = False)\n",
        "    n = 0;\n",
        "    for item in os.listdir(src):\n",
        "        s = os.path.join(src, item)\n",
        "        d = os.path.join(dst, item)\n",
        "        if os.path.isfile(s):\n",
        "            shutil.copy2(s, d)\n",
        "            n += 1\n",
        "        if n == max_n:\n",
        "            print(f'Copy complete, {max_n} files.')\n",
        "            break\n",
        "\n",
        "# - - -\n",
        "# Copy n files from src into dst1, dst2 and dst3.\n",
        "# - - -\n",
        "# Example: copy_nfiles_to_dst123(src,dst1,dst2,dst3, 500)\n",
        "# First 500 files from src into dst1, next 500 into dst2, next 500 into dst3 and stops.\n",
        "def copy_nfiles_to_dst123(src, dst1, dst2, dst3, xsize):\n",
        "    path = Path(dst1)\n",
        "    if not path.exists():\n",
        "        path.mkdir(parents = False, exist_ok = False)\n",
        "    path = Path(dst2)\n",
        "    if not path.exists():\n",
        "        path.mkdir(parents = False, exist_ok = False)\n",
        "    path = Path(dst3)\n",
        "    if not path.exists():\n",
        "        path.mkdir(parents = False, exist_ok = False)\n",
        "    n = 0;\n",
        "    for item in os.listdir(src):\n",
        "\n",
        "        if n >= (xsize*2):\n",
        "            dst = dst1\n",
        "        elif n >= xsize:\n",
        "            dst = dst2\n",
        "        else:\n",
        "            dst = dst3\n",
        "\n",
        "        s = os.path.join(src, item)\n",
        "        d = os.path.join(dst, item)\n",
        "        if os.path.isfile(s):\n",
        "            shutil.copy2(s, d)\n",
        "            n += 1\n",
        "        if n == (xsize*3):\n",
        "            print(f'Copy complete, 3x1000 files.')\n",
        "            break\n",
        "\n",
        "print(\"unzipped to folder: artwork_style_neg_text_v1-5_mse_vae_dpm2SaKarras50_cfg7_n4200\")\n",
        "\n",
        "from IPython.display import clear_output; clear_output(); print('\u001b[1;32mDone! âœ“')\n",
        "print(\"2000 images ready in /content/data/artwork_style\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "TC6nRz-gEYp4",
        "outputId": "001cf1bc-37d1-4224-d517-603813cc5bb3"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;32mDone! âœ“\n",
            "2000 images ready in /content/data/artwork_style\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 2/2 Preparing regularization images\n",
        "print('Preparing regularization images...');\n",
        "#copy_nfiles(\"/content/data/artwork_style_neg_text_v1-5_mse_vae_dpm2SaKarras50_cfg7_n4200\", \"/content/data/artwork_style\", 2000)\n",
        "copy_nfiles_to_dst123(\"/content/data/artwork_style_neg_text_v1-5_mse_vae_dpm2SaKarras50_cfg7_n4200\", \"/content/data/art1\", \"/content/data/art2\", \"/content/data/art3\", 1000)\n",
        "print('\u001b[1;32mRegularization images ready! âœ“')\n",
        "print('3x1000 completed. /content/data/art1 /content/data/art2 /content/data/art3');\n"
      ],
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6B6Dqy5RpFd1",
        "outputId": "2352274f-b8e4-4f63-d4f9-2c569d5c44fb"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Copy complete, 3x1000 files.\n",
            "\u001b[1;32mDone! âœ“\n",
            "3x1000 completed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Download disco diffusion style model\n",
        "if MODEL_NAME == \"sd-dreambooth-library/disco-diffusion-style\":\n",
        "    %cd /content/\n",
        "    !git lfs install\n",
        "    !git clone https://huggingface.co/sd-dreambooth-library/disco-diffusion-style\n",
        "    MODEL_NAME = \"/content/disco-diffusion-style\"\n",
        "    from IPython.display import clear_output; clear_output(); print('\u001b[1;32mDone! âœ“')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "lnZa56MnIMaS",
        "outputId": "c1e22466-8847-4579-f976-230d2e67c2d7"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;32mDone! âœ“\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "5vDpCxId1aCm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f587d13-5f68-44f4-d2ed-f789880663a7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ],
      "source": [
        "%cd /content/\n",
        "concepts_list = [\n",
        "    {\n",
        "        \"instance_prompt\":      \"a painting, art by Susanne Kathlen Mader rondo\",\n",
        "        \"class_prompt\":         \"a painting\",\n",
        "        \"instance_data_dir\":    \"/content/drive/MyDrive/data/mader-rondo\",\n",
        "        \"class_data_dir\":       \"/content/data/art1\"\n",
        "    },\n",
        "    {\n",
        "        \"instance_prompt\":      \"a painting, art by Susanne Kathlen Mader series\",\n",
        "        \"class_prompt\":         \"a painting\",\n",
        "        \"instance_data_dir\":    \"/content/drive/MyDrive/data/mader-series\",\n",
        "        \"class_data_dir\":       \"/content/data/art2\"\n",
        "    },\n",
        "    {\n",
        "        \"instance_prompt\":      \"a painting, art by Susanne Kathlen Mader paper\",\n",
        "        \"class_prompt\":         \"a painting\",\n",
        "        \"instance_data_dir\":    \"/content/drive/MyDrive/data/mader-paper\",\n",
        "        \"class_data_dir\":       \"/content/data/art3\"\n",
        "    }\n",
        "]\n",
        "\n",
        "# `class_data_dir` contains regularization images\n",
        "import json\n",
        "import os\n",
        "for c in concepts_list:\n",
        "    os.makedirs(c[\"instance_data_dir\"], exist_ok=True)\n",
        "\n",
        "with open(\"concepts_list.json\", \"w\") as f:\n",
        "    json.dump(concepts_list, f, indent=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "32gYIDDR1aCp"
      },
      "outputs": [],
      "source": [
        "#@markdown Upload your images by running this cell.\n",
        "\n",
        "#@markdown OR\n",
        "\n",
        "#@markdown You can use the file manager on the left panel to upload (drag and drop) to each `instance_data_dir` (it uploads faster)\n",
        "\n",
        "import os\n",
        "from google.colab import files\n",
        "import shutil\n",
        "\n",
        "for c in concepts_list:\n",
        "    print(f\"Uploading instance images for `{c['instance_prompt']}`\")\n",
        "    uploaded = files.upload()\n",
        "    for filename in uploaded.keys():\n",
        "        dst_path = os.path.join(c['instance_data_dir'], filename)\n",
        "        shutil.move(filename, dst_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "jjcSXTp-u-Eg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d32fee8c-938b-489c-cb48-e62f6ac4742c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-02-27 02:19:13.464712: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-02-27 02:19:14.420721: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-02-27 02:19:14.420848: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-02-27 02:19:14.420874: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "WARNING:accelerate.commands.launch:The following values were not passed to `accelerate launch` and had defaults used instead:\n",
            "\t`--num_processes` was set to a value of `1`\n",
            "\t`--num_machines` was set to a value of `1`\n",
            "\t`--mixed_precision` was set to a value of `'no'`\n",
            "\t`--dynamo_backend` was set to a value of `'no'`\n",
            "To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.\n",
            "2023-02-27 02:19:18.031471: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-02-27 02:19:18.031575: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-02-27 02:19:18.031596: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "/usr/local/lib/python3.8/dist-packages/accelerate/accelerator.py:231: FutureWarning: `logging_dir` is deprecated and will be removed in version 0.18.0 of ðŸ¤— Accelerate. Use `project_dir` instead.\n",
            "  warnings.warn(\n",
            "\n",
            "===================================BUG REPORT===================================\n",
            "Welcome to bitsandbytes. For bug reports, please submit your error trace to: https://github.com/TimDettmers/bitsandbytes/issues\n",
            "For effortless bug reporting copy-paste your error into this form: https://docs.google.com/forms/d/e/1FAIpQLScPB8emS3Thkp66nvqwmjTEgxp8Y9ufuWTzFyr9kJ5AoI47dQ/viewform?usp=sf_link\n",
            "================================================================================\n",
            "/usr/local/lib/python3.8/dist-packages/bitsandbytes/cuda_setup/paths.py:105: UserWarning: /usr/lib64-nvidia did not contain libcudart.so as expected! Searching further paths...\n",
            "  warn(\n",
            "/usr/local/lib/python3.8/dist-packages/bitsandbytes/cuda_setup/paths.py:27: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('/sys/fs/cgroup/memory.events /var/colab/cgroup/jupyter-children/memory.events')}\n",
            "  warn(\n",
            "/usr/local/lib/python3.8/dist-packages/bitsandbytes/cuda_setup/paths.py:27: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('--listen_host=172.28.0.12 --target_host=172.28.0.12 --tunnel_background_save_url=https'), PosixPath('//colab.research.google.com/tun/m/cc48301118ce562b961b3c22d803539adc1e0c19/gpu-t4-s-2j6cd7kowtlhx --tunnel_background_save_delay=10s --tunnel_periodic_background_save_frequency=30m0s --enable_output_coalescing=true --output_coalescing_required=true')}\n",
            "  warn(\n",
            "/usr/local/lib/python3.8/dist-packages/bitsandbytes/cuda_setup/paths.py:27: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('/env/python')}\n",
            "  warn(\n",
            "/usr/local/lib/python3.8/dist-packages/bitsandbytes/cuda_setup/paths.py:27: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('6000,\"kernelManagerProxyHost\"'), PosixPath('[\"--ip=172.28.0.12\",\"--transport=ipc\"],\"debugAdapterMultiplexerPath\"'), PosixPath('true}'), PosixPath('\"/usr/local/bin/dap_multiplexer\",\"enableLsp\"'), PosixPath('{\"kernelManagerProxyPort\"'), PosixPath('\"172.28.0.12\",\"jupyterArgs\"')}\n",
            "  warn(\n",
            "/usr/local/lib/python3.8/dist-packages/bitsandbytes/cuda_setup/paths.py:27: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('//ipykernel.pylab.backend_inline'), PosixPath('module')}\n",
            "  warn(\n",
            "CUDA_SETUP: WARNING! libcudart.so not found in any environmental path. Searching /usr/local/cuda/lib64...\n",
            "CUDA SETUP: CUDA runtime path found: /usr/local/cuda/lib64/libcudart.so\n",
            "CUDA SETUP: Highest compute capability among GPUs detected: 7.5\n",
            "CUDA SETUP: Detected CUDA version 118\n",
            "CUDA SETUP: Loading binary /usr/local/lib/python3.8/dist-packages/bitsandbytes/libbitsandbytes_cuda118.so...\n",
            "/usr/local/lib/python3.8/dist-packages/diffusers/configuration_utils.py:195: FutureWarning: It is deprecated to pass a pretrained model name or path to `from_config`.If you were trying to load a scheduler, please use <class 'diffusers.schedulers.scheduling_ddpm.DDPMScheduler'>.from_pretrained(...) instead. Otherwise, please make sure to pass a configuration dictionary instead. This functionality will be removed in v1.0.0.\n",
            "  deprecate(\"config-passed-as-path\", \"1.0.0\", deprecation_message, standard_warn=False)\n",
            "Caching latents:  91% 2741/3000 [22:58<15:52,  3.68s/it]Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/accelerate\", line 8, in <module>\n",
            "    sys.exit(main())\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/accelerate/commands/accelerate_cli.py\", line 45, in main\n",
            "    args.func(args)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/accelerate/commands/launch.py\", line 1097, in launch_command\n",
            "    simple_launcher(args)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/accelerate/commands/launch.py\", line 552, in simple_launcher\n",
            "    raise subprocess.CalledProcessError(returncode=process.returncode, cmd=cmd)\n",
            "subprocess.CalledProcessError: Command '['/usr/bin/python3', 'train_dreambooth.py', '--pretrained_model_name_or_path=/content/disco-diffusion-style', '--pretrained_vae_name_or_path=stabilityai/sd-vae-ft-mse', '--output_dir=/content/drive/MyDrive/sd_weights/skmader', '--revision=main', '--with_prior_preservation', '--prior_loss_weight=1.0', '--seed=1337', '--resolution=512', '--train_batch_size=1', '--train_text_encoder', '--mixed_precision=no', '--use_8bit_adam', '--gradient_checkpointing', '--gradient_accumulation_steps=1', '--learning_rate=1e-6', '--lr_scheduler=constant', '--lr_warmup_steps=0', '--num_class_images=1000', '--sample_batch_size=4', '--max_train_steps=6000', '--save_interval=200', '--save_sample_prompt=a Susanne Kathlen Mader painting', '--save_sample_prompt_2=a painting, art by Susanne Kathlen Mader rondo', '--save_sample_prompt_3=a painting, art by Susanne Kathlen Mader series', '--save_sample_prompt_4=a painting, art by Susanne Kathlen Mader paper', '--concepts_list=concepts_list.json']' died with <Signals.SIGKILL: 9>.\n"
          ]
        }
      ],
      "source": [
        "!accelerate launch train_dreambooth.py \\\n",
        "  --pretrained_model_name_or_path=$MODEL_NAME \\\n",
        "  --pretrained_vae_name_or_path=\"stabilityai/sd-vae-ft-mse\" \\\n",
        "  --output_dir=$OUTPUT_DIR \\\n",
        "  --revision=\"main\" \\\n",
        "  --with_prior_preservation --prior_loss_weight=1.0 \\\n",
        "  --seed=1337 \\\n",
        "  --resolution=512 \\\n",
        "  --train_batch_size=1 \\\n",
        "  --train_text_encoder \\\n",
        "  --mixed_precision=\"no\" \\\n",
        "  --use_8bit_adam \\\n",
        "  --gradient_checkpointing \\\n",
        "  --gradient_accumulation_steps=1 \\\n",
        "  --learning_rate=1e-6 \\\n",
        "  --lr_scheduler=\"constant\" \\\n",
        "  --lr_warmup_steps=0 \\\n",
        "  --num_class_images=1000 \\\n",
        "  --sample_batch_size=4 \\\n",
        "  --max_train_steps=6000 \\\n",
        "  --save_interval=200 \\\n",
        "  --save_sample_prompt=\"a Susanne Kathlen Mader painting\" \\\n",
        "  --save_sample_prompt_2=\"a painting, art by Susanne Kathlen Mader rondo\" \\\n",
        "  --save_sample_prompt_3=\"a painting, art by Susanne Kathlen Mader series\" \\\n",
        "  --save_sample_prompt_4=\"a painting, art by Susanne Kathlen Mader paper\" \\\n",
        "  --concepts_list=\"concepts_list.json\"\n",
        "\n",
        "# Reduce the `--save_interval` to lower than `--max_train_steps` to save weights from intermediate steps.\n",
        "# `--save_sample_prompt` can be same as `--instance_prompt` to generate intermediate samples (saved along with weights in samples directory).\n",
        "\n",
        "#from google.colab import runtime\n",
        "#runtime.unassign()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Inference work with model"
      ],
      "metadata": {
        "id": "BCyzeaKdv58y"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "89Az5NUxOWdy"
      },
      "outputs": [],
      "source": [
        "#@markdown Specify the weights directory to use (leave blank for latest)\n",
        "WEIGHTS_DIR = \"/content/diff_model\" #@param {type:\"string\"}\n",
        "if WEIGHTS_DIR == \"\":\n",
        "    from natsort import natsorted\n",
        "    from glob import glob\n",
        "    import os\n",
        "    WEIGHTS_DIR = natsorted(glob(OUTPUT_DIR + os.sep + \"*\"))[-1]\n",
        "\n",
        "path = Path(WEIGHTS_DIR)\n",
        "if not path.exists():\n",
        "  raise Exception(f\"[*] WEIGHTS_DIR does not exist!\")\n",
        "else:\n",
        "  print(f\"[*] WEIGHTS_DIR={WEIGHTS_DIR}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "pSL0sDzlyPz2"
      },
      "outputs": [],
      "source": [
        "#@markdown Run to generate a grid of preview images from the last saved weights.\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "\n",
        "weights_folder = OUTPUT_DIR\n",
        "folders = sorted([f for f in os.listdir(weights_folder) if f != \"0\"], key=lambda x: int(x))\n",
        "\n",
        "row = len(folders)\n",
        "col = len(os.listdir(os.path.join(weights_folder, folders[0], \"samples\")))\n",
        "scale = 4\n",
        "fig, axes = plt.subplots(row, col, figsize=(col*scale, row*scale), gridspec_kw={'hspace': 0, 'wspace': 0})\n",
        "\n",
        "for i, folder in enumerate(folders):\n",
        "    folder_path = os.path.join(weights_folder, folder)\n",
        "    image_folder = os.path.join(folder_path, \"samples\")\n",
        "    images = [f for f in os.listdir(image_folder)]\n",
        "    for j, image in enumerate(images):\n",
        "        if row == 1:\n",
        "            currAxes = axes[j]\n",
        "        else:\n",
        "            currAxes = axes[i, j]\n",
        "        if i == 0:\n",
        "            currAxes.set_title(f\"Image {j}\")\n",
        "        if j == 0:\n",
        "            currAxes.text(-0.1, 0.5, folder, rotation=0, va='center', ha='center', transform=currAxes.transAxes)\n",
        "        image_path = os.path.join(image_folder, image)\n",
        "        img = mpimg.imread(image_path)\n",
        "        currAxes.imshow(img, cmap='gray')\n",
        "        currAxes.axis('off')\n",
        "        \n",
        "plt.tight_layout()\n",
        "plt.savefig('grid.png', dpi=72)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5V8wgU0HN-Kq"
      },
      "source": [
        "## Convert weights to ckpt to use in web UIs like AUTOMATIC1111."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dcXzsUyG1aCy"
      },
      "outputs": [],
      "source": [
        "%cd /content/\n",
        "\n",
        "#@markdown Run conversion.\n",
        "ckpt_path = WEIGHTS_DIR + \"/model.ckpt\"\n",
        "\n",
        "half_arg = \"\"\n",
        "#@markdown  Whether to convert to fp16, takes half the space (2GB).\n",
        "fp16 = True #@param {type: \"boolean\"}\n",
        "if fp16:\n",
        "    half_arg = \"--half\"\n",
        "!python convert_diffusers_to_original_stable_diffusion.py --model_path $WEIGHTS_DIR  --checkpoint_path $ckpt_path $half_arg\n",
        "print(f\"[*] Converted ckpt saved at {ckpt_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Convert ckpt > diffusion"
      ],
      "metadata": {
        "id": "l9K0WCkUwRoS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Install requirements \n",
        "from IPython.display import clear_output\n",
        "!pip install omegaconf\n",
        "clear_output()\n",
        "print('\u001b[1;32mDone! âœ“')"
      ],
      "metadata": {
        "id": "iLJCMvOs9TnO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title List devices and info device info\n",
        "from tensorflow.python.client import device_lib\n",
        "temp = device_lib.list_local_devices()\n",
        "print(temp[0])\n",
        "\n",
        "#import tensorflow as tf; print(tf.config.list_physical_devices('GPU'))\n",
        "import tensorflow as tf\n",
        "gpus = tf.config.list_physical_devices('GPU')\n",
        "for gpu in gpus:\n",
        "    print(\"Name:\", gpu.name, \"  Type:\", gpu.device_type)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "jdpgFek2BCsl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "68wzGqbjCsG4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "PATH_CKPT = \"/content/huggface_cache/models--steinhaug--zkiste/snapshots/af385428edf2f108a52b4a236ae14b4780a6d5e5/zkiste3-5050.ckpt\" #@param {type:\"string\"}\n",
        "PATH_DIFFUSERS = \"/content/diff_model\" #@param {type:\"string\"}\n",
        "\n",
        "## Display device type\n",
        "#from tensorflow.python.client import device_lib\n",
        "#temp = device_lib.list_local_devices()\n",
        "#print(temp[0])\n",
        "\n",
        "from pathlib import Path\n",
        "\n",
        "path = Path(PATH_CKPT)\n",
        "if not path.is_file():\n",
        "  raise Exception(f\"File not found! Path: {PATH_CKPT}\")\n",
        "\n",
        "path = Path(PATH_DIFFUSERS)\n",
        "if not path.exists():\n",
        "  print(f\"[*] Create directory...\")\n",
        "  path.mkdir(parents = False, exist_ok = False)\n",
        "\n",
        "%cd /content/\n",
        "!python convert_original_stable_diffusion_to_diffusers.py --scheduler_type ddim --checkpoint_path $PATH_CKPT --image_size 512 --prediction_type epsilon --dump_path $PATH_DIFFUSERS --device cpu\n",
        "\n",
        "WEIGHTS_DIR = PATH_DIFFUSERS"
      ],
      "metadata": {
        "id": "p0KvFqPFwW9g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Auto image"
      ],
      "metadata": {
        "id": "azKA8kZNhek1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gW15FjffdTID",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Initialize stable diffusion from folder \n",
        "import torch\n",
        "from torch import autocast\n",
        "from diffusers import StableDiffusionPipeline, DDIMScheduler\n",
        "from IPython.display import display\n",
        "\n",
        "model_path = WEIGHTS_DIR             # If you want to use previously trained model saved in gdrive, replace this with the full path of model in gdrive\n",
        "\n",
        "pipe = StableDiffusionPipeline.from_pretrained(model_path, safety_checker=None, torch_dtype=torch.float16).to(\"cuda\")\n",
        "pipe.scheduler = DDIMScheduler.from_config(pipe.scheduler.config)\n",
        "pipe.enable_xformers_memory_efficient_attention()\n",
        "g_cuda = None\n",
        "\n",
        "from IPython.display import clear_output; clear_output(); print('\u001b[1;32mDone! âœ“')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oIzkltjpVO_f"
      },
      "outputs": [],
      "source": [
        "#@markdown Can set random seed here for reproducibility.\n",
        "g_cuda = torch.Generator(device='cuda')\n",
        "seed = 52362 #@param {type:\"number\"}\n",
        "g_cuda.manual_seed(seed)\n",
        "saved_file_count = 1;"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "K6xoHWSsbcS3",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "#@title Run to generate image(s)\n",
        "\n",
        "prompt = \"The personification of the Halloween holiday played by (__token1__:0.95), portraited as a (__token__:0.5) with short hair and a villain's smile and a cute hat, cute cheeks, unreal engine, highly detailed, artgerm digital illustration, by Alexei Vinogradov bakery, sweets, emerald eyes\" #@param {type:\"string\"}\n",
        "negative_prompt = \"bad anatomy, extra legs, extra arms, poorly drawn face, poorly drawn hands, poorly drawn feet, fat, disfigured, out of frame, long neck, poo art, bad hands, bad art, deformed, gun, double head, flowers,asian,hyperrealistic,child\" #@param {type:\"string\"}\n",
        "token_name = \"zkistebc guy, zkistebc\" #@param {type:\"string\"}\n",
        "num_samples = 1 #@param {type:\"number\"}\n",
        "guidance_scale = 7.5 #@param {type:\"number\"}\n",
        "num_inference_steps = 20 #@param {type:\"number\"}\n",
        "width = \"512\" #@param [\"512\", \"768\", \"1280\", \"1536\"] {allow-input: true}\n",
        "height = \"1024\" #@param [\"512\", \"768\", \"1280\", \"1536\"] {allow-input: true}\n",
        "width = int(width)\n",
        "height = int(height)\n",
        "new_seed = None #@param {type:\"number\"}\n",
        "save_images_path = \"temp\" #@param {type:\"string\"}\n",
        "\n",
        "#prompt = prompt.replace(\"__token__\", token_name)\n",
        "\n",
        "x = token_name.split(\",\")\n",
        "for index, value in enumerate(x):\n",
        "    if index == 0:\n",
        "        prompt = prompt.replace(\"__token__\", value)\n",
        "    else:\n",
        "        prompt = prompt.replace(\"__token\" + str(index) + \"__\", value)\n",
        "\n",
        "#raise Exception(1);\n",
        "\n",
        "if new_seed:\n",
        "    g_cuda = torch.Generator(device='cuda')\n",
        "    g_cuda.manual_seed(new_seed)\n",
        "\n",
        "if len(save_images_path):\n",
        "    tmp = save_images_path.split(\"/\")\n",
        "    if len(tmp) == 1:\n",
        "        save_images_path = \"/content/\" + save_images_path\n",
        "    from pathlib import Path\n",
        "    path = Path(save_images_path)\n",
        "    if not path.exists():\n",
        "        print(f\"[*] Create save directory...\")\n",
        "        path.mkdir(parents = False, exist_ok = False)\n",
        "    try:\n",
        "        if not image_save_count:\n",
        "            print('Darn we need this one!')\n",
        "    except NameError:\n",
        "        image_save_count = 1\n",
        "\n",
        "print(f\"[*] Prompt used: {prompt}\")\n",
        "\n",
        "with autocast(\"cuda\"), torch.inference_mode():\n",
        "    images = pipe(\n",
        "        prompt,\n",
        "        height=height,\n",
        "        width=width,\n",
        "        negative_prompt=negative_prompt,\n",
        "        num_images_per_prompt=num_samples,\n",
        "        num_inference_steps=num_inference_steps,\n",
        "        guidance_scale=guidance_scale,\n",
        "        generator=g_cuda\n",
        "    ).images\n",
        "\n",
        "for img in images:\n",
        "    display(img)\n",
        "    if len(save_images_path):\n",
        "        precount = f'{image_save_count:04d}'\n",
        "        image_filename = precount + '_' + prompt.replace(\" \", '_')[:240] + '.png'\n",
        "        img.save(save_images_path + \"/\" + image_filename)\n",
        "        image_save_count += 1"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Run to execute batch\n",
        "import os.path\n",
        "from os import path\n",
        "from IPython.display import display\n",
        "import ast\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "\n",
        "model_trained_steps_for_filename = 'wrong1280' #@param {type:\"string\"}\n",
        "num_samples = 1 #@param {type:\"number\"}\n",
        "images_savepath = '/content/drive/MyDrive/crazy' #@param {type:\"string\"}\n",
        "models = \"('zkistebc','zkistebc guy'),('zkisteef','zkisteef guy')\" #@param {type:\"string\"}\n",
        "models_ = \"\" #@param {type:\"string\"}\n",
        "#@markdown Syntax: ('reference name', 'trained instance name')<br>\n",
        "#@markdown Overrides leave empty if not to be used\n",
        "override_width = 512 #@param {type:\"number\"}\n",
        "override_height = 1280 #@param {type:\"number\"}\n",
        "override_seed = None #@param {type:\"number\"}\n",
        "override_guidance_scale = None #@param {type:\"number\"}\n",
        "override_inference_steps = None #@param {type:\"number\"}\n",
        "\n",
        "\n",
        "kista_trainednames = ast.literal_eval('[' + models + ']')\n",
        "\n",
        "if path.exists(images_savepath) == False:\n",
        "  os.mkdir(images_savepath)\n",
        "\n",
        "auto_prompts = [\n",
        " \n",
        "  (\"warrior_poster\",\n",
        "  696969,8.0,50,\n",
        "  \"poster of __token__ , big boobs, warrior goddess| standing alone on hill| centered| detailed gorgeous face| anime style| key visual| intricate detail| highly detailed| breathtaking| vibrant| panoramic| cinematic| Carne Griffiths| Conrad Roset| Makoto Shinkai\",\n",
        "  \"blurry| fuzzy| extra fingers| disfigured| cropped| bad fingers| deformed fingers| mutated fingers| out of frame\"\n",
        "  ),\n",
        "  (\"halloween_man_1\",\n",
        "  2971107907,7.5,50,\n",
        "  \"The personification of the Halloween holiday played by (__ttoken__:0.95), portraited as a (__token__:0.5) with short hair and a villain's smile and a cute hat, cute cheeks, unreal engine, highly detailed, artgerm digital illustration, by Alexei Vinogradov bakery, sweets, emerald eyes\",\n",
        "  \"bad anatomy, extra legs, extra arms, poorly drawn face, poorly drawn hands, poorly drawn feet, fat, disfigured, out of frame, long neck, poo art, bad hands, bad art, deformed, gun, double head, flowers,asian,hyperrealistic,child\",\n",
        "  ),\n",
        "  (\"warrior\",\n",
        "  16,8.0,75,\n",
        "  \"__token__ as strong warrior princess| centered| key visual| intricate| highly detailed| breathtaking beauty| precise lineart| vibrant| comprehensive cinematic| Carne Griffiths| Conrad Roset\",\n",
        "  \"bad anatomy, extra legs, extra arms, poorly drawn face, poorly drawn hands, poorly drawn feet, fat, disfigured, out of frame, long neck, poo art, bad hands, bad art, deformed, gun, double head, flowers,asian,hyperrealistic,child\",\n",
        "  ),\n",
        "  (\"warrior_sketch\",\n",
        "  16,8.0,75,\n",
        "  \"__token__ as strong warrior king| centered| key visual| intricate| highly detailed| breathtaking beauty| precise lineart| vibrant| comprehensive cinematic| Carne Griffiths| Conrad Roset\",\n",
        "  \"\"\n",
        "  ),\n",
        "  (\"warrior_sketch\",\n",
        "  16,8.0,25,\n",
        "  \"__token__ as strong warrior princess| centered| key visual| intricate| highly detailed| breathtaking beauty| precise lineart| vibrant| comprehensive cinematic| Carne Griffiths| Conrad Roset\",\n",
        "  \"\"\n",
        "  ),\n",
        "  (\"punk_face\",\n",
        "  422313768,7.5,50,\n",
        "  \"(__ttoken__:0.25), detailed (bladerunner:1.5) portrait of Punk (__token__:1.2), (standing hair line:2), Sheen Holographic Futuristic sci-fi fashion cyberpunk, neotokyo, synthwave, (aesthetics), futuristic, art by greg rutkowski Alexandros Pyromallis Nekro Rene Margitte\",\n",
        "  \"\"\n",
        "  ),\n",
        "  (\"Glamor_look\",\n",
        "  1654522787,7.5,50,\n",
        "  \"breathtaking beauty| (__token__:1.5) with a white dress and long blond hair floating in wind magically, elf like, extreme photorealistic, 4k, sexy figure, medium shot, illustration, EF 70mm| concept art| Duy Huynh\",\n",
        "  \"no words| watermark| bad anatomy| blurry| fuzzy| extra legs| extra arms| extra fingers| poorly drawn hands| poorly drawn feet| disfigured| out of frame| tiling| bad art| deformed| mutated| double face\"\n",
        "  ),\n",
        "  (\"Cyberpunked_1\",\n",
        "  1654522787,7.5,50,\n",
        "  \"cyberpunk (__token__:1.5) in heavy raining futuristic tokyo rooftop cyberpunk night, sci-fi, __ttoken__ fantasy, intricate, very very beautiful, elegant, neon light, highly detailed, digital painting, artstation, concept art, soft light, hdri, smooth, sharp focus, illustration| art by tian zi| craig mullins| wlop| alphonse much\",\n",
        "  \"no words| watermark| bad anatomy| blurry| fuzzy| extra legs| extra arms| extra fingers| poorly drawn hands| poorly drawn feet| disfigured| out of frame| tiling| bad art| deformed| mutated| double face\"\n",
        "  ),\n",
        "  (\"Cyberpunked_2\",\n",
        "  1654522787,8.0,50,\n",
        "  \"__token__, cyberpunk, in heavy raining futuristic tokyo rooftop cyberpunk night, sci-fi, fantasy, intricate, very very beautiful, elegant, neon light, highly detailed, digital painting, artstation, concept art, soft light, hdri, smooth, sharp focus, illustration, art by tian zi and craig mullins and wlop and alphonse much\",\n",
        "  \"((missing arms)), ((missing legs)), (((extra arms))), (((extra legs))), (fused fingers), (too many fingers), (((long neck)))\"\n",
        "  ),\n",
        "  (\"Tarrot_card\",\n",
        "  2001405895,7.0,50,\n",
        "  \"__token__ squared head on tarot card with intricate detailed frame around the outside | side profile of cyberpunk body with cyborg skull | cyberpunk | styled in Art Nouveau | insanely detailed | embellishments | high definition | concept art | digital art | vibrant\",\n",
        "  \"((missing arms)), ((missing legs)), (((extra arms))), (((extra legs))), (fused fingers), (too many fingers), (((long neck)))\"\n",
        "  ),\n",
        "  (\"Tarrot_card\",\n",
        "  2001405895,7.0,50,\n",
        "  \"__token__ squared head on tarot card with intricate detailed frame around the outside | side profile of cyberpunk body with cyborg skull | cyberpunk | styled in Art Nouveau | insanely detailed | embellishments | high definition | concept art | digital art | vibrant\",\n",
        "  \"\"\n",
        "  ),\n",
        "  (\"Cyborg\",\n",
        "  558991465,8.0,50,\n",
        "  \"__token__ pixar portrait 8 k photo, beautiful shiny white rich galactic prima ballerina clowncore russian cyborg college girl, golden ratio details, sci - fi, fantasy, cyberpunk, intricate, decadent, highly detailed, digital painting, ever after high, octane render, artstation, concept art, smooth, sharp focus, illustration, art by artgerm, loish, wlop\",\n",
        "  \"lowres| worst quality| low quality| normal quality| signature| blurry| bad anatomy| bad hands| missing fingers| extra digit| fewer digits| cropped\"\n",
        "  ),\n",
        "  (\"The_hippie\",\n",
        "  2001405895,7.0,50,\n",
        "  \"full body render of an alluring god, (__token__:1.1)  as festival hippy with tribal tattoos surrounded by a underwater ink pour and flowing liquid gallium and sacred geometry, perfect body and face, sexy (__ttoken__:0.3), cinematic, beautifully lit, by miho hirano, by karol bak, by donato giancola, 3 d, trending on artstation, octane render, 8 k\",\n",
        "  \"lowres| worst quality| low quality| normal quality| signature| blurry| bad anatomy| bad hands| missing fingers| extra digit| fewer digits| cropped\"\n",
        "  ),\n",
        "  (\"Sango_dream_1\",\n",
        "  428858956,7.0,60,\n",
        "  \"__token__, sango fantasy, fantasy magic, , intricate, sharp focus, illustration, highly detailed, digital painting, concept art, matte, Artgerm and Paul lewin and kehinde wiley, masterpiece\",\n",
        "  \"no words| watermark| bad anatomy| blurry| fuzzy| extra legs| extra arms| extra fingers| poorly drawn hands| poorly drawn feet| disfigured| out of frame| tiling| bad art| deformed| mutated| double face\"\n",
        "  ),\n",
        "  (\"Sango_dream_2\",\n",
        "  4289232563,7.0,30,\n",
        "  \"__token__,  sango fantasy, fantasy magic, , intricate, sharp focus, illustration, highly detailed, digital painting, concept art, matte, Artgerm and Paul lewin and kehinde wiley, masterpiece\",\n",
        "  \"circles, bad anatomy| blurry| fuzzy| extra legs| extra arms| extra fingers| poorly drawn hands| poorly drawn feet| disfigured| out of frame| tiling| bad art| deformed| mutated| double face\"\n",
        "  ),\n",
        "\n",
        "]\n",
        "\n",
        "for prompt_ref,seed,guidance_scale,num_inference_steps,prompt,negative_prompt in auto_prompts:\n",
        "    for modelref,kista_modelname in kista_trainednames:\n",
        "        torch.cuda.empty_cache()\n",
        "        newprompt = prompt.replace(\"__token__\", kista_modelname)\n",
        "        newprompt = newprompt.replace(\"__ttoken__\", \"zkistebc\")\n",
        "\n",
        "        if override_seed:\n",
        "            seed = override_seed\n",
        "\n",
        "        g_cuda = torch.Generator(device='cuda')\n",
        "        g_cuda.manual_seed(seed)\n",
        "\n",
        "        if override_height:\n",
        "            height = override_height\n",
        "        if override_width:\n",
        "            width = override_width\n",
        "        if override_inference_steps:\n",
        "            num_inference_steps = override_inference_steps\n",
        "        if override_guidance_scale:\n",
        "            guidance_scale = override_guidance_scale\n",
        "\n",
        "        print(f\"[*] Prompt   : {newprompt}\")\n",
        "        print(f\"[*] PromptNeg: {negative_prompt}\")\n",
        "        print(f\"[*] seed:{seed},gs:{guidance_scale},steps:{num_inference_steps},{width}x{height},\")\n",
        "        with autocast(\"cuda\"), torch.inference_mode():\n",
        "            images = pipe(\n",
        "                newprompt,\n",
        "                height=height,\n",
        "                width=width,\n",
        "                negative_prompt=negative_prompt,\n",
        "                num_images_per_prompt=num_samples,\n",
        "                num_inference_steps=num_inference_steps,\n",
        "                guidance_scale=guidance_scale,\n",
        "                generator=g_cuda\n",
        "            ).images\n",
        "\n",
        "        image_filenames = []\n",
        "\n",
        "        for img in images:\n",
        "            prefix_count = '_' + f'{saved_file_count:04d}'\n",
        "            final_id = 's' + model_trained_steps_for_filename + 'g' + f'{guidance_scale:01f}' + 'i' + f'{num_inference_steps:03d}' + 's' + f'{seed}'\n",
        "            outfilename = prompt_ref + '_' + modelref + '_' + final_id.replace(\".\", '') + prefix_count\n",
        "            image_filename = outfilename.replace(\" \", '_').replace(\"00000i\", 'i') + '.png'\n",
        "            img.save(images_savepath + \"/\" + image_filename)\n",
        "            image_filenames.append(image_filename)\n",
        "            saved_file_count += 1\n",
        "            print(f\"[*] Saved: {image_filename}\")\n",
        "            #display(img.resize((256, 256)))\n",
        "            #display(img.resize((128, 128)))\n",
        "\n",
        "        image_folder = images_savepath + '/'\n",
        "        grid_row = 1\n",
        "        grid_col = len(image_filenames)\n",
        "        grid_scale = 3\n",
        "        if grid_col > 1:\n",
        "            fig, axes = plt.subplots(grid_row, grid_col, figsize=(grid_col*grid_scale, grid_row*grid_scale), gridspec_kw={'hspace': 0, 'wspace': 0})\n",
        "            for j, image_filename in enumerate(image_filenames):\n",
        "                currAxes = axes[j]\n",
        "                currAxes.set_title(f\"{image_filename[0:5]}\")\n",
        "                image_full_path = os.path.join(image_folder, image_filename)\n",
        "                imgdata = mpimg.imread(image_full_path)\n",
        "                currAxes.imshow(imgdata, cmap='gray')\n",
        "                currAxes.axis('off')\n",
        "            plt.tight_layout()\n",
        "            plt.savefig('grid.png', dpi=72)\n",
        "            plt.show()\n",
        "        else:\n",
        "            display(img.resize(( int(height / 2), int(height / 2) )))\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "8Ve9PNFzhuSq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Free up GPU-RAM\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "nlfgsKItli5H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Free up CPU-RAM\n",
        "import gc\n",
        "\n",
        "# Custom Callback To Include in Callbacks List At Training Time\n",
        "class GarbageCollectorCallback(tf.keras.callbacks.Callback):\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        gc.collect()"
      ],
      "metadata": {
        "id": "tCRREnKomZN1",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cleaning up"
      ],
      "metadata": {
        "id": "PFHw44XMhlg6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "WMCqQ5Tcdsm2"
      },
      "outputs": [],
      "source": [
        "#@markdown Run Gradio UI for generating images.\n",
        "import gradio as gr\n",
        "\n",
        "def inference(prompt, negative_prompt, num_samples, height=512, width=512, num_inference_steps=50, guidance_scale=7.5):\n",
        "    with torch.autocast(\"cuda\"), torch.inference_mode():\n",
        "        return pipe(\n",
        "                prompt, height=int(height), width=int(width),\n",
        "                negative_prompt=negative_prompt,\n",
        "                num_images_per_prompt=int(num_samples),\n",
        "                num_inference_steps=int(num_inference_steps), guidance_scale=guidance_scale,\n",
        "                generator=g_cuda\n",
        "            ).images\n",
        "\n",
        "with gr.Blocks() as demo:\n",
        "    with gr.Row():\n",
        "        with gr.Column():\n",
        "            prompt = gr.Textbox(label=\"Prompt\", value=\"photo of zwx dog in a bucket\")\n",
        "            negative_prompt = gr.Textbox(label=\"Negative Prompt\", value=\"\")\n",
        "            run = gr.Button(value=\"Generate\")\n",
        "            with gr.Row():\n",
        "                num_samples = gr.Number(label=\"Number of Samples\", value=4)\n",
        "                guidance_scale = gr.Number(label=\"Guidance Scale\", value=7.5)\n",
        "            with gr.Row():\n",
        "                height = gr.Number(label=\"Height\", value=512)\n",
        "                width = gr.Number(label=\"Width\", value=512)\n",
        "            num_inference_steps = gr.Slider(label=\"Steps\", value=24)\n",
        "        with gr.Column():\n",
        "            gallery = gr.Gallery()\n",
        "\n",
        "    run.click(inference, inputs=[prompt, negative_prompt, num_samples, height, width, num_inference_steps, guidance_scale], outputs=gallery)\n",
        "\n",
        "demo.launch(debug=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "lJoOgLQHnC8L"
      },
      "outputs": [],
      "source": [
        "#@title (Optional) Delete diffuser and old weights and only keep the ckpt to free up drive space.\n",
        "\n",
        "#@markdown [ ! ] Caution, Only execute if you are sure u want to delete the diffuser format weights and only use the ckpt.\n",
        "import shutil\n",
        "from glob import glob\n",
        "import os\n",
        "for f in glob(OUTPUT_DIR+os.sep+\"*\"):\n",
        "    if f != WEIGHTS_DIR:\n",
        "        shutil.rmtree(f)\n",
        "        print(\"Deleted\", f)\n",
        "for f in glob(WEIGHTS_DIR+\"/*\"):\n",
        "    if not f.endswith(\".ckpt\") or not f.endswith(\".json\"):\n",
        "        try:\n",
        "            shutil.rmtree(f)\n",
        "        except NotADirectoryError:\n",
        "            continue\n",
        "        print(\"Deleted\", f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jXgi8HM4c-DA"
      },
      "outputs": [],
      "source": [
        "#@title Free runtime memory\n",
        "exit()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# HF"
      ],
      "metadata": {
        "id": "B5jbpxx_eeAj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from slugify import slugify\n",
        "from huggingface_hub import HfApi, HfFolder, CommitOperationAdd\n",
        "from huggingface_hub import create_repo\n",
        "from IPython.display import display_markdown\n",
        "from IPython.display import clear_output\n",
        "from IPython.utils import capture\n",
        "from google.colab import files\n",
        "import shutil\n",
        "import time\n",
        "import os\n",
        "\n",
        "Create_repo = True #@param {type:\"boolean\"}\n",
        "hf_token_write = \"\" #@param {type:\"string\"}\n",
        "Name_of_your_concept = \"sd_helene\" #@param {type:\"string\"}\n",
        "\n",
        "Name_of_your_concept=Name_of_your_concept.replace(\" \",\"-\")  \n",
        "hf_token = hf_token_write\n",
        "\n",
        "if not len(hf_token_write):\n",
        "    hf_token = HUGGINGFACE_TOKEN\n",
        "\n",
        "\n",
        "api = HfApi()\n",
        "your_username = api.whoami(token=hf_token)[\"name\"]\n",
        "repo_id = f\"{your_username}/{slugify(Name_of_your_concept)}\"\n",
        "\n",
        "def bar(prg):\n",
        "    br=\"\u001b[1;33mUploading to HuggingFace : \" '\u001b[0m|'+'â–ˆ' * prg + ' ' * (25-prg)+'| ' +str(prg*4)+ \"%\"\n",
        "    return br\n",
        "print(\"\u001b[1;32mLoading...\")\n",
        "\n",
        "UPLOAD_DIR = \"/content/temp\"\n",
        "#MODEL_DIR = \"/content/drive/MyDrive/zkiste-models/zkiste2/4646\" #@param {type:\"string\"}\n",
        "\n",
        "os.makedirs(UPLOAD_DIR, exist_ok=True)\n",
        "\n",
        "%cd $UPLOAD_DIR\n",
        "!rm -r safety_checker feature_extractor .git\n",
        "!rm model_index.json\n",
        "!git init\n",
        "!git lfs install --system --skip-repo\n",
        "!git remote add -f origin  \"https://USER:{hf_token}@huggingface.co/runwayml/stable-diffusion-v1-5\"\n",
        "!git config core.sparsecheckout true\n",
        "!echo -e \"feature_extractor\\nsafety_checker\\nmodel_index.json\" > .git/info/sparse-checkout\n",
        "!git pull origin main\n",
        "!rm -r .git\n",
        "#%cd /content\n",
        "\n",
        "readme_text = f'''---\n",
        "license: creativeml-openrail-m\n",
        "tags:\n",
        "- text-to-image\n",
        "- stable-diffusion\n",
        "---\n",
        "### {Name_of_your_concept} \n",
        "'''\n",
        "#Save the readme to a file\n",
        "readme_file = open(\"README.md\", \"w\")\n",
        "readme_file.write(readme_text)\n",
        "readme_file.close()\n",
        "\n",
        "operations = [\n",
        "  CommitOperationAdd(path_in_repo=\"README.md\", path_or_fileobj=\"README.md\")\n",
        "]\n",
        "# CommitOperationAdd(path_in_repo=f\"{Session_Name}.ckpt\",path_or_fileobj=MDLPTH)\n",
        "\n",
        "if Create_repo:\n",
        "  create_repo(repo_id,private=True, token=hf_token)\n",
        "  api.create_commit(\n",
        "    repo_id=repo_id,\n",
        "    operations=operations,\n",
        "    commit_message=f\"Init concept {Name_of_your_concept} repo\",\n",
        "    token=hf_token\n",
        "  )\n",
        "\n",
        "clear_output()\n",
        "print(bar(25))\n",
        "\n",
        "display_markdown(f'''## Ready... [repo link](https://huggingface.co/{repo_id})\n",
        "''', raw=True)\n"
      ],
      "metadata": {
        "id": "K0BchFE5dfez"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from slugify import slugify\n",
        "from huggingface_hub import HfApi, HfFolder, CommitOperationAdd\n",
        "from huggingface_hub import create_repo\n",
        "from IPython.display import display_markdown\n",
        "from IPython.display import clear_output\n",
        "from IPython.utils import capture\n",
        "from google.colab import files\n",
        "import shutil\n",
        "import time\n",
        "import os\n",
        "\n",
        "MODEL1 = '/content/drive/MyDrive/2000/model.ckpt'\n",
        "\n",
        "operations = [\n",
        "  CommitOperationAdd(path_in_repo=\"model.ckpt\",path_or_fileobj=MODEL1)\n",
        "]\n",
        "api.create_commit(\n",
        "  repo_id=repo_id,\n",
        "  operations=operations,\n",
        "  commit_message=f\"Added sd_helene model.\",\n",
        "  token=hf_token\n",
        ")\n"
      ],
      "metadata": {
        "id": "2CEXcg80er5X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from slugify import slugify\n",
        "from huggingface_hub import HfApi, HfFolder, CommitOperationAdd\n",
        "from huggingface_hub import create_repo\n",
        "from IPython.display import display_markdown\n",
        "from IPython.display import clear_output\n",
        "from IPython.utils import capture\n",
        "from google.colab import files\n",
        "import shutil\n",
        "import time\n",
        "import os\n",
        "\n",
        "api.upload_folder(\n",
        "  folder_path='/content/drive/MyDrive/2000/feature_extractor',\n",
        "  path_in_repo=\"feature_extractor\",\n",
        "  repo_id=repo_id, token=hf_token\n",
        ")\n",
        "api.upload_folder(\n",
        "  folder_path='/content/drive/MyDrive/2000/scheduler',\n",
        "  path_in_repo=\"scheduler\",\n",
        "  repo_id=repo_id, token=hf_token\n",
        ")\n",
        "api.upload_folder(\n",
        "  folder_path='/content/drive/MyDrive/2000/text_encoder',\n",
        "  path_in_repo=\"text_encoder\",\n",
        "  repo_id=repo_id, token=hf_token\n",
        ")\n",
        "api.upload_folder(\n",
        "  folder_path='/content/drive/MyDrive/2000/tokenizer',\n",
        "  path_in_repo=\"tokenizer\",\n",
        "  repo_id=repo_id, token=hf_token\n",
        ")\n",
        "api.upload_folder(\n",
        "  folder_path='/content/drive/MyDrive/2000/unet',\n",
        "  path_in_repo=\"unet\",\n",
        "  repo_id=repo_id, token=hf_token\n",
        ")\n",
        "api.upload_folder(\n",
        "  folder_path='/content/drive/MyDrive/2000/vae',\n",
        "  path_in_repo=\"vae\",\n",
        "  repo_id=repo_id, token=hf_token\n",
        ")\n"
      ],
      "metadata": {
        "id": "llWsCw42eh2Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from slugify import slugify\n",
        "from huggingface_hub import HfApi, HfFolder, CommitOperationAdd\n",
        "from huggingface_hub import create_repo\n",
        "from IPython.display import display_markdown\n",
        "from IPython.display import clear_output\n",
        "from IPython.utils import capture\n",
        "from google.colab import files\n",
        "import shutil\n",
        "import time\n",
        "import os\n",
        "\n",
        "MODEL1 = '/content/drive/MyDrive/2000/model.ckpt'\n",
        "MODEL2 = '/content/drive/MyDrive/2000/args.json'\n",
        "MODEL3 = '/content/drive/MyDrive/2000/model_index.json'\n",
        "\n",
        "operations = [\n",
        "  CommitOperationAdd(path_in_repo=\"model-fp16.ckpt\",path_or_fileobj=MODEL1),\n",
        "  CommitOperationAdd(path_in_repo=\"args.json\",path_or_fileobj=MODEL2),\n",
        "  CommitOperationAdd(path_in_repo=\"model_index.json\",path_or_fileobj=MODEL3)\n",
        "]\n",
        "api.create_commit(\n",
        "  repo_id=repo_id,\n",
        "  operations=operations,\n",
        "  commit_message=f\"Added sd_helene trained model, 2000 steps.\",\n",
        "  token=hf_token\n",
        ")"
      ],
      "metadata": {
        "id": "zlobaBA6go5K"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "G0NV324ZcL9L",
        "qn5ILIyDJIcX",
        "PFHw44XMhlg6",
        "B5jbpxx_eeAj"
      ],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "2.7.16 (default, Oct 10 2019, 22:02:15) \n[GCC 8.3.0]"
    },
    "vscode": {
      "interpreter": {
        "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
      }
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}