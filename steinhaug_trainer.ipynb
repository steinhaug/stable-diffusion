{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/steinhaug/stable-diffusion/blob/main/steinhaug_trainer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1wJYg6DovNp8"
      },
      "source": [
        "___Before you start:___   \n",
        "_Version: v1.2_  \n",
        "_Start by saving a copy to drive, and use the copy instead. This way you will be able to save your progress while running it. When you switch to the copy, make sure you are not running multiple sessions - under runtime select manage sessions and make sure you have killed all your sessions before you start running your saved copy._\n",
        "\n",
        "This notebook is based on the [ShivamShrirao](https://github.com/ShivamShrirao/diffusers/tree/main/examples/dreambooth) and [TheLastBen](https://colab.research.google.com/github/TheLastBen/fast-stable-diffusion/blob/main/fast-DreamBooth.ipynb) Dreambooth colab.\n",
        "\n",
        "NB! This requires custom editing for each run. If you are looking for a automated dreambooth check out this one, [Dreambooth Colab Edition - for people in a hurry](https://colab.research.google.com/github/steinhaug/stable-diffusion/blob/main/Dreambooth_Colab_edition_for_people_in_a_hurry.ipynb)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "XU7NuMAA2drw"
      },
      "outputs": [],
      "source": [
        "#@title Connect runtime and mount Google Drive\n",
        "#@markdown Check type of GPU and VRAM available.\n",
        "!nvidia-smi --query-gpu=name,memory.total,memory.free --format=csv,noheader\n",
        "\n",
        "save_to_gdrive = True #@param {type:\"boolean\"}\n",
        "if save_to_gdrive:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aLWXPZqjsZVV",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Install dependencies\n",
        "from IPython.display import clear_output\n",
        "from pathlib import Path\n",
        "\n",
        "!wget -q https://github.com/steinhaug/diffusers/raw/main/examples/dreambooth/train_dreambooth.py\n",
        "!wget -q https://github.com/ShivamShrirao/diffusers/raw/main/examples/dreambooth/train_dreambooth.py -O train_dreambooth_new.py\n",
        "#!wget -q https://github.com/steinhaug/diffusers/raw/main/scripts/convert_original_stable_diffusion_to_diffusers.py\n",
        "!wget https://github.com/ShivamShrirao/diffusers/raw/main/scripts/convert_original_stable_diffusion_to_diffusers.py -O convert_original_stable_diffusion_to_diffusers.py\n",
        "!wget -q https://github.com/steinhaug/diffusers/raw/main/scripts/convert_diffusers_to_original_stable_diffusion.py\n",
        "\n",
        "%pip install -qq git+https://github.com/steinhaug/diffusers\n",
        "%pip install -q -U --pre triton\n",
        "%pip install -q accelerate transformers ftfy bitsandbytes==0.35.0 gradio natsort safetensors xformers\n",
        "%pip install omegaconf\n",
        "\n",
        "clear_output()\n",
        "print('\u001b[1;32mAll dependencies installed! âœ“')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "y4lqqWT_uxD2"
      },
      "outputs": [],
      "source": [
        "#@title Login to HuggingFace ðŸ¤—\n",
        "#@markdown You need to accept the model license before downloading or using the Stable Diffusion weights. Please, visit the [model card](https://huggingface.co/runwayml/stable-diffusion-v1-5), read the license and tick the checkbox if you agree. You have to be a registered user in ðŸ¤— Hugging Face Hub, and you'll also need to use an access token for the code to work.\n",
        "\n",
        "!mkdir -p ~/.cache\n",
        "!mkdir -p ~/.cache/huggingface\n",
        "HUGGINGFACE_TOKEN = \"\" #@param {type:\"string\"}\n",
        "!echo -n \"{HUGGINGFACE_TOKEN}\" > ~/.cache/huggingface/token\n",
        "\n",
        "clear_output()\n",
        "print('\u001b[1;32mDone! âœ“')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rxg0y5MBudmd",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Select model and define folder for save\n",
        "#@markdown If model weights should be saved directly in google drive (takes around 4-5 GB).\n",
        "from IPython.display import clear_output;\n",
        "save_to_gdrive = True #@param {type:\"boolean\"}\n",
        "\n",
        "if save_to_gdrive:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "\n",
        "#@markdown Name/Path of the initial model.\n",
        "MODEL_NAME = \"dreamlike-art/dreamlike-photoreal-2.0\" #@param [\"sd-dreambooth-library/disco-diffusion-style\", \"runwayml/stable-diffusion-v1-5\", \"dreamlike-art/dreamlike-photoreal-2.0\", \"SG161222/Realistic_Vision_V2.0\", \"Lykon/DreamShaper\", \"prompthero/openjourney\"] {allow-input: true}\n",
        "#@markdown Enter the directory name to save model at.\n",
        "OUTPUT_DIR = \"sd_weights/dreamlike-steinhaug-20\" #@param {type:\"string\"}\n",
        "\n",
        "if save_to_gdrive:\n",
        "    OUTPUT_DIR = \"/content/drive/MyDrive/\" + OUTPUT_DIR\n",
        "else:\n",
        "    OUTPUT_DIR = \"/content/\" + OUTPUT_DIR\n",
        "\n",
        "!mkdir -p $OUTPUT_DIR\n",
        "\n",
        "!mkdir /content/data/\n",
        "\n",
        "import os\n",
        "import shutil\n",
        "from pathlib import Path\n",
        "\n",
        "# - - -\n",
        "# Copy n files from src to dst\n",
        "# - - -\n",
        "# Example: copy_nfiles(src,dst,500)\n",
        "# Copies first 500 files from src to dst then stops.\n",
        "def copy_nfiles(src, dst, max_n):\n",
        "    path = Path(dst)\n",
        "    if not path.exists():\n",
        "        path.mkdir(parents = False, exist_ok = False)\n",
        "    n = 0;\n",
        "    for item in os.listdir(src):\n",
        "        s = os.path.join(src, item)\n",
        "        d = os.path.join(dst, item)\n",
        "        if os.path.isfile(s):\n",
        "            shutil.copy2(s, d)\n",
        "            n += 1\n",
        "        if n == max_n:\n",
        "            print(f'Copy complete, {max_n} files.')\n",
        "            break\n",
        "\n",
        "# - - -\n",
        "# Copy n files from src into dst1, dst2 and dst3.\n",
        "# - - -\n",
        "# Example: copy_nfiles_to_dst123(src,dst1,dst2,dst3, 500)\n",
        "# First 500 files from src into dst1, next 500 into dst2, next 500 into dst3 and stops.\n",
        "def copy_nfiles_to_dst123(src, dst1, dst2, dst3, xsize):\n",
        "    path = Path(dst1)\n",
        "    if not path.exists():\n",
        "        path.mkdir(parents = False, exist_ok = False)\n",
        "    path = Path(dst2)\n",
        "    if not path.exists():\n",
        "        path.mkdir(parents = False, exist_ok = False)\n",
        "    path = Path(dst3)\n",
        "    if not path.exists():\n",
        "        path.mkdir(parents = False, exist_ok = False)\n",
        "    n = 0;\n",
        "    for item in os.listdir(src):\n",
        "\n",
        "        if n >= (xsize*2):\n",
        "            dst = dst1\n",
        "        elif n >= xsize:\n",
        "            dst = dst2\n",
        "        else:\n",
        "            dst = dst3\n",
        "\n",
        "        s = os.path.join(src, item)\n",
        "        d = os.path.join(dst, item)\n",
        "        if os.path.isfile(s):\n",
        "            shutil.copy2(s, d)\n",
        "            n += 1\n",
        "        if n == (xsize*3):\n",
        "            print(f'Copy complete, 3x{xsize} files.')\n",
        "            break\n",
        "\n",
        "def ret_directoryFileCount(dir_path):\n",
        "    file_count = 0\n",
        "    for path in os.listdir(dir_path):\n",
        "        if os.path.isfile(os.path.join(dir_path, path)):\n",
        "            file_count += 1\n",
        "    return file_count\n",
        "\n",
        "\n",
        "#copy_nfiles_to_dst123(\"/content/data/artwork_style_neg_text_v1-5_mse_vae_dpm2SaKarras50_cfg7_n4200\", \"/content/data/art1\", \"/content/data/art2\", \"/content/data/art3\", 1000)\n",
        "#copy_nfiles(\"/content/data/tmp/guy_v1-5_mse_vae_ddim50_cfg7_n4820\", \"/content/data/guy_images_500\", 500)\n",
        "\n",
        "saved_grid_count = 1\n",
        "\n",
        "clear_output(); print('\u001b[1;32mDone! âœ“')\n",
        "print(f\"[*] Weights will be saved at {OUTPUT_DIR}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Regularization images - class images\n",
        "%cd /content/data/\n",
        "from zipfile import ZipFile\n",
        "\n",
        "#@markdown This cell will download and prepare the regularization images needed for training. Just change the selected archive and reload this cell to change regularization images.\n",
        "regularization_archive = \"man-1000-ddim\" #@param [\"man-1000-ddim\", \"man-4820-ddim\", \"man-394-unsplash\"]\n",
        "\n",
        "REGZIP_ID = ''\n",
        "if regularization_archive == 'man-1000-ddim':\n",
        "    REGZIP_ID = \"guy_v1-5_mse_vae_ddim50_cfg7_n1000\"\n",
        "    !wget https://huggingface.co/datasets/steinhaug/regularization/resolve/main/{REGZIP_ID}.zip -O {REGZIP_ID}.zip\n",
        "elif regularization_archive == 'man-4820-ddim':\n",
        "    REGZIP_ID = \"guy_v1-5_mse_vae_ddim50_cfg7_n4820\"\n",
        "    !wget https://huggingface.co/datasets/ProGamerGov/StableDiffusion-v1-5-Regularization-Images/resolve/main/{REGZIP_ID}.zip -O {REGZIP_ID}.zip\n",
        "elif regularization_archive == 'man-394-unsplash':\n",
        "    REGZIP_ID = \"man_unsplash-394\"\n",
        "    !wget https://huggingface.co/datasets/steinhaug/regularization/resolve/main/{REGZIP_ID}.zip -O {REGZIP_ID}.zip\n",
        "else:\n",
        "    raise Exception(f\"[!] Unknown parameter for regularization_archive.\")\n",
        "\n",
        "if REGZIP_ID !== '':\n",
        "    with ZipFile(\"/content/data/\" + REGZIP_ID + \".zip\", 'r') as zObject:\n",
        "        zObject.extractall(path=\"/content/data\")\n",
        "    REGULARIZATION_DIR = \"/content/data/\" + REGZIP_ID\n",
        "    clear_output()\n",
        "    print('\u001b[1;32mRegularization images - unpacked and ready! âœ“')"
      ],
      "metadata": {
        "cellView": "form",
        "id": "SKa6d9SXyA1i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4LCl6bljv108"
      },
      "outputs": [],
      "source": [
        "# Concept setup\n",
        "\n",
        "# 1 - 5\n",
        "SET_NAME = 5\n",
        "\n",
        "concepts_list = [\n",
        "    {\n",
        "        \"instance_prompt\":      \"photo of steinhaug guy\",\n",
        "        \"class_prompt\":         \"photo of a guy\",\n",
        "        \"instance_data_dir\":    \"/content/data/steinhaug\",\n",
        "        \"class_data_dir\":       \"/content/data/guy_images_auto\",\n",
        "    }\n",
        "]\n",
        "\n",
        "# Create the directory for training images and .json file \n",
        "import json; import os;\n",
        "%cd /content/\n",
        "for c in concepts_list:\n",
        "    os.makedirs(c[\"instance_data_dir\"], exist_ok=True)\n",
        "with open(\"concepts_list.json\", \"w\") as f:\n",
        "    json.dump(concepts_list, f, indent=4)\n",
        "clear_output(); print('\u001b[1;32mDone! âœ“')\n",
        "print(f\"[*] Weights will be saved at {OUTPUT_DIR}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "32gYIDDR1aCp"
      },
      "outputs": [],
      "source": [
        "#@title Optional - file uploader for training images\n",
        "#@markdown Use file manager on the left panel to upload (drag and drop) to each `instance_data_dir` (it uploads faster), or run this cell.\n",
        "\n",
        "import os\n",
        "from google.colab import files\n",
        "import shutil\n",
        "\n",
        "for c in concepts_list:\n",
        "    print(f\"Uploading instance images for `{c['instance_prompt']}`\")\n",
        "    uploaded = files.upload()\n",
        "    for filename in uploaded.keys():\n",
        "        dst_path = os.path.join(c['instance_data_dir'], filename)\n",
        "        shutil.move(filename, dst_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bBoSWaWxBrkY",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Automatic training calibration\n",
        "#@markdown We calibrate the training setting based on how many training images you have uploaded.<br>\n",
        "#@markdown Regularization images are automatically added from the archive you selected previously.  \n",
        "\n",
        "import os; import shutil;\n",
        "\n",
        "for c in concepts_list:\n",
        "    NUM_INSTANCE_IMAGES = ret_directoryFileCount(c[\"instance_data_dir\"]);\n",
        "\n",
        "if NUM_INSTANCE_IMAGES == 0:\n",
        "    raise NameError('No training images uploaded, you need to do this first!')\n",
        "else:\n",
        "    print('[*] Training img count: ', NUM_INSTANCE_IMAGES)\n",
        "    if SET_NAME == 2:\n",
        "        # set2 - 990\n",
        "        n_STEPS_IMG = 90\n",
        "        n_CLASS_IMG = 15\n",
        "        n_STEPS_WRP = 10\n",
        "    elif SET_NAME == 3:\n",
        "        # set3 - 900\n",
        "        n_STEPS_IMG = 100\n",
        "        n_CLASS_IMG = 15\n",
        "        n_STEPS_WRP = 8\n",
        "    elif SET_NAME == 4:\n",
        "        # set4 - 808\n",
        "        n_STEPS_IMG = 101\n",
        "        n_CLASS_IMG = 14\n",
        "        n_STEPS_WRP = 12\n",
        "    elif SET_NAME == 5:\n",
        "        # set5 - \n",
        "        n_STEPS_IMG = 80\n",
        "        n_CLASS_IMG = 25\n",
        "        n_STEPS_WRP = 10\n",
        "    else:\n",
        "        # set1 - 500, 640\n",
        "        n_STEPS_IMG = 80\n",
        "        n_CLASS_IMG = 12\n",
        "        n_STEPS_WRP = 10\n",
        "\n",
        "    LEARNING_RATE = 1e-6\n",
        "    LR_SCHEDULE = \"polynomial\"\n",
        "    NUM_CLASS_IMAGES = NUM_INSTANCE_IMAGES * n_CLASS_IMG\n",
        "    MAX_NUM_STEPS = NUM_INSTANCE_IMAGES * n_STEPS_IMG\n",
        "    LR_WARMUP_STEPS = int(MAX_NUM_STEPS / n_STEPS_WRP)\n",
        "    MAX_TRAIN_STEPS = NUM_INSTANCE_IMAGES * 120\n",
        "\n",
        "    print('[*] SET_NAME: ', SET_NAME)\n",
        "    print(f\"[*] NUM_CLASS_IMAGES {NUM_CLASS_IMAGES}\")\n",
        "    print(f\"[*] MAX_NUM_STEPS {MAX_NUM_STEPS}\")\n",
        "    print(f\"[*] LR_WARMUP_STEPS {LR_WARMUP_STEPS}\")\n",
        "    print(f\"[*] MAX_TRAIN_STEPS {MAX_TRAIN_STEPS}\")\n",
        "\n",
        "    for c in concepts_list:\n",
        "        if os.path.exists(c[\"class_data_dir\"]):\n",
        "            shutil.rmtree(c[\"class_data_dir\"])\n",
        "        os.makedirs(c[\"class_data_dir\"], exist_ok=True)\n",
        "        copy_nfiles(REGULARIZATION_DIR, c[\"class_data_dir\"], NUM_CLASS_IMAGES)\n",
        "        print('[*] Class_data_dir regularization imgs: ', ret_directoryFileCount(c[\"class_data_dir\"]))\n",
        "\n",
        "    print(f'Output: {OUTPUT_DIR}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wuuy5j2_vh0k",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Dreambooth trainer - Lets train the model\n",
        "!python3 train_dreambooth.py \\\n",
        "  --pretrained_model_name_or_path=$MODEL_NAME \\\n",
        "  --pretrained_vae_name_or_path=\"stabilityai/sd-vae-ft-mse\" \\\n",
        "  --output_dir=$OUTPUT_DIR \\\n",
        "  --revision=\"main\" \\\n",
        "  --with_prior_preservation --prior_loss_weight=1.0 \\\n",
        "  --seed=1337 \\\n",
        "  --resolution=512 \\\n",
        "  --train_text_encoder \\\n",
        "  --mixed_precision=\"no\" \\\n",
        "  --use_8bit_adam \\\n",
        "  --gradient_checkpointing \\\n",
        "  --gradient_accumulation_steps=1 \\\n",
        "  --train_batch_size=1 \\\n",
        "  --learning_rate=$LEARNING_RATE \\\n",
        "  --lr_scheduler=$LR_SCHEDULE \\\n",
        "  --lr_warmup_steps=$LR_WARMUP_STEPS \\\n",
        "  --num_class_images=$NUM_CLASS_IMAGES \\\n",
        "  --max_train_steps=$MAX_TRAIN_STEPS \\\n",
        "  --save_interval=$n_STEPS_IMG \\\n",
        "  --sample_batch_size=4 \\\n",
        "  --save_sample_prompt=\"photo of steinhaug guy\" \\\n",
        "  --n_save_sample=10 \\\n",
        "  --concepts_list=\"concepts_list.json\"\n",
        "\n",
        "clear_output()\n",
        "print('\u001b[1;32mTraining completed! âœ“')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cleanup and finnish"
      ],
      "metadata": {
        "id": "NEzOIeGup3If"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "f2ER2wXKcDPp"
      },
      "outputs": [],
      "source": [
        "#@title GRID MAKER: generate a grid of preview images from the saved checkpoints\n",
        "import os\n",
        "from sys import exit\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "\n",
        "OVERRIDE_OUTPUT_DIR = True #@param {type:\"boolean\"}\n",
        "\n",
        "OVERRIDE_DIR = \"/content/drive/MyDrive/sd_weights/dreamlike-steinhaug-20\" #@param {type:\"string\"}\n",
        "\n",
        "SAVE_GRID_IN_DIR = True #@param {type:\"boolean\"}\n",
        "\n",
        "if OVERRIDE_OUTPUT_DIR:\n",
        "    weights_folder = OVERRIDE_DIR\n",
        "    breaki = 5\n",
        "else:\n",
        "    weights_folder = OUTPUT_DIR\n",
        "    breaki = 99\n",
        "\n",
        "folders = sorted([f for f in os.listdir(weights_folder) if f != \"0\" and os.path.isdir(weights_folder + '/' + f)], key=lambda x: int(x))\n",
        "\n",
        "scale = 4\n",
        "\n",
        "row = len(folders)\n",
        "col = len(os.listdir(os.path.join(weights_folder, folders[0], \"samples\")))\n",
        "\n",
        "if col > breaki:\n",
        "    col = breaki\n",
        "\n",
        "fig, axes = plt.subplots(row, col, figsize=(col*scale, row*scale), gridspec_kw={'hspace': 0, 'wspace': 0})\n",
        "\n",
        "for i, folder in enumerate(folders):\n",
        "    folder_path = os.path.join(weights_folder, folder)\n",
        "    image_folder = os.path.join(folder_path, \"samples\")\n",
        "    images = [f for f in os.listdir(image_folder)]\n",
        "    for j, image in enumerate(images):\n",
        "        if row == 1:\n",
        "            currAxes = axes[j]\n",
        "        else:\n",
        "            currAxes = axes[i, j]\n",
        "        if i == 0:\n",
        "            currAxes.set_title(f\"Image {j}\")\n",
        "        if j == 0:\n",
        "            currAxes.text(-0.1, 0.5, folder, rotation=0, va='center', ha='center', transform=currAxes.transAxes)\n",
        "        image_path = os.path.join(image_folder, image)\n",
        "        img = mpimg.imread(image_path)\n",
        "        currAxes.imshow(img, cmap='gray')\n",
        "        currAxes.axis('off')\n",
        "        if j == (breaki - 1):\n",
        "            break;\n",
        "\n",
        "if SAVE_GRID_IN_DIR:\n",
        "    %cd $weights_folder\n",
        "    plt.savefig(f'{saved_grid_count:04d}' + \"_\" + '_grid.png', dpi=72)\n",
        "\n",
        "plt.tight_layout()\n",
        "saved_grid_count += 1\n",
        "%cd /content\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title GRID MAKER - Autodelete folders\n",
        "import os\n",
        "\n",
        "# todo auto select the folders\n",
        "\n",
        "if os.path.isdir(weights_folder):\n",
        "    user_inp_data = input('Do you want to continue? yes or no ')\n",
        "    if user_inp_data == 'yes':\n",
        "        keeper = \"1040\"\n",
        "        keeper2 = \"1111\"\n",
        "\n",
        "        do_delete_all = False\n",
        "\n",
        "        folders = sorted([f for f in os.listdir(weights_folder) if f != \"0\" and os.path.isdir(weights_folder + '/' + f)], key=lambda x: int(x))\n",
        "\n",
        "        for i, folder in enumerate(folders):\n",
        "            if folder == keeper or folder == keeper2:\n",
        "                do_delete_all = True\n",
        "\n",
        "        for i, folder in enumerate(folders):\n",
        "            print(folder)\n",
        "            if folder == keeper or folder == keeper2:\n",
        "                print('We keep this one!')\n",
        "            else:\n",
        "                dirPapth = f'{weights_folder}/' + folder\n",
        "                if do_delete_all:\n",
        "                    print(f'Deleting all files in {dirPapth}')\n",
        "                    !rm -Rf {dirPapth}/scheduler/*\n",
        "                    !rm -Rf {dirPapth}/text_encoder/*\n",
        "                    !rm -Rf {dirPapth}/tokenizer/*\n",
        "                    !rm -Rf {dirPapth}/unet/*\n",
        "                    !rm -Rf {dirPapth}/vae/*\n",
        "                    if os.path.isdir(dirPapth + '/args.json'):\n",
        "                        !rm {dirPapth}/args.json\n",
        "                    if os.path.isdir(dirPapth + '/model_index.json'):\n",
        "                        !rm {dirPapth}/model_index.json\n",
        "\n",
        "        print(f'Done!')\n",
        "    else:\n",
        "        print(f'Make sure you want to do this before continuing')\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "E_NyVNkEBje0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5V8wgU0HN-Kq"
      },
      "source": [
        "## CONVERTERS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "dcXzsUyG1aCy"
      },
      "outputs": [],
      "source": [
        "#@title CONVERT: diffusers to .ckpt\n",
        "%cd /content/\n",
        "#@markdown  Whether to convert to fp16, takes half the space (2GB).\n",
        "fp16 = False #@param {type: \"boolean\"}\n",
        "\n",
        "if fp16:\n",
        "    ckpt_path = WEIGHTS_DIR + \"/model_fp16.ckpt\"\n",
        "else:\n",
        "    ckpt_path = WEIGHTS_DIR + \"/model.ckpt\"\n",
        "\n",
        "half_arg = \"\"\n",
        "if fp16:\n",
        "    half_arg = \"--half\"\n",
        "!python convert_diffusers_to_original_stable_diffusion.py --model_path $WEIGHTS_DIR  --checkpoint_path $ckpt_path $half_arg\n",
        "print(f\"[*] Converted ckpt saved at {ckpt_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "p0KvFqPFwW9g"
      },
      "outputs": [],
      "source": [
        "#@title CONVERT: .ckpt to diffusers\n",
        "\n",
        "PATH_CKPT = \"/content/model/realisticVisionV13_v13.ckpt\" #@param {type:\"string\"}\n",
        "PATH_DIFFUSERS = \"/content/diff_model\" #@param {type:\"string\"}\n",
        "\n",
        "## Display device type\n",
        "#from tensorflow.python.client import device_lib\n",
        "#temp = device_lib.list_local_devices()\n",
        "#print(temp[0])\n",
        "\n",
        "from pathlib import Path\n",
        "\n",
        "path = Path(PATH_CKPT)\n",
        "if not path.is_file():\n",
        "  raise Exception(f\"File not found! Path: {PATH_CKPT}\")\n",
        "\n",
        "path = Path(PATH_DIFFUSERS)\n",
        "if not path.exists():\n",
        "  print(f\"[*] Create directory...\")\n",
        "  path.mkdir(parents = False, exist_ok = False)\n",
        "\n",
        "%cd /content/\n",
        "!python convert_original_stable_diffusion_to_diffusers.py --scheduler_type ddim --checkpoint_path $PATH_CKPT --image_size 512 --prediction_type epsilon --dump_path $PATH_DIFFUSERS --device cpu\n",
        "\n",
        "WEIGHTS_DIR = PATH_DIFFUSERS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BCyzeaKdv58y"
      },
      "source": [
        "# Diffusion Inference mode: Lets load the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "89Az5NUxOWdy"
      },
      "outputs": [],
      "source": [
        "#@markdown Specify the weights directory to use (leave blank for latest)\n",
        "WEIGHTS_DIR = \"/content/drive/MyDrive/sd_weights/dreamlike-steinhaug-20/2814\" #@param {type:\"string\"}\n",
        "if WEIGHTS_DIR == \"\":\n",
        "    from natsort import natsorted\n",
        "    from glob import glob\n",
        "    import os\n",
        "    WEIGHTS_DIR = natsorted(glob(OUTPUT_DIR + os.sep + \"*\"))[-1]\n",
        "\n",
        "path = Path(WEIGHTS_DIR)\n",
        "if not path.exists():\n",
        "  raise Exception(f\"[*] WEIGHTS_DIR does not exist!\")\n",
        "else:\n",
        "  print(f\"[*] WEIGHTS_DIR={WEIGHTS_DIR}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gW15FjffdTID",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Load pipeline, init Diffusers - Stable diffusion inference\n",
        "import torch\n",
        "from torch import autocast\n",
        "from diffusers import StableDiffusionPipeline, DDIMScheduler\n",
        "from IPython.display import display\n",
        "\n",
        "model_path = WEIGHTS_DIR             # If you want to use previously trained model saved in gdrive, replace this with the full path of model in gdrive\n",
        "\n",
        "pipe = StableDiffusionPipeline.from_pretrained(model_path, safety_checker=None, torch_dtype=torch.float16).to(\"cuda\")\n",
        "pipe.scheduler = DDIMScheduler.from_config(pipe.scheduler.config)\n",
        "pipe.enable_xformers_memory_efficient_attention()\n",
        "g_cuda = None\n",
        "\n",
        "from IPython.display import clear_output; clear_output(); print('\u001b[1;32mDone! âœ“')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oIzkltjpVO_f"
      },
      "outputs": [],
      "source": [
        "#@markdown Can set random seed here for reproducibility.\n",
        "g_cuda = torch.Generator(device='cuda')\n",
        "seed = 1 #@param {type:\"number\"}\n",
        "g_cuda.manual_seed(seed)\n",
        "saved_file_count = 1;"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K6xoHWSsbcS3",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "# Place promt here "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PFHw44XMhlg6"
      },
      "source": [
        "# Mini Gradio - Inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "WMCqQ5Tcdsm2"
      },
      "outputs": [],
      "source": [
        "#@markdown Run Gradio UI for generating images.\n",
        "import gradio as gr\n",
        "\n",
        "def inference(prompt, negative_prompt, num_samples, height=512, width=512, num_inference_steps=50, guidance_scale=7.5):\n",
        "    with torch.autocast(\"cuda\"), torch.inference_mode():\n",
        "        return pipe(\n",
        "                prompt, height=int(height), width=int(width),\n",
        "                negative_prompt=negative_prompt,\n",
        "                num_images_per_prompt=int(num_samples),\n",
        "                num_inference_steps=int(num_inference_steps), guidance_scale=guidance_scale,\n",
        "                generator=g_cuda\n",
        "            ).images\n",
        "\n",
        "with gr.Blocks() as demo:\n",
        "    with gr.Row():\n",
        "        with gr.Column():\n",
        "            prompt = gr.Textbox(label=\"Prompt\", value=\"photo of zwx dog in a bucket\")\n",
        "            negative_prompt = gr.Textbox(label=\"Negative Prompt\", value=\"\")\n",
        "            run = gr.Button(value=\"Generate\")\n",
        "            with gr.Row():\n",
        "                num_samples = gr.Number(label=\"Number of Samples\", value=4)\n",
        "                guidance_scale = gr.Number(label=\"Guidance Scale\", value=7.5)\n",
        "            with gr.Row():\n",
        "                height = gr.Number(label=\"Height\", value=512)\n",
        "                width = gr.Number(label=\"Width\", value=512)\n",
        "            num_inference_steps = gr.Slider(label=\"Steps\", value=24)\n",
        "        with gr.Column():\n",
        "            gallery = gr.Gallery()\n",
        "\n",
        "    run.click(inference, inputs=[prompt, negative_prompt, num_samples, height, width, num_inference_steps, guidance_scale], outputs=gallery)\n",
        "\n",
        "demo.launch(debug=True)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "5V8wgU0HN-Kq",
        "BCyzeaKdv58y",
        "PFHw44XMhlg6"
      ],
      "machine_shape": "hm",
      "provenance": [],
      "gpuClass": "premium",
      "include_colab_link": true
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "2.7.16 (default, Oct 10 2019, 22:02:15) \n[GCC 8.3.0]"
    },
    "vscode": {
      "interpreter": {
        "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}