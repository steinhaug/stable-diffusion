{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/steinhaug/stable-diffusion/blob/main/BLIP-2/AutoCaptioner-LLaVA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JLrfOnnHAulW"
      },
      "source": [
        "## AutoCaptioner using LLaVA\n",
        "\n",
        "Remember to run postWorker notebook when this one is done.  \n",
        "\n",
        "[![Buy me a beer](https://raw.githubusercontent.com/steinhaug/stable-diffusion/main/assets/buy-me-a-beer.png ) ](https://steinhaug.com/donate/)\n",
        "\n",
        "__NB!__  \n",
        "This notebook is not made for \"people in a hurry\", so you need to make sure to download the correct images you want to caption and make sure the inference is targeting the correct folders.  \n",
        "If you would like a \"1,2,3 go\" notebook for image captioning ask me and I'll put it together.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AjIlnM48aec1",
        "outputId": "c0142b5b-e19e-4a27-a5d0-12cfa347f13a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "60oc14dbXT1c"
      },
      "outputs": [],
      "source": [
        "#@markdown Download some images\n",
        "import locale\n",
        "locale.getpreferredencoding = lambda: \"UTF-8\"\n",
        "!mkdir /content/images\n",
        "#!wget --header 'Authorization: Bearer TOKEN_HERE' https://huggingface.co/camenduru/polaroid/resolve/main/style_name_fix.zip\n",
        "!cp /content/drive/MyDrive/data/blip2.zip /content/images/style_name_fix.zip\n",
        "!unzip /content/images/style_name_fix.zip -d /content/images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IH3_BSi7GyKj"
      },
      "source": [
        "## Pre-install: System"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K6utlt7-Zcff",
        "outputId": "dc16669d-7074-4600-847d-96787bd3a139"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;32mDone! ✓\n"
          ]
        }
      ],
      "source": [
        "#@markdown 1.0: Install dependencies\n",
        "from IPython.display import clear_output\n",
        "%cd /content\n",
        "!git clone -b dev https://github.com/camenduru/LLaVA\n",
        "%cd /content/LLaVA\n",
        "!wget https://raw.githubusercontent.com/L0garithmic/fastcolabcopy/main/fastcopy.py\n",
        "\n",
        "!pip install -q transformers==4.36.2\n",
        "!pip install ninja\n",
        "!pip install flash-attn --no-build-isolation\n",
        "\n",
        "!pip install -e .\n",
        "clear_output()\n",
        "print('\u001b[1;32mDone! ✓')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "4Fgx-7UpEZw1",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@markdown 1.2: Load notebook functions, needs to reload if you restart session.\n",
        "import tarfile\n",
        "import os\n",
        "import glob\n",
        "import zipfile\n",
        "import shutil\n",
        "\n",
        "def compress_tar(directory_path, output_tar_file, inclusion_pattern=None):\n",
        "    if output_tar_file is None:\n",
        "        output_tar_file = f\"{directory_path}/{return__folderName(directory_path)}.tar\"\n",
        "    if not output_tar_file.endswith('.gz'):\n",
        "        output_tar_file += '.gz'\n",
        "    with tarfile.open(output_tar_file, 'w:gz') as tar:\n",
        "        for root, dirs, files in os.walk(directory_path):\n",
        "            if inclusion_pattern:\n",
        "                files_to_include = glob.glob(os.path.join(root, inclusion_pattern))\n",
        "            else:\n",
        "                files_to_include = [os.path.join(root, file) for file in files]\n",
        "            for file_path in files_to_include:\n",
        "                arcname = os.path.relpath(file_path, directory_path)\n",
        "                print(f\"{arcname}\")\n",
        "                tar.add(file_path, arcname=arcname)\n",
        "\n",
        "def decompress_tar(tar_file, destination=None, flatten_structure=False):\n",
        "    with tarfile.open(tar_file, 'r') as tar:\n",
        "        if destination is not None:\n",
        "            print(f\"Create: {destination}\")\n",
        "            os.makedirs(destination, exist_ok=True)\n",
        "\n",
        "        folder, extension = os.path.splitext(return__folderName(tar_file))\n",
        "\n",
        "        for member in tar.getmembers():\n",
        "            if flatten_structure:\n",
        "                # Use just the filename without directories\n",
        "                member.name = os.path.basename(member.name)\n",
        "                #print(f\"member.name 1: {member.name}\")\n",
        "            if destination is not None:\n",
        "                # Join the destination directory with the member's name\n",
        "                #member_path = os.path.join(destination, folder)\n",
        "                if flatten_structure:\n",
        "                    member_path = os.path.join(destination, folder, os.path.dirname(member.name))\n",
        "                else:\n",
        "                    member_path = destination\n",
        "                #print(f\"member_path 2: {member_path}\")\n",
        "            else:\n",
        "                member_path = os.path.dirname(member.name)\n",
        "                #print(f\"member_path 3: {member_path}\")\n",
        "\n",
        "            if flatten_structure and destination==None:\n",
        "                member_path = os.path.dirname(tar_file)\n",
        "                #print(f\"member_path 4: {member_path}\")\n",
        "\n",
        "            #print(f\"{member.name}: {member_path}\")\n",
        "            tar.extract(member, path=member_path)\n",
        "\n",
        "            #break\n",
        "def decompress_tar_gz(file_path, output_dir='.'):\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "    try:\n",
        "        with tarfile.open(file_path, 'r:gz') as tar:\n",
        "            tar.extractall(output_dir)\n",
        "        print(f\"Successfully decompressed '{file_path}' to '{output_dir}'.\")\n",
        "    except tarfile.TarError as e:\n",
        "        print(f\"Error decompressing '{file_path}': {e}\")\n",
        "\n",
        "def decompress_zip_files(directory):\n",
        "    # Check if the directory exists\n",
        "    if not os.path.isdir(directory):\n",
        "        print(\"The specified directory does not exist.\")\n",
        "        return\n",
        "\n",
        "    # List all files in the directory\n",
        "    files = os.listdir(directory)\n",
        "\n",
        "    # Filter to keep only .zip files\n",
        "    zip_files = [f for f in files if f.endswith('.zip')]\n",
        "\n",
        "    # Process each zip file\n",
        "    for zip_file in zip_files:\n",
        "        # Full path to the zip file\n",
        "        zip_path = os.path.join(directory, zip_file)\n",
        "\n",
        "        # Extract the base name without the '.zip' extension to create a new folder\n",
        "        folder_name = zip_file[:-4]\n",
        "        new_folder_path = os.path.join(directory, folder_name)\n",
        "\n",
        "        # Create the new directory\n",
        "        if not os.path.exists(new_folder_path):\n",
        "            os.makedirs(new_folder_path)\n",
        "\n",
        "        # Open the zip file\n",
        "        with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "            # Extract all the files\n",
        "            for file_info in zip_ref.infolist():\n",
        "                # Ensure we are only extracting files, not directories\n",
        "                if file_info.is_dir():\n",
        "                    continue  # Skip directories\n",
        "                # Extract each file to the root of the new folder, ignoring any folder structure within the zip\n",
        "                extracted_path = os.path.join(new_folder_path, os.path.basename(file_info.filename))\n",
        "                with zip_ref.open(file_info.filename) as source, open(extracted_path, 'wb') as target:\n",
        "                    shutil.copyfileobj(source, target)\n",
        "\n",
        "        print(f\"Extracted {zip_file} into {new_folder_path}\")\n",
        "\n",
        "def write_the_file(path, data_string):\n",
        "    if len(str(data_string)):\n",
        "        with open(path, 'w+') as fw:\n",
        "            fw.write(str(data_string))\n",
        "    else:\n",
        "        if os.path.exists(path):\n",
        "            os.remove(path)\n",
        "    return '';\n",
        "\n",
        "def delete_dir(directory_path):\n",
        "    if os.path.exists(directory_path):\n",
        "        shutil.rmtree(directory_path)\n",
        "        print(f\"Directory and all contents deleted: {directory_path}\")\n",
        "    else:\n",
        "        print(\"The directory does not exist.\")\n",
        "\n",
        "def return__folderName(directory_path, verify_folder=False):\n",
        "    if not verify_folder:\n",
        "        return os.path.basename(os.path.normpath(directory_path))\n",
        "    if os.path.isdir(directory_path):\n",
        "        last_folder_name = os.path.basename(os.path.normpath(directory_path))\n",
        "        return last_folder_name\n",
        "    else:\n",
        "        return None # Return None for invalid paths\n",
        "\n",
        "def ensure_array(input_var):\n",
        "    if isinstance(input_var, list):\n",
        "        return input_var\n",
        "    elif isinstance(input_var, str):\n",
        "        return [input_var]\n",
        "    else:\n",
        "        raise ValueError(\"Input must be a string or a list\")\n",
        "\n",
        "def array__prefix_with(filter_extensions, prefix='.'):\n",
        "    return [ext if ext.startswith(prefix) else prefix + ext for ext in filter_extensions]\n",
        "\n",
        "def return__fileCount(directory_path, extensions=None):\n",
        "    matching_files_count = 0\n",
        "\n",
        "    if extensions is not None:\n",
        "        extensions = array__prefix_with(ensure_array(extensions)) #['.jpg', '.jpeg', '.png', '.gif', '.bmp', '.webp']\n",
        "\n",
        "    for root, dirs, files in os.walk(directory_path):\n",
        "        for file in files:\n",
        "            if extensions is None:\n",
        "                matching_files_count += 1\n",
        "            elif any(file.lower().endswith(extension.lower()) for extension in extensions):\n",
        "                matching_files_count += 1\n",
        "\n",
        "    return matching_files_count\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pre-install: Download and prepare files"
      ],
      "metadata": {
        "id": "oTEyrsfwRKoL"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1eQmrQrVbQHS"
      },
      "source": [
        "Download the image set, decompress the files and launch the captioning loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RKWOlIGizo-V"
      },
      "outputs": [],
      "source": [
        "import locale\n",
        "locale.getpreferredencoding = lambda: \"UTF-8\"\n",
        "\n",
        "from google.colab import userdata\n",
        "HF_TOKEN = userdata.get('HF_TOKEN')\n",
        "\n",
        "!huggingface-cli login --token {HF_TOKEN}\n",
        "from huggingface_hub import snapshot_download"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Otvo8vKIz3AW"
      },
      "outputs": [],
      "source": [
        "#@ markdown Download image sets\n",
        "import os\n",
        "SAVE_PATH = '/content/datasets'\n",
        "REPO_ID = 'steinhaug/onceUponAtimeInPornVille'\n",
        "os.makedirs(f\"{SAVE_PATH}/{REPO_ID}\", exist_ok=True)\n",
        "path = snapshot_download(repo_id=REPO_ID, repo_type=\"dataset\", revision=\"main\", allow_patterns=\"SexArt/*\", local_dir=f\"{SAVE_PATH}/{REPO_ID}\", local_dir_use_symlinks=False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown Decompress captions\n",
        "tar_gz_file_path = '/content/drive/MyDrive/datasets/SexArt.tar.gz'\n",
        "output_directory = '/content/datasets/SexArt'\n",
        "\n",
        "if not os.path.exists(output_directory):\n",
        "    os.makedirs(output_directory)\n",
        "\n",
        "# Call the function\n",
        "decompress_tar_gz(tar_gz_file_path, output_directory)\n"
      ],
      "metadata": {
        "id": "_cW5JIqTGpkr",
        "outputId": "c1efd84c-553d-4a94-a318-ab95b190053d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully decompressed '/content/drive/MyDrive/datasets/SexArt.tar.gz' to '/content/datasets/SexArt'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown Decompress all .tar folders\n",
        "IMAGE_FOLDER = '/content/datasets/steinhaug/onceUponAtimeInPornVille/SexArt'\n",
        "output_directory = '/content/datasets/SexArt'\n",
        "\n",
        "for item_name in os.listdir(IMAGE_FOLDER):\n",
        "    file_path = os.path.join(IMAGE_FOLDER, item_name)\n",
        "    #print(f\"{file_path}\")\n",
        "    root, extension = os.path.splitext(file_path)\n",
        "    if extension == '.tar':\n",
        "        decompress_tar(file_path, output_directory, False)\n",
        "        print(f\"Decompressed: {file_path}\")\n"
      ],
      "metadata": {
        "id": "rQJXBoQxHn3o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UB1kg1LrC14B"
      },
      "outputs": [],
      "source": [
        "!rm -Rf /content/datasets/steinhaug/onceUponAtimeInPornVille/Domai"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vOwSbjBmTIzi"
      },
      "source": [
        "## Model CONFIG"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "cellView": "form",
        "id": "QDE9jxWDquBt"
      },
      "outputs": [],
      "source": [
        "#@markdown __[\\*]>=-  Unload model -=<[\\*]__ <br>\n",
        "#@markdown Run this cell if you need to load another model, or reset the runtime.\n",
        "image_processor = None\n",
        "vision_tower = None\n",
        "import gc\n",
        "import torch\n",
        "model = None\n",
        "tokenizer = None\n",
        "del model\n",
        "del tokenizer\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W_JjYTntUk_2",
        "outputId": "b2f3a64d-bac2-4576-df55-312d418dfb94"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;32mSelected model: llava-v1.5-13b-3GB ✓\n"
          ]
        }
      ],
      "source": [
        "# @markdown 1/3: Model select\n",
        "from IPython.display import clear_output\n",
        "%cd /content/LLaVA\n",
        "clear_output()\n",
        "\n",
        "import fastcopy\n",
        "import os\n",
        "def return__folderName(directory_path, verify_folder=False):\n",
        "\n",
        "    if not verify_folder:\n",
        "        return os.path.basename(os.path.normpath(directory_path))\n",
        "\n",
        "    # Ensure the path is a valid directory\n",
        "    if os.path.isdir(directory_path):\n",
        "        # Split the path into components and get the last one\n",
        "        last_folder_name = os.path.basename(os.path.normpath(directory_path))\n",
        "        return last_folder_name\n",
        "    else:\n",
        "        return None  # Return None for invalid paths\n",
        "\n",
        "model_id = \"4bit/llava-v1.5-13b-3GB\" # @param ['liuhaotian/llava-v1.5-7b', '4bit/llava-v1.5-13b-3GB']\n",
        "\n",
        "model_drive_path = f\"/content/drive/MyDrive/models/LLaVA/{model_id}\"\n",
        "model_path = f\"/content/models/{return__folderName(model_id)}\"\n",
        "\n",
        "print(f\"\u001b[1;32mSelected model: {return__folderName(model_id)} ✓\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84,
          "referenced_widgets": [
            "43acce0924974eb6a673f3f179c9a1ff",
            "cd785299e44e4ac6a74ba00d369a403a",
            "00e3c07e0bf947e382157313198afd14",
            "cf561e9bb9f24292953df1f9e7c3622a",
            "81b9442f4f9146978f83c11ea68dbfd6",
            "131626e39ba04c1a96311fe53acab2ef",
            "ec4e1ba610c34ac1b0084f16fbe71cf0",
            "c25e38573bd7472d80a128aca553cd42",
            "7e95d191e34547b382d2abe7fe20a179",
            "71dc8a29e73d4ddc9bd2a0c57a9ff446",
            "84f6ba6061f44119a34c851ea5123558"
          ]
        },
        "id": "dwo2mY8tidLl",
        "outputId": "7e742fc0-a761-4ed6-8d0f-579804266ae7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2024-04-26 14:14:35,826] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "Model download and config complete.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/9 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "43acce0924974eb6a673f3f179c9a1ff"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "#@markdown 2/3: Model loader, prepare files and load model into GPU...\n",
        "import os\n",
        "if not os.path.isdir(model_path):\n",
        "    os.makedirs(model_path)\n",
        "    !python fastcopy.py \"$model_drive_path/\". \"$model_path\" --thread 20 --size-limit 400mb\n",
        "    !python fastcopy.py \"$model_drive_path/\". \"$model_path\" --thread 3 --size-limit 800mb\n",
        "    !python fastcopy.py \"$model_drive_path/\". \"$model_path\" --thread 3 --size-limit 3500mb\n",
        "    !rsync -r -v --size-only --progress $model_drive_path/. $model_path --delete\n",
        "\n",
        "from transformers import AutoTokenizer, BitsAndBytesConfig\n",
        "from llava.model import LlavaLlamaForCausalLM\n",
        "import torch\n",
        "\n",
        "if model_id == 'liuhaotian/llava-v1.5-7b':\n",
        "    kwargs = {\"device_map\": \"auto\", \"low_cpu_mem_usage\": True }\n",
        "    kwargs['load_in_8bit'] = True\n",
        "    kwargs['quantization_config'] = BitsAndBytesConfig(\n",
        "        load_in_8bit=True\n",
        "    )\n",
        "    print(\"Model download and config complete.\")\n",
        "elif model_id == '4bit/llava-v1.5-13b-3GB':\n",
        "    kwargs = {\"device_map\": \"auto\", \"low_cpu_mem_usage\": True }\n",
        "    kwargs['load_in_4bit'] = True\n",
        "    kwargs['quantization_config'] = BitsAndBytesConfig(\n",
        "        load_in_4bit=True,\n",
        "        bnb_4bit_compute_dtype=torch.float16,\n",
        "        bnb_4bit_use_double_quant=True,\n",
        "        bnb_4bit_quant_type='nf4'\n",
        "    )\n",
        "    print(\"Model download and config complete.\")\n",
        "elif model_id == '4bit/llava-v1.5-13b-4GB-8bit':\n",
        "    kwargs = {\"device_map\": \"auto\", \"low_cpu_mem_usage\": True }\n",
        "    kwargs['load_in_4bit'] = True\n",
        "    kwargs['quantization_config'] = BitsAndBytesConfig(\n",
        "        load_in_4bit=True,\n",
        "        bnb_4bit_quant_type=\"nf4\",\n",
        "        bnb_4bit_use_double_quant=True,\n",
        "        bnb_4bit_compute_dtype=torch.bfloat16\n",
        "    )\n",
        "    print(\"Model download and config complete.\")\n",
        "else:\n",
        "    print(\"Error...\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def old_ones():\n",
        "    #@ markdown llava-v1.5-13b-3GB\n",
        "    from transformers import AutoTokenizer, BitsAndBytesConfig\n",
        "    from llava.model import LlavaLlamaForCausalLM\n",
        "    import torch\n",
        "\n",
        "    model_path = \"/content/llava-v1.5-13b-3GB\"\n",
        "    kwargs = {\"device_map\": \"auto\", \"low_cpu_mem_usage\": True }\n",
        "    kwargs['load_in_4bit'] = True\n",
        "    kwargs['quantization_config'] = BitsAndBytesConfig(\n",
        "        load_in_4bit=True,\n",
        "        bnb_4bit_compute_dtype=torch.float16,\n",
        "        bnb_4bit_use_double_quant=True,\n",
        "        bnb_4bit_quant_type='nf4'\n",
        "    )\n",
        "\n",
        "\n",
        "    #@ markdown llava-v1.5-7b\n",
        "    from transformers import AutoTokenizer, BitsAndBytesConfig\n",
        "    from llava.model import LlavaLlamaForCausalLM\n",
        "    import torch\n",
        "\n",
        "    model_path = \"/content/llava-v1.5-7b\"\n",
        "    kwargs = {\"device_map\": \"auto\", \"low_cpu_mem_usage\": True }\n",
        "    kwargs['load_in_8bit'] = True\n",
        "    kwargs['quantization_config'] = BitsAndBytesConfig(\n",
        "        load_in_8bit=True\n",
        "    )\n",
        "\n",
        "\n",
        "\n",
        "#@ title Load it up - move to GPU\n",
        "my_list = ['llava-v1.5-7b','llava-v1.5-13b-3GB','llava-v1.5-13b-4GB-8bit']\n",
        "if return__folderName(model_path) in my_list:\n",
        "    model = LlavaLlamaForCausalLM.from_pretrained(model_path, **kwargs)\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_path, use_fast=False)\n",
        "\n",
        "    vision_tower = model.get_vision_tower()\n",
        "    if not vision_tower.is_loaded:\n",
        "        vision_tower.load_model()\n",
        "    vision_tower.to(device='cuda')\n",
        "    image_processor = vision_tower.image_processor\n",
        "else:\n",
        "    print(f\"{element_to_check} is not a valid model.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "cellView": "form",
        "id": "VjYy0F2gZIPR"
      },
      "outputs": [],
      "source": [
        "#@markdown 3/3: Load the caption_image func\n",
        "import os\n",
        "import requests\n",
        "from PIL import Image\n",
        "from io import BytesIO\n",
        "from llava.conversation import conv_templates, SeparatorStyle\n",
        "from llava.utils import disable_torch_init\n",
        "from llava.constants import IMAGE_TOKEN_INDEX, DEFAULT_IMAGE_TOKEN, DEFAULT_IM_START_TOKEN, DEFAULT_IM_END_TOKEN\n",
        "from llava.mm_utils import tokenizer_image_token, get_model_name_from_path, KeywordsStoppingCriteria\n",
        "from transformers import TextStreamer\n",
        "\n",
        "def caption_image(image_file, prompt, temperature=0.2):\n",
        "    if image_file.startswith('http') or image_file.startswith('https'):\n",
        "        response = requests.get(image_file)\n",
        "        image = Image.open(BytesIO(response.content)).convert('RGB')\n",
        "    else:\n",
        "        image = Image.open(image_file).convert('RGB')\n",
        "    disable_torch_init()\n",
        "    conv_mode = \"llava_v0\"\n",
        "    conv = conv_templates[conv_mode].copy()\n",
        "    roles = conv.roles\n",
        "    image_tensor = image_processor.preprocess(image, return_tensors='pt')['pixel_values'].half().cuda()\n",
        "    inp = f\"{roles[0]}: {prompt}\"\n",
        "    inp = DEFAULT_IM_START_TOKEN + DEFAULT_IMAGE_TOKEN + DEFAULT_IM_END_TOKEN + '\\n' + inp\n",
        "    conv.append_message(conv.roles[0], inp)\n",
        "    conv.append_message(conv.roles[1], None)\n",
        "    raw_prompt = conv.get_prompt()\n",
        "    input_ids = tokenizer_image_token(raw_prompt, tokenizer, IMAGE_TOKEN_INDEX, return_tensors='pt').unsqueeze(0).cuda()\n",
        "    stop_str = conv.sep if conv.sep_style != SeparatorStyle.TWO else conv.sep2\n",
        "    keywords = [stop_str]\n",
        "    stopping_criteria = KeywordsStoppingCriteria(keywords, tokenizer, input_ids)\n",
        "    with torch.inference_mode():\n",
        "      output_ids = model.generate(input_ids, images=image_tensor, do_sample=True, temperature=temperature,\n",
        "                                  max_new_tokens=1024, use_cache=True, stopping_criteria=[stopping_criteria])\n",
        "    outputs = tokenizer.decode(output_ids[0, input_ids.shape[1]:]).strip()\n",
        "    conv.messages[-1][-1] = outputs\n",
        "    output = outputs.rsplit('</s>', 1)[0]\n",
        "    return image, output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xDodJLBDhS5V"
      },
      "source": [
        "## Inference testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "PT0YY28dwTZi"
      },
      "outputs": [],
      "source": [
        "#@markdown <h2>Multiquestion loop</h2>\n",
        "question = '''Answer the following questions:\n",
        "1 - Describe the subject in the image.\n",
        "2 - Use descriptive language for the subject.\n",
        "3 - Describe the subject using explicit language focusing on bodily features.\n",
        "4 - You are working at an adult store and you job is to write captions for images. Describe the following photo.\n",
        "5 - You are working for a marketing company that sells adulterated photos and your job is to write captions so that people might buy the photo. Describe the following photo.\n",
        "Separate your answers with line breaks.\n",
        "'''\n",
        "file_name = 'p1.jpg'\n",
        "image, output = caption_image(f'/content/images/blip2/{file_name}', question, 0.1); output = output.replace(\"\\n\\n\", \"\\n\");\n",
        "sizeDiv=8; h, w = image.size; display(image.resize(( int(h / sizeDiv) , int(w / sizeDiv) )));\n",
        "print(f\"{question}\\n\\n0.1\\n{output}\")\n",
        "image, output = caption_image(f'/content/images/blip2/{file_name}', question, 0.3); output = output.replace(\"\\n\\n\", \"\\n\");\n",
        "print(f\"\\n0.3:\\n{output}\")\n",
        "\n",
        "question = '''Answer the following questions:\n",
        "1 - Describe the subject in the image.\n",
        "2 - Use descriptive language for the subject.\n",
        "3 - Describe the subject using explicit language focusing on bodily features.\n",
        "4 - If this was a photo for an adult movie, what would the title be?\n",
        "5 - If this was a photo for a book, what would the title of the book be?\n",
        "6 - If this was a photo for a novel, what would the title of the novel be?\n",
        "7 - You are in a bookstore that sells romantic and sexual inspired books, on the shelf you see a book with the photo on the front. What is the title of the book?\n",
        "\n",
        "Separate your answers with line breaks.\n",
        "'''\n",
        "\n",
        "image, output = caption_image(f'/content/images/blip2/{file_name}', question, 0.1); output = output.replace(\"\\n\\n\", \"\\n\");\n",
        "print(f\"\\n{question}\\n\\n0.1\\n{output}\")\n",
        "image, output = caption_image(f'/content/images/blip2/{file_name}', question, 0.3); output = output.replace(\"\\n\\n\", \"\\n\");\n",
        "print(f\"\\n0.3:\\n{output}\")\n",
        "\n",
        "question = '''Answer the following questions:\n",
        "1 - You are working in the company \"Pussy Inc\" where everybody share their love for the womans vagina in all forms. Your job is to write 50 or so words describing the photo vividly.\n",
        "2 - You are working in the company \"Pussy Inc\" where everybody share their love for the womans vagina in all forms. Your job is to write atleast 50 words describing the photo vividly.\n",
        "3 - You are working in the company \"Pussy Inc\" where everybody share their love for the womans vagina in all forms. Your job is to write atleast 50 words describing the picture with sexualized and perverted language, for the picture of the month in our newspaper.\n",
        "\n",
        "Separate your answers with line breaks.\n",
        "'''\n",
        "\n",
        "image, output = caption_image(f'/content/images/blip2/{file_name}', question, 0.1); output = output.replace(\"\\n\\n\", \"\\n\");\n",
        "print(f\"\\n{question}\\n\\n0.1\\n{output}\")\n",
        "image, output = caption_image(f'/content/images/blip2/{file_name}', question, 0.3); output = output.replace(\"\\n\\n\", \"\\n\");\n",
        "print(f\"\\n0.3:\\n{output}\\n\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "QhtcmqRuXT1c"
      },
      "outputs": [],
      "source": [
        "#@markdown <h2>Benchmark loop</h2>\n",
        "question = 'Describe the image and color details.'\n",
        "\n",
        "file_names = os.listdir('/content/images/blip2')\n",
        "sorted_file_names = sorted(file_names)\n",
        "for file_name in sorted_file_names:\n",
        "    try:\n",
        "        image, output = caption_image(f'/content/images/blip2/{file_name}', question)\n",
        "        print(f\"{file_name}:{output}\")\n",
        "        # image\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing {file_name}: {str(e)}\")\n",
        "        continue"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FUvkv79FEGAt"
      },
      "source": [
        "## AutoCaptioning testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YMOnKqIwynUU"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "question = '''You are captioning adult images, answer the following questions:\n",
        "1 - Is the subjects head visible? Yes / No\n",
        "2 - Are the subjects hands visible? Yes / No\n",
        "3 - Are the subjects feet visible? Yes / No\n",
        "4 - Describe what the hands are doing, or can't tell if you do not know.\n",
        "5 - If possible, describe what the hands are doing.\n",
        "6 - Would you say the subject is: standing, sitting or lying?\n",
        "7 - Try to reason if the photo is indoors or outdoors?\n",
        "8 - Try to reason what time of day the photo is taken?\n",
        "\n",
        "Separate your answers with line breaks.'''\n",
        "\n",
        "file_names = [\n",
        "    '/content/datasets/SexArt/23.03.23.Paulina.Pace.Stunning.View/SexArt_Stunning-View_Paulina-Pace_high_0004.jpg',\n",
        "]\n",
        "\n",
        "for file_name in file_names:\n",
        "    image, output = caption_image(file_name, question, 0.2); output = output.replace(\"\\n\\n\", \"\\n\");\n",
        "    sizeDiv=24; h, w = image.size; display(image.resize(( int(h / sizeDiv) , int(w / sizeDiv) )));\n",
        "    print(f\"{os.path.basename(file_name)}\")\n",
        "    print(f\"\\n0.2\\n{output}\")\n",
        "    #image, output = caption_image(file_name, question, 0.2); output = output.replace(\"\\n\\n\", \"\\n\");\n",
        "    #print(f\"\\n\\n0.2\\n{output}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## AutoCaptioning"
      ],
      "metadata": {
        "id": "wQT75vCrPjiq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kw4Y15ae6xDN",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@markdown **CAPTIONER** AutoCaptioner Loop\n",
        "IMAGE_FOLDER = \"/content/datasets/SexArt\" # @param {type:\"string\"}\n",
        "\n",
        "question = '''You are captioning adult images, answer the following questions:\n",
        "1 - If this was a photo for an adult movie, what would the title be?\n",
        "2 - Use descriptive language for the subject.\n",
        "3 - How would you rate the subject? Completely naked, almost naked, panties and bra, clothed or can't tell.\n",
        "4 - If the subject has a vagina visible in the photo, how would you describe it? Shaved pussy, trimmed pussy, hairy pussy or can't tell.\n",
        "5 - If the subject is a woman, how would you rate her breats? Tiny, small, medium, large, mega or can't tell.\n",
        "6 - How would you rate the subjects body build? Skinny, thin, normal, big, fat or unsure.\n",
        "7 - Is the subjects head visible? Yes / No\n",
        "8 - Are the subjects hands visible? Yes / No\n",
        "9 - Are the subjects feet or lower legs visible? Yes / No\n",
        "10 - Would you say the subject is: standing, kneeling, lying or sitting? If lying then on the back or stomach?\n",
        "11 - Describe what the hands are doing, or can't tell if you do not know.\n",
        "\n",
        "Separate your answers with line breaks.'''\n",
        "\n",
        "image_extensions = ['.jpg', '.jpeg', '.png', '.gif', '.bmp', '.webp']\n",
        "total_count = return__fileCount(IMAGE_FOLDER, image_extensions)\n",
        "\n",
        "image_count = 0\n",
        "for root, dirs, files in os.walk(IMAGE_FOLDER):\n",
        "    for file in files:\n",
        "        #print( f\"{root}/{file}\" )\n",
        "        file_path = os.path.join(root, file)\n",
        "        file_root, file_ext = os.path.splitext(file_path)\n",
        "        if file_ext.lower() in image_extensions:\n",
        "            image_count = image_count + 1\n",
        "            caption_file = f\"{file_root}.txt\"\n",
        "            print(f\"-= {image_count}/{total_count} : {caption_file} =-\")\n",
        "            if not os.path.isfile(caption_file):\n",
        "                try:\n",
        "                    image, caption_result = caption_image(file_path, question)\n",
        "                    caption_result = caption_result.replace(\"\\n\\n\", \"\\n\")\n",
        "                    write_the_file(caption_file, caption_result)\n",
        "                    sizeDiv = 25\n",
        "                    h, w = image.size\n",
        "                    display(image.resize(( int(h / sizeDiv) , int(w / sizeDiv) )))\n",
        "                    print(f\"{caption_result}\")\n",
        "                except Exception as e:\n",
        "                    print(f\"Error processing {image_count}/{total_count} ({item_name}): {str(e)}\")\n",
        "                    continue\n",
        "            else:\n",
        "                verbosed_message = f\"Caption file already exists.\"\n",
        "                #print(verbosed_message)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p0OSpvM0-gS1"
      },
      "outputs": [],
      "source": [
        "# Compresses all the .txt files\n",
        "compress_tar('/content/datasets/SexArt', '/content/drive/MyDrive/datasets/SexArt3.tar', '*.txt')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "cH4nePeMSfBp"
      },
      "outputs": [],
      "source": [
        "#if \"step1_installed_flag\" not in globals():\n",
        "#  raise Exception(\"Please run step 1 first!\")\n",
        "\n",
        "#@markdown ### 📈 Analyze Tags\n",
        "#@markdown Perhaps you need another look at your dataset.\n",
        "show_top_tags = 50 #@param {type:\"number\"}\n",
        "\n",
        "from collections import Counter\n",
        "top_tags = Counter()\n",
        "\n",
        "for txt in [f for f in os.listdir(IMAGE_FOLDER) if f.lower().endswith(\".txt\")]:\n",
        "  with open(os.path.join(IMAGE_FOLDER, txt), 'r') as f:\n",
        "    top_tags.update([s.strip() for s in f.read().split(\" \")])\n",
        "\n",
        "top_tags = Counter(top_tags)\n",
        "print(f\"📊 Top {show_top_tags} tags:\")\n",
        "for k, v in top_tags.most_common(show_top_tags):\n",
        "  print(f\"{k} ({v})\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "43acce0924974eb6a673f3f179c9a1ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cd785299e44e4ac6a74ba00d369a403a",
              "IPY_MODEL_00e3c07e0bf947e382157313198afd14",
              "IPY_MODEL_cf561e9bb9f24292953df1f9e7c3622a"
            ],
            "layout": "IPY_MODEL_81b9442f4f9146978f83c11ea68dbfd6"
          }
        },
        "cd785299e44e4ac6a74ba00d369a403a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_131626e39ba04c1a96311fe53acab2ef",
            "placeholder": "​",
            "style": "IPY_MODEL_ec4e1ba610c34ac1b0084f16fbe71cf0",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "00e3c07e0bf947e382157313198afd14": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c25e38573bd7472d80a128aca553cd42",
            "max": 9,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7e95d191e34547b382d2abe7fe20a179",
            "value": 9
          }
        },
        "cf561e9bb9f24292953df1f9e7c3622a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_71dc8a29e73d4ddc9bd2a0c57a9ff446",
            "placeholder": "​",
            "style": "IPY_MODEL_84f6ba6061f44119a34c851ea5123558",
            "value": " 9/9 [03:01&lt;00:00, 19.73s/it]"
          }
        },
        "81b9442f4f9146978f83c11ea68dbfd6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "131626e39ba04c1a96311fe53acab2ef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ec4e1ba610c34ac1b0084f16fbe71cf0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c25e38573bd7472d80a128aca553cd42": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7e95d191e34547b382d2abe7fe20a179": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "71dc8a29e73d4ddc9bd2a0c57a9ff446": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "84f6ba6061f44119a34c851ea5123558": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}