{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/steinhaug/stable-diffusion/blob/main/BLIP-2/AutoCaptioner-LLaVA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "AjIlnM48aec1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "60oc14dbXT1c"
      },
      "outputs": [],
      "source": [
        "#@markdown Download some images\n",
        "import locale\n",
        "locale.getpreferredencoding = lambda: \"UTF-8\"\n",
        "!mkdir /content/images\n",
        "#!wget --header 'Authorization: Bearer TOKEN_HERE' https://huggingface.co/camenduru/polaroid/resolve/main/style_name_fix.zip\n",
        "!cp /content/drive/MyDrive/data/blip2.zip /content/images/style_name_fix.zip\n",
        "!unzip /content/images/style_name_fix.zip -d /content/images"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pre-install"
      ],
      "metadata": {
        "id": "IH3_BSi7GyKj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown 1.0: Install dependencies\n",
        "from IPython.display import clear_output\n",
        "%cd /content\n",
        "!git clone -b dev https://github.com/camenduru/LLaVA\n",
        "%cd /content/LLaVA\n",
        "!wget https://raw.githubusercontent.com/L0garithmic/fastcolabcopy/main/fastcopy.py\n",
        "\n",
        "!pip install -q transformers==4.36.2\n",
        "!pip install ninja\n",
        "!pip install flash-attn --no-build-isolation\n",
        "\n",
        "!pip install -e .\n",
        "clear_output()\n",
        "print('\u001b[1;32mDone! ✓')"
      ],
      "metadata": {
        "id": "K6utlt7-Zcff",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown 1.2: Load notebook functions, needs to reload if you restart session.\n",
        "import tarfile\n",
        "import os\n",
        "import glob\n",
        "\n",
        "def compress_directory(directory_path, output_tar_file, inclusion_pattern=None):\n",
        "    if output_tar_file is None:\n",
        "        output_tar_file = f\"{directory_path}/{return__folderName(directory_path)}.tar\"\n",
        "    if not output_tar_file.endswith('.gz'):\n",
        "        output_tar_file += '.gz'\n",
        "    with tarfile.open(output_tar_file, 'w:gz') as tar:\n",
        "        for root, dirs, files in os.walk(directory_path):\n",
        "            if inclusion_pattern:\n",
        "                files_to_include = glob.glob(os.path.join(root, inclusion_pattern))\n",
        "            else:\n",
        "                files_to_include = [os.path.join(root, file) for file in files]\n",
        "            for file_path in files_to_include:\n",
        "                arcname = os.path.relpath(file_path, directory_path)\n",
        "                print(f\"{arcname}\")\n",
        "                tar.add(file_path, arcname=arcname)\n",
        "\n",
        "def decompress_tar(tar_file, destination=None, flatten_structure=False):\n",
        "    with tarfile.open(tar_file, 'r') as tar:\n",
        "        if destination is not None:\n",
        "            os.makedirs(destination, exist_ok=True)\n",
        "\n",
        "        for member in tar.getmembers():\n",
        "            if flatten_structure:\n",
        "                # Use just the filename without directories\n",
        "                member.name = os.path.basename(member.name)\n",
        "            if destination is not None:\n",
        "                # Join the destination directory with the member's name\n",
        "                member_path = os.path.join(destination, os.path.dirname(member.name))\n",
        "            else:\n",
        "                member_path = os.path.dirname(member.name)\n",
        "\n",
        "            if flatten_structure and destination==None:\n",
        "                member_path = os.path.dirname(tar_file)\n",
        "\n",
        "            tar.extract(member, path=member_path)\n",
        "\n",
        "def write_the_file(path, data_string):\n",
        "    if len(str(data_string)):\n",
        "        with open(path, 'w+') as fw:\n",
        "            fw.write(str(data_string))\n",
        "    else:\n",
        "        if os.path.exists(path):\n",
        "            os.remove(path)\n",
        "    return '';\n",
        "\n",
        "def return__folderName(directory_path, verify_folder=False):\n",
        "    if not verify_folder:\n",
        "        return os.path.basename(os.path.normpath(directory_path))\n",
        "    if os.path.isdir(directory_path):\n",
        "        last_folder_name = os.path.basename(os.path.normpath(directory_path))\n",
        "        return last_folder_name\n",
        "    else:\n",
        "        return None # Return None for invalid paths\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "4Fgx-7UpEZw1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model CONFIG"
      ],
      "metadata": {
        "id": "vOwSbjBmTIzi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown __[\\*]>=-  Unload model -=<[\\*]__ <br>\n",
        "#@markdown Run this cell if you need to load another model, or reset the runtime.\n",
        "image_processor = None\n",
        "vision_tower = None\n",
        "import gc\n",
        "import torch\n",
        "model = None\n",
        "tokenizer = None\n",
        "del model\n",
        "del tokenizer\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "cellView": "form",
        "id": "QDE9jxWDquBt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @markdown 1/3: Model select\n",
        "from IPython.display import clear_output\n",
        "%cd /content/LLaVA\n",
        "clear_output()\n",
        "\n",
        "import fastcopy\n",
        "import os\n",
        "def return__folderName(directory_path, verify_folder=False):\n",
        "\n",
        "    if not verify_folder:\n",
        "        return os.path.basename(os.path.normpath(directory_path))\n",
        "\n",
        "    # Ensure the path is a valid directory\n",
        "    if os.path.isdir(directory_path):\n",
        "        # Split the path into components and get the last one\n",
        "        last_folder_name = os.path.basename(os.path.normpath(directory_path))\n",
        "        return last_folder_name\n",
        "    else:\n",
        "        return None  # Return None for invalid paths\n",
        "\n",
        "model_id = \"4bit/llava-v1.5-13b-3GB\" # @param ['liuhaotian/llava-v1.5-7b', '4bit/llava-v1.5-13b-3GB']\n",
        "\n",
        "model_drive_path = f\"/content/drive/MyDrive/models/LLaVA/{model_id}\"\n",
        "model_path = f\"/content/models/{return__folderName(model_id)}\"\n",
        "\n",
        "print(f\"\u001b[1;32mSelected model: {return__folderName(model_id)} ✓\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "W_JjYTntUk_2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown 2/3: Model loader, prepare files and load model into GPU...\n",
        "import os\n",
        "if not os.path.isdir(model_path):\n",
        "    os.makedirs(model_path)\n",
        "    !python fastcopy.py \"$model_drive_path/\". \"$model_path\" --thread 20 --size-limit 400mb\n",
        "    !python fastcopy.py \"$model_drive_path/\". \"$model_path\" --thread 3 --size-limit 800mb\n",
        "    !rsync -r -v --size-only --progress $model_drive_path/. $model_path --delete\n",
        "\n",
        "from transformers import AutoTokenizer, BitsAndBytesConfig\n",
        "from llava.model import LlavaLlamaForCausalLM\n",
        "import torch\n",
        "\n",
        "if model_id == 'liuhaotian/llava-v1.5-7b':\n",
        "    kwargs = {\"device_map\": \"auto\", \"low_cpu_mem_usage\": True }\n",
        "    kwargs['load_in_8bit'] = True\n",
        "    kwargs['quantization_config'] = BitsAndBytesConfig(\n",
        "        load_in_8bit=True\n",
        "    )\n",
        "    print(\"Model download and config complete.\")\n",
        "elif model_id == '4bit/llava-v1.5-13b-3GB':\n",
        "    kwargs = {\"device_map\": \"auto\", \"low_cpu_mem_usage\": True }\n",
        "    kwargs['load_in_4bit'] = True\n",
        "    kwargs['quantization_config'] = BitsAndBytesConfig(\n",
        "        load_in_4bit=True,\n",
        "        bnb_4bit_compute_dtype=torch.float16,\n",
        "        bnb_4bit_use_double_quant=True,\n",
        "        bnb_4bit_quant_type='nf4'\n",
        "    )\n",
        "    print(\"Model download and config complete.\")\n",
        "elif model_id == '4bit/llava-v1.5-13b-4GB-8bit':\n",
        "    kwargs = {\"device_map\": \"auto\", \"low_cpu_mem_usage\": True }\n",
        "    kwargs['load_in_4bit'] = True\n",
        "    kwargs['quantization_config'] = BitsAndBytesConfig(\n",
        "        load_in_4bit=True,\n",
        "        bnb_4bit_quant_type=\"nf4\",\n",
        "        bnb_4bit_use_double_quant=True,\n",
        "        bnb_4bit_compute_dtype=torch.bfloat16\n",
        "    )\n",
        "    print(\"Model download and config complete.\")\n",
        "else:\n",
        "    print(\"Error...\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def old_ones():\n",
        "    #@ markdown llava-v1.5-13b-3GB\n",
        "    from transformers import AutoTokenizer, BitsAndBytesConfig\n",
        "    from llava.model import LlavaLlamaForCausalLM\n",
        "    import torch\n",
        "\n",
        "    model_path = \"/content/llava-v1.5-13b-3GB\"\n",
        "    kwargs = {\"device_map\": \"auto\", \"low_cpu_mem_usage\": True }\n",
        "    kwargs['load_in_4bit'] = True\n",
        "    kwargs['quantization_config'] = BitsAndBytesConfig(\n",
        "        load_in_4bit=True,\n",
        "        bnb_4bit_compute_dtype=torch.float16,\n",
        "        bnb_4bit_use_double_quant=True,\n",
        "        bnb_4bit_quant_type='nf4'\n",
        "    )\n",
        "\n",
        "\n",
        "    #@ markdown llava-v1.5-7b\n",
        "    from transformers import AutoTokenizer, BitsAndBytesConfig\n",
        "    from llava.model import LlavaLlamaForCausalLM\n",
        "    import torch\n",
        "\n",
        "    model_path = \"/content/llava-v1.5-7b\"\n",
        "    kwargs = {\"device_map\": \"auto\", \"low_cpu_mem_usage\": True }\n",
        "    kwargs['load_in_8bit'] = True\n",
        "    kwargs['quantization_config'] = BitsAndBytesConfig(\n",
        "        load_in_8bit=True\n",
        "    )\n",
        "\n",
        "\n",
        "\n",
        "#@ title Load it up - move to GPU\n",
        "my_list = ['llava-v1.5-7b','llava-v1.5-13b-3GB','llava-v1.5-13b-4GB-8bit']\n",
        "if return__folderName(model_path) in my_list:\n",
        "    model = LlavaLlamaForCausalLM.from_pretrained(model_path, **kwargs)\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_path, use_fast=False)\n",
        "\n",
        "    vision_tower = model.get_vision_tower()\n",
        "    if not vision_tower.is_loaded:\n",
        "        vision_tower.load_model()\n",
        "    vision_tower.to(device='cuda')\n",
        "    image_processor = vision_tower.image_processor\n",
        "else:\n",
        "    print(f\"{element_to_check} is not a valid model.\")\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "dwo2mY8tidLl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VjYy0F2gZIPR",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@markdown 3/3: Load the caption_image func\n",
        "import os\n",
        "import requests\n",
        "from PIL import Image\n",
        "from io import BytesIO\n",
        "from llava.conversation import conv_templates, SeparatorStyle\n",
        "from llava.utils import disable_torch_init\n",
        "from llava.constants import IMAGE_TOKEN_INDEX, DEFAULT_IMAGE_TOKEN, DEFAULT_IM_START_TOKEN, DEFAULT_IM_END_TOKEN\n",
        "from llava.mm_utils import tokenizer_image_token, get_model_name_from_path, KeywordsStoppingCriteria\n",
        "from transformers import TextStreamer\n",
        "\n",
        "def caption_image(image_file, prompt, temperature=0.2):\n",
        "    if image_file.startswith('http') or image_file.startswith('https'):\n",
        "        response = requests.get(image_file)\n",
        "        image = Image.open(BytesIO(response.content)).convert('RGB')\n",
        "    else:\n",
        "        image = Image.open(image_file).convert('RGB')\n",
        "    disable_torch_init()\n",
        "    conv_mode = \"llava_v0\"\n",
        "    conv = conv_templates[conv_mode].copy()\n",
        "    roles = conv.roles\n",
        "    image_tensor = image_processor.preprocess(image, return_tensors='pt')['pixel_values'].half().cuda()\n",
        "    inp = f\"{roles[0]}: {prompt}\"\n",
        "    inp = DEFAULT_IM_START_TOKEN + DEFAULT_IMAGE_TOKEN + DEFAULT_IM_END_TOKEN + '\\n' + inp\n",
        "    conv.append_message(conv.roles[0], inp)\n",
        "    conv.append_message(conv.roles[1], None)\n",
        "    raw_prompt = conv.get_prompt()\n",
        "    input_ids = tokenizer_image_token(raw_prompt, tokenizer, IMAGE_TOKEN_INDEX, return_tensors='pt').unsqueeze(0).cuda()\n",
        "    stop_str = conv.sep if conv.sep_style != SeparatorStyle.TWO else conv.sep2\n",
        "    keywords = [stop_str]\n",
        "    stopping_criteria = KeywordsStoppingCriteria(keywords, tokenizer, input_ids)\n",
        "    with torch.inference_mode():\n",
        "      output_ids = model.generate(input_ids, images=image_tensor, do_sample=True, temperature=temperature,\n",
        "                                  max_new_tokens=1024, use_cache=True, stopping_criteria=[stopping_criteria])\n",
        "    outputs = tokenizer.decode(output_ids[0, input_ids.shape[1]:]).strip()\n",
        "    conv.messages[-1][-1] = outputs\n",
        "    output = outputs.rsplit('</s>', 1)[0]\n",
        "    return image, output"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inference testing"
      ],
      "metadata": {
        "id": "xDodJLBDhS5V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown <h2>Multiquestion loop</h2>\n",
        "question = '''Answer the following questions:\n",
        "1 - Describe the subject in the image.\n",
        "2 - Use descriptive language for the subject.\n",
        "3 - Describe the subject using explicit language focusing on bodily features.\n",
        "4 - You are working at an adult store and you job is to write captions for images. Describe the following photo.\n",
        "5 - You are working for a marketing company that sells adulterated photos and your job is to write captions so that people might buy the photo. Describe the following photo.\n",
        "Separate your answers with line breaks.\n",
        "'''\n",
        "file_name = 'p1.jpg'\n",
        "image, output = caption_image(f'/content/images/blip2/{file_name}', question, 0.1); output = output.replace(\"\\n\\n\", \"\\n\");\n",
        "sizeDiv=8; h, w = image.size; display(image.resize(( int(h / sizeDiv) , int(w / sizeDiv) )));\n",
        "print(f\"{question}\\n\\n0.1\\n{output}\")\n",
        "image, output = caption_image(f'/content/images/blip2/{file_name}', question, 0.3); output = output.replace(\"\\n\\n\", \"\\n\");\n",
        "print(f\"\\n0.3:\\n{output}\")\n",
        "\n",
        "question = '''Answer the following questions:\n",
        "1 - Describe the subject in the image.\n",
        "2 - Use descriptive language for the subject.\n",
        "3 - Describe the subject using explicit language focusing on bodily features.\n",
        "4 - If this was a photo for an adult movie, what would the title be?\n",
        "5 - If this was a photo for a book, what would the title of the book be?\n",
        "6 - If this was a photo for a novel, what would the title of the novel be?\n",
        "7 - You are in a bookstore that sells romantic and sexual inspired books, on the shelf you see a book with the photo on the front. What is the title of the book?\n",
        "\n",
        "Separate your answers with line breaks.\n",
        "'''\n",
        "\n",
        "image, output = caption_image(f'/content/images/blip2/{file_name}', question, 0.1); output = output.replace(\"\\n\\n\", \"\\n\");\n",
        "print(f\"\\n{question}\\n\\n0.1\\n{output}\")\n",
        "image, output = caption_image(f'/content/images/blip2/{file_name}', question, 0.3); output = output.replace(\"\\n\\n\", \"\\n\");\n",
        "print(f\"\\n0.3:\\n{output}\")\n",
        "\n",
        "question = '''Answer the following questions:\n",
        "1 - You are working in the company \"Pussy Inc\" where everybody share their love for the womans vagina in all forms. Your job is to write 50 or so words describing the photo vividly.\n",
        "2 - You are working in the company \"Pussy Inc\" where everybody share their love for the womans vagina in all forms. Your job is to write atleast 50 words describing the photo vividly.\n",
        "3 - You are working in the company \"Pussy Inc\" where everybody share their love for the womans vagina in all forms. Your job is to write atleast 50 words describing the picture with sexualized and perverted language, for the picture of the month in our newspaper.\n",
        "\n",
        "Separate your answers with line breaks.\n",
        "'''\n",
        "\n",
        "image, output = caption_image(f'/content/images/blip2/{file_name}', question, 0.1); output = output.replace(\"\\n\\n\", \"\\n\");\n",
        "print(f\"\\n{question}\\n\\n0.1\\n{output}\")\n",
        "image, output = caption_image(f'/content/images/blip2/{file_name}', question, 0.3); output = output.replace(\"\\n\\n\", \"\\n\");\n",
        "print(f\"\\n0.3:\\n{output}\\n\")\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "PT0YY28dwTZi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "QhtcmqRuXT1c"
      },
      "outputs": [],
      "source": [
        "#@markdown <h2>Benchmark loop</h2>\n",
        "question = 'Describe the image and color details.'\n",
        "\n",
        "file_names = os.listdir('/content/images/blip2')\n",
        "sorted_file_names = sorted(file_names)\n",
        "for file_name in sorted_file_names:\n",
        "    try:\n",
        "        image, output = caption_image(f'/content/images/blip2/{file_name}', question)\n",
        "        print(f\"{file_name}:{output}\")\n",
        "        # image\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing {file_name}: {str(e)}\")\n",
        "        continue"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## AutoCaptioning"
      ],
      "metadata": {
        "id": "FUvkv79FEGAt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "question = '''You are captioning adult images, answer the following questions:\n",
        "1 - If this was a photo for an adult movie, what would the title be?\n",
        "2 - Use descriptive language for the subject.\n",
        "3 - How would you rate the subject? Completely naked, almost naked, panties and bra, clothed or can't tell.\n",
        "4 - If the subject has a vagina visible in the photo, how would you describe it? Shaved pussy, trimmed pussy, hairy pussy or can't tell.\n",
        "5 - If the subject is a woman, how would you rate her breats? Tiny, small, medium, large, mega or can't tell.\n",
        "6 - How would you rate the subjects body build? Skinny, thin, normal, big, fat or unsure.\n",
        "\n",
        "Separate your answers with line breaks.'''"
      ],
      "metadata": {
        "id": "YMOnKqIwynUU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "from google.colab import userdata\n",
        "HF_TOKEN = userdata.get('HF_TOKEN')\n",
        "\n",
        "!huggingface-cli login --token {HF_TOKEN}\n",
        "from huggingface_hub import snapshot_download"
      ],
      "metadata": {
        "id": "RKWOlIGizo-V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@ markdown Download image sets\n",
        "import os\n",
        "SAVE_PATH = '/content/datasets'\n",
        "REPO_ID = 'steinhaug/onceUponAtimeInPornVille'\n",
        "os.makedirs(f\"{SAVE_PATH}/{REPO_ID}\", exist_ok=True)\n",
        "path = snapshot_download(repo_id=REPO_ID, repo_type=\"dataset\", revision=\"main\", allow_patterns=\"SkinnyHotGirls/*\", local_dir=f\"{SAVE_PATH}/{REPO_ID}\", local_dir_use_symlinks=False)"
      ],
      "metadata": {
        "id": "Otvo8vKIz3AW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tar_file_path = '/content/datasets/steinhaug/onceUponAtimeInPornVille/SkinnyHotGirls/skinny_hot_girls.tar'\n",
        "decompress_tar(tar_file_path, None, True)\n",
        "IMAGE_FOLDER = '/content/datasets/steinhaug/onceUponAtimeInPornVille/SkinnyHotGirls'"
      ],
      "metadata": {
        "id": "0bnejhBj1me0"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loop through folder and caption images in seperate .txt\n",
        "\n",
        "question = '''You are captioning adult images, answer the following questions:\n",
        "1 - If this was a photo for an adult movie, what would the title be?\n",
        "2 - Use descriptive language for the subject.\n",
        "3 - How would you rate the subject? Completely naked, almost naked, panties and bra, clothed or can't tell.\n",
        "4 - If the subject has a vagina visible in the photo, how would you describe it? Shaved pussy, trimmed pussy, hairy pussy or can't tell.\n",
        "5 - If the subject is a woman, how would you rate her breats? Tiny, small, medium, large, mega or can't tell.\n",
        "6 - How would you rate the subjects body build? Skinny, thin, normal, big, fat or unsure.\n",
        "\n",
        "Separate your answers with line breaks.'''\n",
        "\n",
        "for item_name in os.listdir(IMAGE_FOLDER):\n",
        "    file_path = os.path.join(IMAGE_FOLDER, item_name)\n",
        "\n",
        "    root, extension = os.path.splitext(file_path)\n",
        "    image_extensions = ['.jpg', '.jpeg', '.png', '.gif', '.bmp', '.webp']\n",
        "    if extension.lower() in image_extensions:\n",
        "        caption_file = f\"{root}.txt\"\n",
        "        try:\n",
        "            image, caption_result = caption_image(file_path, question)\n",
        "            caption_result = caption_result.replace(\"\\n\\n\", \"\\n\")\n",
        "            write_the_file(caption_file, caption_result)\n",
        "            sizeDiv = 8\n",
        "            h, w = image.size\n",
        "            display(image.resize(( int(h / sizeDiv) , int(w / sizeDiv) )))\n",
        "            print(f\"{caption_result}\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing {item_name}: {str(e)}\")\n",
        "            continue"
      ],
      "metadata": {
        "id": "Kw4Y15ae6xDN"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "compress_directory(IMAGE_FOLDER, '/content/captions.tar', '*.txt')"
      ],
      "metadata": {
        "id": "p0OSpvM0-gS1"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}