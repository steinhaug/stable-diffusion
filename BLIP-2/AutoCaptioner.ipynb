{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "mount_file_id": "1-Q4MJ_JBCoecptXozarrJzVTt3VCoV1E",
      "authorship_tag": "ABX9TyN1hFqJAdxfrJTO/MAmk/AI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/steinhaug/stable-diffusion/blob/main/BLIP-2/AutoCaptioner.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Connect runtime and mount Google Drive\n",
        "#@markdown Check type of GPU and VRAM available.\n",
        "!nvidia-smi --query-gpu=name,memory.total,memory.free --format=csv,noheader\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5FN-Xk8REEGk",
        "outputId": "e0cd1634-d0ce-4a45-9259-ceb51dab0976"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tesla T4, 15360 MiB, 15101 MiB\n",
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "IMAGE_FOLDERS = '/content/drive/MyDrive/datasets/PinupFiles'"
      ],
      "metadata": {
        "id": "RLswQHUNzF83"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Captioning pipeline"
      ],
      "metadata": {
        "id": "d156OILH4uHl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown Install blip-2\n",
        "from IPython.display import clear_output\n",
        "def ret_directoryFileCount(dir_path):\n",
        "    file_count = 0\n",
        "    for path in os.listdir(dir_path):\n",
        "        if os.path.isfile(os.path.join(dir_path, path)):\n",
        "            file_count += 1\n",
        "    return file_count\n",
        "import sys\n",
        "if 'google.colab' in sys.modules:\n",
        "    !pip3 install salesforce-lavis\n",
        "clear_output()\n",
        "print('[1;32mDone! ✓')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6u_F-ybpBUex",
        "outputId": "92a9eec5-49eb-4cc9-892d-51e7b9dbcc7b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1;32mDone! ✓\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown Init blip-2\n",
        "import torch\n",
        "from PIL import Image\n",
        "import requests\n",
        "from lavis.models import load_model_and_preprocess\n",
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else \"cpu\""
      ],
      "metadata": {
        "id": "xMN2jZFABhtK",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Load the blip-2 model\n",
        "#model, vis_processors, _ = load_model_and_preprocess(\n",
        "#    name=\"blip2_opt\", model_type=\"pretrain_opt2.7b\", is_eval=True, device=device\n",
        "#)\n",
        "model, vis_processors, _ = load_model_and_preprocess(\n",
        "    name=\"blip2_opt\", model_type=\"caption_coco_opt2.7b\", is_eval=True, device=device\n",
        ")\n",
        "vis_processors.keys()\n",
        "clear_output(); print('[1;32mDone! ✓')"
      ],
      "metadata": {
        "id": "7YyFmmXRBt9F",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown Functions\n",
        "import os; import random; import json; import time;\n",
        "\n",
        "def load_image(image_path, sizeDiv=8):\n",
        "    raw_image = Image.open(f'{image_path}').convert('RGB')\n",
        "    h, w = raw_image.size\n",
        "    display(raw_image.resize(( int(h / sizeDiv) , int(w / sizeDiv) )))\n",
        "    image = vis_processors[\"eval\"](raw_image).unsqueeze(0).to(device)\n",
        "    return image\n",
        "\n",
        "def wrap_query(query):\n",
        "    return \"Question: \" + query + \" Answer:\"\n",
        "\n",
        "def write__logfile(file, msg):\n",
        "    with open(file, 'a') as fa:\n",
        "        fa.write(msg)\n",
        "    return ''\n",
        "\n",
        "def write_the_file(path, data_string):\n",
        "    if len(str(data_string)):\n",
        "        with open(path, 'w+') as fw:\n",
        "            fw.write(str(data_string))\n",
        "    else:\n",
        "        if os.path.exists(path):\n",
        "            os.remove(path)\n",
        "    return '';\n",
        "\n",
        "def ret__longest_val(arr):\n",
        "    curr_v = ''\n",
        "    curr_x = 0\n",
        "    while arr:\n",
        "        val = arr.pop(0)\n",
        "        if len(val) >= curr_x:\n",
        "            curr_x = len(val)\n",
        "            curr_v = val\n",
        "    return curr_v\n",
        "\n",
        "def auto__get_AI_caption(IMG_SRC):\n",
        "    image = load_image(IMG_SRC)\n",
        "    cap1 = ret__longest_val( model.generate({\"image\": image}, use_nucleus_sampling=False, num_captions=4) )\n",
        "    cap2 = ret__longest_val( model.generate({\"image\": image}, use_nucleus_sampling=True, num_captions=4) )\n",
        "    cap3 = model.generate({\"image\": image, \"prompt\": wrap_query('What is out of the ordinary with this image?')}).pop(0)\n",
        "    return [cap1, cap2, cap3]\n",
        "\n",
        "def auto__create_caption(IMG_SRC, CAPTION_SRC):\n",
        "    if os.path.isfile(CAPTION_SRC):\n",
        "        return 1\n",
        "    caption_array = auto__get_AI_caption(IMG_SRC)\n",
        "    write_the_file(CAPTION_SRC, json.dumps(caption_array))\n",
        "    return json.dumps(caption_array)\n",
        "\n",
        "#caption = auto__get_AI_caption('/content/drive/MyDrive/datasets/PinupFiles/Beth-Lily/beth-lily-vol-1-set-1-1.jpg')\n",
        "#write_the_file('/content/test.txt', caption)\n",
        "#print(caption)\n",
        "#image = vis_processors[\"eval\"](raw_image).unsqueeze(0).to(device)"
      ],
      "metadata": {
        "id": "DrbuXVgmCT1q",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Optional: Unzipping all ZIP files in IMAGE_FOLDERS\n",
        "#@markdown Unzip all folders in IMAGE_FOLDERS\n",
        "from zipfile import ZipFile\n",
        "import os\n",
        "\n",
        "for item in os.listdir(IMAGE_FOLDERS):\n",
        "    zips = os.path.join(IMAGE_FOLDERS, item)\n",
        "    print(f'Extracting: {item}')\n",
        "    with ZipFile(zips, 'r') as zObject:\n",
        "        zObject.extractall(path=IMAGE_FOLDERS)"
      ],
      "metadata": {
        "id": "crCt80sPxBH_",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title List directories and image count\n",
        "import os\n",
        "for item_name in os.listdir(IMAGE_FOLDERS):\n",
        "    item = os.path.join(IMAGE_FOLDERS, item_name)\n",
        "    if os.path.isdir(item):\n",
        "        if \"_captions\" in item_name:\n",
        "            continue;\n",
        "        print( f'{item_name}: {ret_directoryFileCount(item)}' )"
      ],
      "metadata": {
        "id": "wPumjHpEzL9T",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Captioning loop for all folders within IMAGE_FOLDERS\n",
        "import os; import random; import json; import time;\n",
        "\n",
        "LOGFILE_NAME = '/' + time.strftime(\"%Y%m%d-%H%M%S\") + '.log'\n",
        "\n",
        "for IMAGE_FOLDER in os.listdir(IMAGE_FOLDERS):\n",
        "    FOLDER = os.path.join(IMAGE_FOLDERS, IMAGE_FOLDER)\n",
        "    if os.path.isdir(FOLDER):\n",
        "        if \"_captions\" in FOLDER:\n",
        "            continue;\n",
        "        os.makedirs(FOLDER + '_captions', exist_ok=True)\n",
        "        for FILE_NAME in os.listdir(FOLDER):\n",
        "            IMG_SRC = os.path.join(FOLDER, FILE_NAME)\n",
        "            if os.path.isfile(IMG_SRC):\n",
        "                f_name, f_ext = os.path.splitext(FILE_NAME)\n",
        "                CAPTION_SRC = FOLDER + f'_captions/{f_name}.txt'\n",
        "                caption = auto__create_caption(IMG_SRC, CAPTION_SRC)\n",
        "                if caption == 1:\n",
        "                    write__logfile(IMAGE_FOLDERS + LOGFILE_NAME, f'{f_name}: {caption}')\n",
        "                else:\n",
        "                    print(f'{f_name}: {caption}')\n",
        "\n",
        "#    if IMAGE_FOLDER == 'Holly-Peers':\n",
        "#        print('Found Holly-Peers')\n",
        "#        break"
      ],
      "metadata": {
        "id": "YHlBxsTF0l-y",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}